# 在公共演讲入门课程中融入虚拟现实训练

关键词：教学沟通，虚拟现实，公共演讲，基础课程，演讲培训，沟通教育 摘要：本研究呈现了两项研究的结果，使用虚拟现实（VR）公共演讲训练模拟作为基础沟通课程的教学辅助工具。第一项研究的结果表明，与没有练习相比，VR练习与后续演讲评分较高相关。然而，VR练习并未降低公共演讲焦虑（PSA）。在后续研究中，VR练习与其他形式的实验室练习进行比较，包括面对镜子和录制视频的练习。所有实验室练习（VR、镜子或视频）均与比没有练习更高的演讲评分相关，但在结果方面，各实验室练习条件之间没有显著差异。讨论结果时，借鉴和使用虚拟公共演讲模拟在大型本科公共演讲课程中的应用。公共演讲是全国大多数沟通系的基石。提高沟通能力是高等教育中基础沟通课程的主要功能（Cohen，1994；Morreale等，2016），在大多数情况下，这意味着提高公共演讲技能。通常，这些课程依靠行为训练、公共演讲示范和练习以及表演反馈等技术，以提高沟通能力并降低公共演讲焦虑（PSA；Robinson，1997）。然而，基础课程通常在大型课程中进行，且同时有多个班次（Morreale等，2016）。这些影响基础课程结构的因素可能导致在为学生提供有意义的练习和反馈机会方面出现潜在困难，原因包括班级过于拥挤、教学教师之间缺乏标准化反馈，或班级组成及观众反应的差异。

![](images/1.jpg)  
FIGURE 1 Screenshot of Participant Giving Speech and the Virtual Environment.

一种有效将受控练习环节纳入基础课程的方法是使用虚拟观众为在练习中的演讲者提供逼真且同步的反馈。目前市场上已有多款模拟公共演讲体验的商业产品。这些虚拟系统的观众由数字化身组成，能够对目光、头部运动和声音语调做出积极或消极的反应（如图1所示）。传播学者们已经开始研究这些系统在公共演讲和沟通技能训练中的实用性。然而，尚不清楚将这些系统纳入基础公共演讲课程后，是否会改善学生的表现。因此，我们的核心研究问题是，虚拟现实（VR）公共演讲在多大程度上可以模拟、补充或增强基础沟通课程中的有效演讲实践？在接下来的论文中，我们讨论基础沟通课程的格式和公共演讲技能训练，接着回顾现有关于VR公共演讲的文献，最后介绍两项将VR公共演讲训练纳入基础沟通课程的研究案例。

# 有效的演讲训练

公共演讲历来是传播学的核心（Cohen, 1994）。超过 $60\%$ 的基础传播课程教授公共演讲，$100\%$ 的两年制学校和 $88.6\%$ 的四年制学校在基础传播课程中强调公共演讲（Morreale et al., 2016）。根据国家传播协会关于成为合格演讲者的指南（Morreale et al., 2007），要成为一名有效的公共演讲者，必须满足或超越以下八个领域的基本能力标准：（1）恰当选择主题，（2）传达论文/具体目的，（3）提供适当的支持材料，（4）使用有效的组织结构，（5）恰当使用语言，（6）在语速、音高和音量上使用声调变化，（7）使用正确的发音、语法和清晰表达，以及（8）使用支持言语信息的肢体（非语言）行为。这八项能力源自超过100年的公共演讲培训，类似的培训模型已在全球的公共演讲课程中得到采用（例如，英语演讲联盟，2019；西川-范·埃斯特，2009）。一般而言，传播学领域培养多种技能，以增强和改善这些公共演讲能力，包括练习眼神交流、非语言行为、手势、声音表现、演讲技巧、演讲写作以及识别观众反馈（Haynes, 1990）。这种基于技能的培训似乎对自我评估和熟练他者（例如演讲俱乐部成员）的评估的演讲技能都有积极影响（Seibold et al., 1993）。

基础课程最好的培训机制之一就是要求学生练习公众演讲。一项实证研究显示，学生在演讲前的准备和练习能够提高评估结果。此外，演讲前的练习量和练习类型被认定为影响公众演讲能力的重要因素。演练的重要性在于公众号演讲课程中使用最广泛的教材《公众演讲艺术》中得到了体现。这本书强调，练习是培养合格演讲者最关键的组成部分。在大多数基础课程中，学生通常需要完成1到10次演讲，平均每学期要求进行三次演讲。针对性的反馈也在发展扎实的公众演讲技能中发挥着重要作用。基础课程帮助学生成为更好公众演讲者的一种方式是提供结构化的评分标准，明确演讲中的修辞、语言和非语言的期望。某位学者认为，及时的反馈（即在演讲后立即进行反馈）能够让听众的反应直接影响演讲者，并告知他们在演讲中表现出的强项和需要改进的地方。在公众演讲课程中纳入及时反馈的一种方式是录制学生的演讲，并要求他们观看录音。在一项关于录音反馈在公众演讲课程中作用的荟萃分析中，研究者报告称，录音反馈能提高技能获得、演讲内容、对演讲的回忆以及更积极的课程态度。

此外，大多数公共演讲的传播教育强调克服和应对公共演讲焦虑（PSA）和/或沟通焦虑（CA）的必要性，这两者都会对学生的自信心和公开演讲能力产生负面影响（Allen & Bourhis, 1996；Allen et al., 1989；Bodie, 2010；McCroskey, 1982；Robinson, 1997）。CA是一个广泛的术语，指个体对与他人进行真实或预期沟通所带来的焦虑的恐惧（McCroskey, 1982）。值得注意的是，练习是减少沟通焦虑最有效的技术之一（Allen et al., 1989；Bodie, 2010）。与PSA更密切相关的负面评价恐惧（FNE；Watson & Friend, 1969）特指对他人评价的担忧、对可能的负面评价的痛苦以及期望自己会受到负面评价。FNE与CA密切相关，可能是人们对公共演讲恐惧的潜在原因。总之，练习、反馈和焦虑减轻是有效公共演讲训练中的三个最重要的关注点。此外，平均绩点、以往公共演讲经验（Pearson & Child, 2008；Rubin et al., 1990）和生物性别（Pearson et al., 2008）等习惯性变量都会影响学生在公共演讲作业中的成绩。然而，鉴于这些特征的僵化性，本文将重点关注虚拟现实平台在提供（a）增加和系统化练习机会，（b）为演讲者提供相关反馈，以及（c）减少CA和FNE方面的作用。

# 虚拟现实与公众演讲

虚拟现实（VR）为学生提供了一个独特的机会，可以在模拟未来公共演讲场合的虚拟环境中进行演讲练习。在这些环境中，可以通过360度视频模拟观众（例如，生成动画的类人化虚拟形象在数字化教室中；参见Davis等，2020）。因为研究表明，人们在与非人类实体（如电视、计算机、虚拟形象）互动时，往往会以类似于与人类实体互动的方式来回应（参见计算机作为社会角色范式；Reeves & Nass，1996），因此在360度视频或虚拟观众面前进行VR练习应该能够模拟面对面场合的练习。

支持这一论断的是，对于高度演讲焦虑的演讲者，在虚拟观众面前发言可能会引发焦虑（Kothgassner 等，2016；Vanni 等，2013），这表明虚拟演示在功能上模拟了现实中的演讲体验。同样，Pertaub 等（2002）和 Slater 等（2006）研究了对演讲者的主观和生理心理影响；恐惧症参与者在虚拟观众面前表现出更高的焦虑和更快的心率。这种效果对于高社交恐惧的参与者尤其明显。考虑到虚拟现实能够引发在观众面前演讲的真实感受，早期的虚拟现实研究集中在其作为脱敏工具的有效性，通过暴露疗法帮助高度反应的演讲者进行适应。Harris 等，200；Pertaub 等，200；Vanni 等，01。总体而言，结果表明在结合暴露疗法时，虚拟现实能够减少演讲焦虑（Vanni 等，2013）。然而，虚拟现实练习在课堂环境中减轻焦虑的程度仍然未知；一些研究发现虚拟现实练习减少了焦虑（LeFebvre 等，2020），而其他研究则显示虚拟现实练习增加了演讲焦虑（Davis 等，2020）。

其他研究已探讨虚拟现实作为公共演讲教学辅助工具的效果，尤其是通过平台内反馈。例如，Chollet等人（2015）利用虚拟环境测试视觉、口头或观众非语言反馈对演讲者表现的影响，发现互动和响应性的非语言反馈条件对演讲者最具吸引力，而与互动观众练习的演讲者最希望重复这一体验。许多虚拟现实公共演讲程序被动收集眼神注视、触觉和声音等行为，并基于这些指标向演讲者提供反馈，这些指标与演讲者表现相关（例如，Batrinca等，2013）。因此，虚拟现实软件提供的反馈可以成为帮助学生提高演讲能力的工具（Morreale等，2007），特别是在提高声音多样性（即能力六）、发音清晰度（即能力七）和眼神交流（即能力八）方面。由于易于部署和相对较低的实施成本，将虚拟现实纳入大型公共演讲课程已成为传播学者关注的话题。除了学者实施的便利性，作为演讲练习工具的虚拟现实程序还为学生带来了积极的情感体验（Vallade等，2020），增强了公共演讲自我效能感（Frisby等，2020），并减少了想象互动中的演讲焦虑（LeFebvre等，2020）。然而，很少有研究将演讲评分作为因变量，而那些涉及的研究也较为稀缺。

我们的整体研究问题是：在虚拟观众面前练习的学生相比于未练习的学生，是否展现出更高的公共演讲能力？这背后可能有哪些潜在机制来解释这种能力？我们通过在一所大型中西部大学的同一基础传播课程中进行的为期两个学期的公共演讲模拟（虚拟演说者；Blom，2018），作为演讲练习工具，来探讨这个问题。在第一项研究中，我们比较了参与了虚拟现实练习课程的学生与未参与学生的成绩，并研究了这些成绩与初始公共演讲焦虑（PSA）及社交恐惧（FNE）之间的关联。对于虚拟现实条件下的参与者，我们进一步探讨了软件反馈、任务兴趣和乐趣以及在虚拟环境中的存在感，作为虚拟现实练习有效性的潜在调节变量或中介变量，以寻找未来研究的方向。我们还控制了参与者对虚拟现实技术的先前经验。在第二项研究中，我们将虚拟现实练习与视频录制条件（Bourhis & Allen，1998）以及参与者在镜子前观看自己演讲的传统练习方法进行了比较，这是一种促使自我意识的传统演讲练习方法（Dermody & Sutherland，2019）。在第二项研究中，我们还增加了任务难度和需求感知，以及任务焦虑测量，并结合第一项研究中测量的其他变量。

# 研究 1

# 方法

参与者。学生 $n = 204$，其中 $45\%$ 为女性；$M_{年龄} = 19.52$，$SD_{年龄} = 1.37$，招募自一门大型入门级传播课程，但只有同意将所有课程成绩用于本研究的参与者（$n = 140$）被保留用于分析。学生因参与本研究而获得课程学分，并可以根据需要完成替代作业。所有招募、数据收集和分析程序均经过大学伦理审查委员会批准。程序。我们采用准实验方法，以尽量减少对现有课堂的干扰。在学期首个演讲前两周，参与者填写了测量其公共演讲焦虑（PSA）、对虚拟现实（VR）的兴趣、VR经验以及人口统计信息的调查。在完成初始调查后，但在进行最终演讲之前，有 80 名参与者选择在虚拟现实中练习演讲。到达实验室后，参与者收到了一份详细说明实验室程序和数据收集的知情同意书。实验人员简要描述了实验程序。随后，学生在虚拟现实中练习他们的演讲。之后，参与者完成了关于模拟晕动症、对练习课程的兴趣、空间存在感、公共演讲焦虑（PSA）和社交焦虑（FNE）的测量。此外，参与者还从虚拟程序中获得反馈（见图）。参与者可以随意查看反馈。就在他们在虚拟现实中练习演讲后不超过 3 周，学生在其朗读课程中进行了相同的演讲，朗读课程是更大课堂下的一个较小（1020人）子部分。成绩由经过培训的研究生助教进行评估，并在学期末汇总。

![](images/2.jpg)  
FIGURE 2 Sample of Virtual Orator Feedback Screen.

软件。虚拟演讲者（Blom, 2018）软件包用于训练课程。所有参与者在同一个小教室场景中进行演讲。观众的设置为友好，并在性别和种族上均匀分布。参与者被给予12分钟的练习时间。VirtualOrator通过计算机的内置摄像头记录演讲者在虚拟现实中的表现，并插入演讲者在虚拟现实中的视野图像，同时收集与言语和非言语表现相关的各种数据，例如演讲音调和音量，以及房间内的注视分布。硬件。实验室配备了Alienware 15R4笔记本电脑和HTC VIVE头显（附带软件）。虚拟环境通过SteamVR（Valve, 2019）运行。参与者利用VIVE控制器通过点击方向箭头按钮来更改幻灯片或他们的演示和笔记（如适用）（见图1）。

# 措施

个人公开演讲焦虑报告。收集了34项个人公开演讲焦虑报告（PRPSA; McCroskey, 1970），在招募后进行（T1: $n = 132$ $\mathtt{d} = .90$ $M = 3.28$ $S D = 0.53$），并在参与者在虚拟现实中演讲后再次进行评估（T2: $n = 53^1$ $\mathtt{a} = .92$ $M = 3.26$ $S D = 0.63$）。分数越高表示公开演讲焦虑越严重。负面评价恐惧量表。负面评价恐惧量表（FNES; Leary, 1983）包含诸如教育等方面的内容，并在招募后（T1: $n = 132$，$\mathtt{d} = .90$ $M = 3.21$，$S D = 0.76$）和在虚拟现实中演讲后（T2: $n = 54^1$，$\mathtt{a} = .92$，$M = 3.23$，$S D = 0.79$）进行测量。分数越高表明对负面评价的恐惧越大。虚拟现实反馈。反馈包括演讲者在虚拟教室不同象限注视的时间、单调段落的数量以及在同一音高、范围和音量下演讲的百分比。详细信息见表1。

<table><tr><td rowspan=1 colspan=6>TABLE 1Study 1 Descriptive statistics for VR performance measures</td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>n</td><td rowspan=1 colspan=1>Min.</td><td rowspan=1 colspan=1>Max.</td><td rowspan=1 colspan=1>M</td><td rowspan=1 colspan=1>SD</td></tr><tr><td rowspan=1 colspan=1>Time looking front left</td><td rowspan=1 colspan=1>67</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>551.32</td><td rowspan=1 colspan=1>78.1672</td><td rowspan=1 colspan=1>118.7878</td></tr><tr><td rowspan=1 colspan=1>Time looking front right</td><td rowspan=1 colspan=1>67</td><td rowspan=1 colspan=1>0.54</td><td rowspan=1 colspan=1>531.95</td><td rowspan=1 colspan=1>113.5474</td><td rowspan=1 colspan=1>106.6375</td></tr><tr><td rowspan=1 colspan=1>Time looking back left</td><td rowspan=1 colspan=1>67</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>11.91</td><td rowspan=1 colspan=1>13.9608</td><td rowspan=1 colspan=1>18.58946</td></tr><tr><td rowspan=1 colspan=1>Time looking back right</td><td rowspan=1 colspan=1>67</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>107.56</td><td rowspan=1 colspan=1>16.7944</td><td rowspan=1 colspan=1>24.35308</td></tr><tr><td rowspan=1 colspan=1>Number of monotone segments</td><td rowspan=1 colspan=1>47</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>5</td><td rowspan=1 colspan=1>1.0426</td><td rowspan=1 colspan=1>1.28465</td></tr><tr><td rowspan=1 colspan=1>Ave. % on fundamental tone</td><td rowspan=1 colspan=1>47</td><td rowspan=1 colspan=1>0.45</td><td rowspan=1 colspan=1>0.94</td><td rowspan=1 colspan=1>.666</td><td rowspan=1 colspan=1>.1113</td></tr><tr><td rowspan=1 colspan=1>Number of notes hit</td><td rowspan=1 colspan=1>47</td><td rowspan=1 colspan=1>9</td><td rowspan=1 colspan=1>21</td><td rowspan=1 colspan=1>13.3191</td><td rowspan=1 colspan=1>3.00801</td></tr><tr><td rowspan=1 colspan=1>Tonal Range</td><td rowspan=1 colspan=1>47</td><td rowspan=1 colspan=1>8</td><td rowspan=1 colspan=1>20</td><td rowspan=1 colspan=1>13.4255</td><td rowspan=1 colspan=1>3.01262</td></tr><tr><td rowspan=1 colspan=1>Ave. % notes per segment</td><td rowspan=1 colspan=1>47</td><td rowspan=1 colspan=1>3.33</td><td rowspan=1 colspan=1>14.03</td><td rowspan=1 colspan=1>8.0345</td><td rowspan=1 colspan=1>2.21843</td></tr><tr><td rowspan=1 colspan=1>% lower notes</td><td rowspan=1 colspan=1>47</td><td rowspan=1 colspan=1>.13</td><td rowspan=1 colspan=1>.92</td><td rowspan=1 colspan=1>.4193</td><td rowspan=1 colspan=1>.18526</td></tr><tr><td rowspan=1 colspan=1>Ave. semitonal distance F = 0</td><td rowspan=1 colspan=1>47</td><td rowspan=1 colspan=1>2.25</td><td rowspan=1 colspan=1>7.59</td><td rowspan=1 colspan=1>4.2084</td><td rowspan=1 colspan=1>1.12561</td></tr><tr><td rowspan=1 colspan=1>Decibel Mean</td><td rowspan=1 colspan=1>47</td><td rowspan=1 colspan=1>-21.13</td><td rowspan=1 colspan=1>-3.48</td><td rowspan=1 colspan=1>-8.4342</td><td rowspan=1 colspan=1>2.93311</td></tr><tr><td rowspan=1 colspan=1>Decibel SD</td><td rowspan=1 colspan=1>47</td><td rowspan=1 colspan=1>3.88</td><td rowspan=1 colspan=1>9.11</td><td rowspan=1 colspan=1>6.4495</td><td rowspan=1 colspan=1>1.30352</td></tr></table>

演讲成绩。本研究中作为因变量的演讲是学期末的最终演讲，形式为5分钟的特殊场合演讲（例如祝酒词、悼词、纪念词；$n = 140$，$\mathrm{Max} = 110$，$\mathrm{Min} = 74$，$M_{\text{score}} = 100.37$，$SD_{\text{score}} = 7.18$）。演讲由九位经过培训的研究生讲师进行评分。得分基于两个主要元素：书面大纲的质量，包括演讲内容和参考文献，以及表现质量，评估各项特征，包括音量和语速、眼神接触、姿态以及手势。由于研究表明练习和反馈对演讲的内容和表达两个方面均会产生影响（Pearson et al., 2006；Seibold et al., 1993），我们在分析中包含了两个得分。

# 附加措施

虚拟现实体验。虚拟现实体验（Hartmann等，2010）使用五个项目通过一到五的评分量表来测量与虚拟环境的体验，样本量 $n = 132$ ，均值 $M = 2.90$，标准差 $SD = 0.79$。较高的分数表示更多的体验。任务评估。我们使用了内在动机清单（IMI；Deci等，1994）的子量表，包括兴趣/享受 $\mathbf{\check{a}} = .82$，五个项目，均值 $M = 6.45$，标准差 $SD = 1.23$，价值/有用性 $\mathsf{a} = .94$ 六个项目，均值 $M = 6.51$，标准差 $SD = 1.42 { \it \Omega }$，以及努力/重要性 $\mathrm{\Phi} ( \mathrm{a} = .80$，六个项目，均值 $M = 5.50$，标准差 $SD = 1.20 { \it \Psi }$），测量使用八点量表。空间存在感。我们使用了空间存在体验量表（SPES；Hartmann等，2016）的简短形式，该量表包含四个项目，评估虚拟环境的真实感和沉浸感，评分范围从一到七（ $\mathrm{\Phi} [ \mathrm{a} = .88$，均值 $M = 5.28$，标准差 $SD = 1.08 { \mathrm{\Omega} }$。

# 结果

首先，检查了所有变量之间的相关性（表 2 和表 3）。年龄、性别与语言成绩之间没有显著相关性。然而，考虑到以往研究表明性别对语言成绩有影响，我们在分析中保留了性别这一变量。

<table><tr><td rowspan=1 colspan=5>TABLE 2Study 1 Correlation Between Outcomes and Potential Control Variables</td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>Age</td><td rowspan=1 colspan=1>Gender</td><td rowspan=1 colspan=1>Anxiety</td><td rowspan=1 colspan=1>FNE</td></tr><tr><td rowspan=1 colspan=1>Age</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Gender</td><td rowspan=1 colspan=1>-.05</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Anxiety</td><td rowspan=1 colspan=1>-.05</td><td rowspan=1 colspan=1>.14</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>FNE</td><td rowspan=1 colspan=1>-.05</td><td rowspan=1 colspan=1>.15</td><td rowspan=1 colspan=1>.59**</td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Speech grades</td><td rowspan=1 colspan=1>.07</td><td rowspan=1 colspan=1>.13</td><td rowspan=1 colspan=1>-.13</td><td rowspan=1 colspan=1>.06</td></tr></table>

$^{**} p < .05, ^{*} p < .01$ $^{**} p < .05, ^{*} p < .01$。注：上标表示具有语音等级的 $n_{cors}$。A: $n = 45$，B: $n = 30$，C: $n = 81$，D: $n = 54$。

<table><tr><td rowspan=1 colspan=16>TABLE 3Study 1 Correlations Between Performance Variables</td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>2</td><td rowspan=1 colspan=1>3</td><td rowspan=1 colspan=1>4</td><td rowspan=1 colspan=1>5</td><td rowspan=1 colspan=1>6</td><td rowspan=1 colspan=1>7</td><td rowspan=1 colspan=1>8</td><td rowspan=1 colspan=1>9</td><td rowspan=1 colspan=1>10</td><td rowspan=1 colspan=1>11</td><td rowspan=1 colspan=1>12</td><td rowspan=1 colspan=1>13</td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>Sp. grades</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=4 colspan=1>Visual(n =67)</td><td rowspan=1 colspan=1>2</td><td rowspan=1 colspan=1>Front left</td><td rowspan=1 colspan=1>.20</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>3</td><td rowspan=1 colspan=1>Front right</td><td rowspan=1 colspan=1>.00</td><td rowspan=1 colspan=1>-.09</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>4</td><td rowspan=1 colspan=1>Back lefta</td><td rowspan=1 colspan=1>-.08</td><td rowspan=1 colspan=1>.51**</td><td rowspan=1 colspan=1>.01</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>5</td><td rowspan=1 colspan=1>Back right</td><td rowspan=1 colspan=1>-.34*</td><td rowspan=1 colspan=1>-.14</td><td rowspan=1 colspan=1>.39**</td><td rowspan=1 colspan=1>.40**</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=4 colspan=1>Verbal(n = 47)</td><td rowspan=1 colspan=1>6</td><td rowspan=1 colspan=1># mono. seg.8</td><td rowspan=1 colspan=1>.03</td><td rowspan=1 colspan=1>.17</td><td rowspan=1 colspan=1>-.27</td><td rowspan=1 colspan=1>.24</td><td rowspan=1 colspan=1>-.08</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>7</td><td rowspan=1 colspan=1>% fund. tone8</td><td rowspan=1 colspan=1>-.38*</td><td rowspan=1 colspan=1>-.04</td><td rowspan=1 colspan=1>-.22</td><td rowspan=1 colspan=1>.12</td><td rowspan=1 colspan=1>-.07</td><td rowspan=1 colspan=1>.55**</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>8</td><td rowspan=1 colspan=1>dB MB</td><td rowspan=1 colspan=1>.26</td><td rowspan=1 colspan=1>.18</td><td rowspan=1 colspan=1>.23</td><td rowspan=1 colspan=1>-.07</td><td rowspan=1 colspan=1>-.03</td><td rowspan=1 colspan=1>-.22</td><td rowspan=1 colspan=1>-.37*</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>9</td><td rowspan=1 colspan=1>dB SD</td><td rowspan=1 colspan=1>.06</td><td rowspan=1 colspan=1>.12</td><td rowspan=1 colspan=1>.35*</td><td rowspan=1 colspan=1>.08</td><td rowspan=1 colspan=1>.16</td><td rowspan=1 colspan=1>-.39**</td><td rowspan=1 colspan=1>-.45**</td><td rowspan=1 colspan=1>.05</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=5 colspan=1>Scales(n = 110)</td><td rowspan=1 colspan=1>10</td><td rowspan=1 colspan=1>IMI Int/Enjc</td><td rowspan=1 colspan=1>.02</td><td rowspan=1 colspan=1>.01</td><td rowspan=1 colspan=1>.13</td><td rowspan=1 colspan=1>.00</td><td rowspan=1 colspan=1>.31*</td><td rowspan=1 colspan=1>.16</td><td rowspan=1 colspan=1>-.11</td><td rowspan=1 colspan=1>.08</td><td rowspan=1 colspan=1>-.08</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>11</td><td rowspan=1 colspan=1>IMI Val/Use</td><td rowspan=1 colspan=1>.07</td><td rowspan=1 colspan=1>.01</td><td rowspan=1 colspan=1>.24</td><td rowspan=1 colspan=1>.04</td><td rowspan=1 colspan=1>.31*</td><td rowspan=1 colspan=1>.28</td><td rowspan=1 colspan=1>-.07</td><td rowspan=1 colspan=1>-.05</td><td rowspan=1 colspan=1>.08</td><td rowspan=1 colspan=1>.74**</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>12</td><td rowspan=1 colspan=1>IMI Eff/Impc</td><td rowspan=1 colspan=1>.11</td><td rowspan=1 colspan=1>-.03</td><td rowspan=1 colspan=1>.12</td><td rowspan=1 colspan=1>-.03</td><td rowspan=1 colspan=1>.27*</td><td rowspan=1 colspan=1>.02</td><td rowspan=1 colspan=1>-.28</td><td rowspan=1 colspan=1>.16</td><td rowspan=1 colspan=1>.17</td><td rowspan=1 colspan=1>.59**</td><td rowspan=1 colspan=1>.66**</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>13</td><td rowspan=1 colspan=1>PRPSA T2D</td><td rowspan=1 colspan=1>-.32*</td><td rowspan=1 colspan=1>.28</td><td rowspan=1 colspan=1>.12</td><td rowspan=1 colspan=1>.16</td><td rowspan=1 colspan=1>.12</td><td rowspan=1 colspan=1>-.21</td><td rowspan=1 colspan=1>-.17</td><td rowspan=1 colspan=1>-.05</td><td rowspan=1 colspan=1>.43*</td><td rowspan=1 colspan=1>-.15</td><td rowspan=1 colspan=1>.05</td><td rowspan=1 colspan=1>-.04</td><td rowspan=1 colspan=1>--</td></tr><tr><td rowspan=1 colspan=1>14</td><td rowspan=1 colspan=1>FNES T2D</td><td rowspan=1 colspan=1>-.07</td><td rowspan=1 colspan=1>.13</td><td rowspan=1 colspan=1>-.11</td><td rowspan=1 colspan=1>.05</td><td rowspan=1 colspan=1>.09</td><td rowspan=1 colspan=1>-.10</td><td rowspan=1 colspan=1>-.22</td><td rowspan=1 colspan=1>.02</td><td rowspan=1 colspan=1>.22</td><td rowspan=1 colspan=1>.09</td><td rowspan=1 colspan=1>.12</td><td rowspan=1 colspan=1>-.04</td><td rowspan=1 colspan=1>.69**</td></tr></table>

接下来，进行了一系列 $\mathrm { t }$ -检验，检查参与虚拟现实实验的参与者与未参与者在初始 PRPSA、FNES 或虚拟现实体验方面是否存在差异。这些变量在各组之间没有显著差异（所有 $t < 1 . 0 0$；所有 $p > . 0 5$）。两个组中所有参与者的 $9 5 \%$ 置信区间重叠，等效检验显示两组之间在 $\Delta = . 3 0$（Cohen's $d$）和 $\Delta = . 1 6$ 下均无显著差异（见表 4）。

<table><tr><td rowspan=1 colspan=8>TABLE 4Study 1 Descriptive Statistics at Time 1 by Group and Equivalence Tests by Condition</td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=2>VR(n =72)</td><td rowspan=1 colspan=1>No VR (n = 60)</td><td rowspan=1 colspan=1>No VR (n = 60)</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>M</td><td rowspan=1 colspan=1>SD</td><td rowspan=1 colspan=1>M</td><td rowspan=1 colspan=1>SD</td><td rowspan=1 colspan=1>t</td><td rowspan=1 colspan=1>df</td><td rowspan=1 colspan=1>p</td></tr><tr><td rowspan=1 colspan=1>PRPSA T1</td><td rowspan=1 colspan=1>3.27</td><td rowspan=1 colspan=1>.54</td><td rowspan=1 colspan=1>3.29</td><td rowspan=1 colspan=1>.53</td><td rowspan=1 colspan=1>0.19</td><td rowspan=1 colspan=1>174</td><td rowspan=1 colspan=1>.001</td></tr><tr><td rowspan=1 colspan=1>FNES T1</td><td rowspan=1 colspan=1>3.19</td><td rowspan=1 colspan=1>.75</td><td rowspan=1 colspan=1>3.25</td><td rowspan=1 colspan=1>.79</td><td rowspan=1 colspan=1>0.41</td><td rowspan=1 colspan=1>174</td><td rowspan=1 colspan=1>.002</td></tr><tr><td rowspan=1 colspan=1>VR Experience T1</td><td rowspan=1 colspan=1>2.89</td><td rowspan=1 colspan=1>.72</td><td rowspan=1 colspan=1>2.91</td><td rowspan=1 colspan=1>.87</td><td rowspan=1 colspan=1>-0.01</td><td rowspan=1 colspan=1>174</td><td rowspan=1 colspan=1>.001</td></tr></table>

报道的测试结果为 Cohen's ${ \mathsf { d } } = . 3 0$，显著结果表示置信区间重叠。

为了检验我们的核心研究问题，我们使用了分层回归，将学期末演讲的得分作为结果变量（见表5）。所有报告的回归系数均为标准化值。在第1步中输入了人口统计数据，第2步中输入了公共演讲焦虑量表（PRPSA）、社交焦虑（FNE）和虚拟现实（VR）中的先前经验，第3步中加入了条件（是否使用VR）。在第1步中，年龄和性别对最终得分均没有显著影响。在第2步中，第三次也是最后一次演讲的得分变异通过PRPSA进行预测，即公共演讲焦虑较高的学生在演讲中的得分较低，$\beta = - . 2 5$ $t = - 2 . 4 0$ , $\mathbf { \nabla } p = . 0 2$；然而，整体模型并不显著。在最终模型中，PRPSA仍然是表现的重要负向预测因子，$\beta = - . 2 5$ $t = - 2 . 4 1$ , $p = . 0 2$，而在VR中练习则是最终演讲成绩的重要正向预测因子，$\beta = . 2 0 7$ $t = 2 . 4 0 , p = . 0 2$。整体模型显著，$F \left( 6 , 1 3 0 \right) = 2 . 6 2$ , $p = . 0 2$。结果可见于表5。请注意，VR参与反映了学生是否在VR中练习了演讲（练习 $= 1$，未练习 $= 0$）。

<table><tr><td rowspan=1 colspan=9>TABLE 5Study 1 Hierarchical Regression Predicting Final Speech Grades</td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>β</td><td rowspan=1 colspan=1>SE</td><td rowspan=1 colspan=1>t</td><td rowspan=1 colspan=1>p</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Step 1</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>F</td><td rowspan=1 colspan=1>df</td><td rowspan=1 colspan=1>p</td><td rowspan=1 colspan=1>adj R²</td></tr><tr><td rowspan=1 colspan=1>Age</td><td rowspan=1 colspan=1>.08</td><td rowspan=1 colspan=1>.49</td><td rowspan=1 colspan=1>.87</td><td rowspan=1 colspan=1>.38</td><td rowspan=1 colspan=1>1.62</td><td rowspan=1 colspan=1>2,128</td><td rowspan=1 colspan=1>.20</td><td rowspan=1 colspan=1>.01</td></tr><tr><td rowspan=1 colspan=1>Gender</td><td rowspan=1 colspan=1>.14</td><td rowspan=1 colspan=1>1.27</td><td rowspan=1 colspan=1>1.63</td><td rowspan=1 colspan=1>.11</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Step 2</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>F</td><td rowspan=1 colspan=1>df</td><td rowspan=1 colspan=1>p</td><td rowspan=1 colspan=1>adj R²2</td></tr><tr><td rowspan=1 colspan=1>Age</td><td rowspan=1 colspan=1>.07</td><td rowspan=1 colspan=1>.48</td><td rowspan=1 colspan=1>.83</td><td rowspan=1 colspan=1>.41</td><td rowspan=1 colspan=1>1.87</td><td rowspan=1 colspan=1>5,125</td><td rowspan=1 colspan=1>.10</td><td rowspan=1 colspan=1>.03</td></tr><tr><td rowspan=1 colspan=1>Gender</td><td rowspan=1 colspan=1>.16</td><td rowspan=1 colspan=1>1.31</td><td rowspan=1 colspan=1>1.79</td><td rowspan=1 colspan=1>.08</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>PRPSA T1</td><td rowspan=1 colspan=1>-.25</td><td rowspan=1 colspan=1>1.47</td><td rowspan=1 colspan=1>-2.40</td><td rowspan=1 colspan=1>.02</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>FNES T1</td><td rowspan=1 colspan=1>.18</td><td rowspan=1 colspan=1>1.02</td><td rowspan=1 colspan=1>1.69</td><td rowspan=1 colspan=1>.09</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>VR Exp</td><td rowspan=1 colspan=1>.04</td><td rowspan=1 colspan=1>.81</td><td rowspan=1 colspan=1>.43</td><td rowspan=1 colspan=1>.67</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Step 3</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>F</td><td rowspan=1 colspan=1>df</td><td rowspan=1 colspan=1>p</td><td rowspan=1 colspan=1>adj R²2</td></tr><tr><td rowspan=1 colspan=1>Age</td><td rowspan=1 colspan=1>.08</td><td rowspan=1 colspan=1>.47</td><td rowspan=1 colspan=1>.92</td><td rowspan=1 colspan=1>.36</td><td rowspan=1 colspan=1>2.62</td><td rowspan=1 colspan=1>6,124</td><td rowspan=1 colspan=1>.02</td><td rowspan=1 colspan=1>.07</td></tr><tr><td rowspan=1 colspan=1>Gender</td><td rowspan=1 colspan=1>2.19</td><td rowspan=1 colspan=1>1.29</td><td rowspan=1 colspan=1>1.70</td><td rowspan=1 colspan=1>.09</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>PRPSA T1</td><td rowspan=1 colspan=1>-.25</td><td rowspan=1 colspan=1>1.44</td><td rowspan=1 colspan=1>-2.40</td><td rowspan=1 colspan=1>.02</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>FNES T1</td><td rowspan=1 colspan=1>.19</td><td rowspan=1 colspan=1>1.01</td><td rowspan=1 colspan=1>1.85</td><td rowspan=1 colspan=1>.07</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>VR Exp</td><td rowspan=1 colspan=1>.04</td><td rowspan=1 colspan=1>.8</td><td rowspan=1 colspan=1>.46</td><td rowspan=1 colspan=1>.65</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>VR Participation</td><td rowspan=1 colspan=1>.21</td><td rowspan=1 colspan=1>1.24</td><td rowspan=1 colspan=1>2.44</td><td rowspan=1 colspan=1>.02</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr></table>

为了确定虚拟现实训练对公众演讲焦虑的影响，我们考察了演讲焦虑、对负面评价的恐惧与虚拟现实体验量表之间的相关性，包括空间存在感、内在享受、价值感和努力程度。除了演讲焦虑与对负面评价恐惧之间存在强正相关关系 $( r = . 6 5 , p < . 0 0 1 )$ 外，没有发现显著关系。最后，为了考察方案反馈在演讲表现中的作用，进行了分层回归分析，以方案反馈变量预测最终演讲得分。年龄和性别为 2 $( F ( 1 5 , 2 6 ) = 2 . 0 8, p = . 1 1 )$，而且只有一个虚拟现实反馈参数，即注视右后象限的时间 $( \beta = - . 9 5, S E = . 1 1, p = . 0 2 )$，显著预测了演讲表现。

# 讨论

研究1发现，虚拟现实训练在控制参与评分后，对演讲评分有正向预测。然而，我们并未发现虚拟现实练习或反馈对公共演讲焦虑（PSA）或社交焦虑（FNE）有显著影响，这与过去的研究结果可能暗示的相反；此外，我们也没有发现任务兴趣、存在感或反馈与最终成绩之间存在显著关系。最后，鉴于研究设计，我们无法排除参与者的选择效应。例如，动机或潜在的学术能力可能同时预测实验室出席率和演讲评分。因此，我们在随后的研究中尝试复制研究1的发现。为了解决自我选择的问题，在研究2中，我们随机分配学生进行虚拟现实练习、视频条件练习或镜子前练习，以比较不同的练习方法。我们还纳入了自我意识、自我效能、任务难度和任务需求，这些因素都被提出作为虚拟现实演讲改善的潜在机制，但未经过实证测试（例如，Davis等，2020；Frisby等，2020）。我们保留了研究1中的空间存在感、内在动机、社交焦虑（FNE）和虚拟现实经验。

# 研究二

# 方法

参与者。我们招募了在 T1 注册的学生 $\overset { \cdot } { n } = 371$，$n = 234$，他们同意公开自己的成绩，其中女性占 $51.3\%$，平均年龄 $M_{年龄} = 20.23$，年龄标准差 $SD_{年龄} = 1.20$，这些学生来自不同学期的相同入门沟通课程。纳入研究 2 的所有学生均未参与研究 1。所有的保留和补偿程序与研究 1 完全相同，并已获得同一机构审查委员会的批准。

# 过程

在研究2中，参与者在到达实验室后被随机分配到三种条件之一进行演讲练习。他们要么在与研究1相同的虚拟现实条件下练习，要么在视频条件下，或者在镜子前面进行练习。在视频条件下，使用了一台Alienware 15R4笔记本电脑，用于录制学生练习演讲的过程。参与者在演讲时可以看到自己在屏幕上，但不需要在之后观看录制内容。在镜子条件下，使用了一面5英尺高的画架镜子（参照Dermody & Sutherland，2019年）。虽然我们记录了未参加演讲实验室的人的成绩，但只有那些到实验室的参与者完成了下面描述的自我报告量表。

# 措施

对负面评价的恐惧（Leary, 1983；$n = 234$，$\alpha = .84$，$M = 35.86$，$SD = 8.39$）和虚拟现实体验（Hartmann et al., 2010；$n = 234$，$\alpha = .86$，$M = 28.84$，$SD = 0.91$）在研究1中被保留，内在动机量表中的兴趣/乐趣子量表（$n = 180$，$\alpha = .82$，$M = 6.11$，$SD = 1.66$）、价值/有用性（$n = 180$，$\alpha = .96$，$M = 6.97$，$SD = 1.84$）和努力/重要性（$n = 180$，$\alpha = .81$，$M = 5.76$，$SD = 1.64$；Deci et al., 1994）在T2实验室练习后收集，尽管在研究2中采用了九点量表。空间存在体验量表（SPES，Hartmann et al., 2016；$n = 114$，$\alpha = .90$，$M = 4.79$，$SD = 1.23$）仅针对虚拟现实组收集。演讲成绩的收集方式与研究1相似（$n = 371$，$M = 93.02$，$SD = 19.91$）。我们在研究2中没有检查来自虚拟现实环境的反馈。关于研究2的新测量方法将在下文讨论。个人公共演讲焦虑报告。在研究2中，我们使用了PRPSA的18项版本（Mörtberg et al., 2018；$n = 242$，$\alpha = .93$，$M = 48.76$，$SD = 14.46$），以应对参与者疲劳问题。

状态-特质焦虑量表。采用Tluczek等（2009）验证的状态-特质焦虑量表（STAI；Spielberger等，1983）六项版本，在T1（$n = 237$，$\alpha = .87$，$M = 51.36$，$SD = 13.44$）和T2（$n = 253$，$\alpha = .82$，$M = 40.63$，$SD = 12.09_{.}$）中使用。该量表测量参与者感到平静、满足、放松、紧张（反向）、不安（反向）和担忧（反向）的程度，评分范围为1（完全不）到4（非常）。量表的得分通过对所有项目（反向编码修正后）求和，乘以20并除以6来计算。高分表示较少的焦虑。 罗森伯格自尊量表。参与者在T1完成了10项罗森伯格自尊（RSE）量表（Rosenberg，1965），该量表测量特质自尊，评分范围为1（强烈同意）到4（强烈不同意）。RSE的得分通过对各项目求和（反向编码修正后；$n = 234$，$\alpha = .90$，$M = 35.44$，$SD = 5.47_{.}$）得出。 自我意识量表。Scheier和Carver（2013）修订的自我意识量表（SCS-R；$n = 236$，$\alpha = .84$，$M = 2.63$，$SD = 0.45$）仅在T1进行测量。该量表包含21个项目，要求参与者表明在各种社交和私人情境中感到紧张、焦虑和/或自我意识的程度。项目评分范围为1（完全不像我）到4（非常像我）。量表得分为所有项目的均值，高分表示更强的自我意识。 演讲信心个人报告。修改版的演讲者信心个人报告（MRPCS；Pertaub等，2001）中的躯体量表在T2对VR条件下的参与者进行测量，$n = 259$，$\alpha = .87$，$M = 1.50$，$SD = 0.52$。该量表包含八个项目（例如，我感到胃部不适），评分范围从1（完全不）到4（非常）。高分表示说话时的恐惧感更强。

NASA任务负荷指数。NASA任务负荷指数（NASA-TLX；Hart & Staveland，1988）仅在T2中进行测量。该量表包含10个条目，经过调整以询问体验的各个要素的要求程度，参与者在1（非常低）到7（非常高）的范围内进行回答。该量表的10个条目取平均值，得分越高表示任务负荷越大。我们重复该量表两次，以评估演讲交付体验的任务负荷（即，他们在实验室的体验；$n = 180$，$\alpha = .71$，$M = 3.39$，$SD = 1.00$），然后再次评估练习演讲内容的任务负荷（即，他们在记忆演讲及主题方面的舒适程度；$n = 180$，$\alpha = .73$，$M = 3.33$，$SD = 1.02$）。认知需求。我们调整了Bowman等人（2018）的认知需求子量表（$n = 30$，$\alpha = .85$，$M = 3.92$，$SD = 1.08$），以评估在实验室练习演讲所需的心理注意力和深度思考的程度（例如：“练习我的演讲让我调动了所有的心理资源”），评分范围为1（强烈不同意）到7（强烈同意）。该量表为七个条目的平均值，高分表明练习演讲需要更多的认知资源。

# 结果

表6和表7中报告了l测量的相关性。与研究1一样，性别和年龄与演讲成绩没有相关性，但仍然保留用于分析。为了评估实验室实践条件在演讲成绩中的作用，我们进行了单因素方差分析（VR vs. 视频 vs. 镜子 vs. 无实验室），并使用事后Bonferroni检验查看不同条件下演讲成绩是否存在差异。方差分析结果显著，$F(3, 367) = 2.96$，$p = .03$，$\eta^{2} = .02$，VR组$n = 115$，$M = 95.24$，$S D = 16.91$，镜子组$[n = 101$，$M = 95.39$，$S D = 12.10$，视频组${\dot{n}} = 45$，$M = 94.80$，$S D = 13.63$，与未参加实验室的$n = 261$，$M = 50.24$，$S D = 6.43$的组相比，得分更高，但VR、镜子和视频练习条件之间的逐对差异并不显著。

<table><tr><td rowspan=1 colspan=6>TABLE 6Study 2 Correlations Between Speech Grades and Potential Controls</td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>Speech Grade</td><td rowspan=1 colspan=1>Age</td><td rowspan=1 colspan=1>Gender</td><td rowspan=1 colspan=1>PRPSA</td><td rowspan=1 colspan=1>STAI</td></tr><tr><td rowspan=1 colspan=1>Age</td><td rowspan=1 colspan=1>-.01</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Gender</td><td rowspan=1 colspan=1>.01</td><td rowspan=1 colspan=1>-.04</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>PRPSA</td><td rowspan=1 colspan=1>.02</td><td rowspan=1 colspan=1>.00</td><td rowspan=1 colspan=1>.19**</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>STAI</td><td rowspan=1 colspan=1>.08</td><td rowspan=1 colspan=1>-.01</td><td rowspan=1 colspan=1>.23**</td><td rowspan=1 colspan=1>.82**</td><td rowspan=1 colspan=1>--</td></tr><tr><td rowspan=1 colspan=1>SCR</td><td rowspan=1 colspan=1>-.02</td><td rowspan=1 colspan=1>-.05</td><td rowspan=1 colspan=1>.18**</td><td rowspan=1 colspan=1>.39**</td><td rowspan=1 colspan=1>.37**</td></tr></table>

*p < .05，**p < .01 ${ \mathsf { S T A l } } =$ 状态-特质焦虑量表；$M { \sf R P C S } =$ 个人报告的演讲者信心；$\left| \mathsf { M } \right| =$ 内在动机量表

<table><tr><td rowspan=1 colspan=11>TABLE 7Study 2 Correlations Between Performance Variables</td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>Speechrades</td><td rowspan=1 colspan=1>SPRES</td><td rowspan=1 colspan=1>STAIT2</td><td rowspan=1 colspan=1>MRPCS</td><td rowspan=1 colspan=1>Sat.</td><td rowspan=1 colspan=1>NASATLXDem.</td><td rowspan=1 colspan=1>NASATLXReh.</td><td rowspan=1 colspan=1>Demand</td><td rowspan=1 colspan=1>IMI Int/Enj</td><td rowspan=1 colspan=1>IMI Val/Use</td></tr><tr><td rowspan=1 colspan=1>SPRES</td><td rowspan=1 colspan=1>-.08</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>STAI6 T2</td><td rowspan=1 colspan=1>.17**</td><td rowspan=1 colspan=1>-.11</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>MRPCS</td><td rowspan=1 colspan=1>.13*</td><td rowspan=1 colspan=1>-.04</td><td rowspan=1 colspan=1>.74**</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Sat.</td><td rowspan=1 colspan=1>-.01</td><td rowspan=1 colspan=1>.14</td><td rowspan=1 colspan=1>-.34**</td><td rowspan=1 colspan=1>-.23**</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>NASA TLX Dem.</td><td rowspan=1 colspan=1>.17*</td><td rowspan=1 colspan=1>.06</td><td rowspan=1 colspan=1>.41**</td><td rowspan=1 colspan=1>.41**</td><td rowspan=1 colspan=1>-.36**</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>NASA TLX Reh.</td><td rowspan=1 colspan=1>.07</td><td rowspan=1 colspan=1>-.01</td><td rowspan=1 colspan=1>.44**</td><td rowspan=1 colspan=1>.37**</td><td rowspan=1 colspan=1>-.33**</td><td rowspan=1 colspan=1>.74**</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Demand</td><td rowspan=1 colspan=1>.08</td><td rowspan=1 colspan=1>.17</td><td rowspan=1 colspan=1>.33**</td><td rowspan=1 colspan=1>.32**</td><td rowspan=1 colspan=1>-.22**</td><td rowspan=1 colspan=1>.65**</td><td rowspan=1 colspan=1>.63**</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>IMI Int/Enj</td><td rowspan=1 colspan=1>-.06</td><td rowspan=1 colspan=1>.43**</td><td rowspan=1 colspan=1>-.17*</td><td rowspan=1 colspan=1>-.07</td><td rowspan=1 colspan=1>.28**</td><td rowspan=1 colspan=1>-.09</td><td rowspan=1 colspan=1>-.07</td><td rowspan=1 colspan=1>.11</td><td rowspan=1 colspan=1>--</td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>IMI Val/Use</td><td rowspan=1 colspan=1>.01</td><td rowspan=1 colspan=1>.43**</td><td rowspan=1 colspan=1>-.13</td><td rowspan=1 colspan=1>-.15*</td><td rowspan=1 colspan=1>.23**</td><td rowspan=1 colspan=1>-.06</td><td rowspan=1 colspan=1>-.06</td><td rowspan=1 colspan=1>.18*</td><td rowspan=1 colspan=1>.69**</td><td rowspan=1 colspan=1>--</td></tr><tr><td rowspan=1 colspan=1>IME Eff/mp</td><td rowspan=1 colspan=1>-.08</td><td rowspan=1 colspan=1>.28*</td><td rowspan=1 colspan=1>.10</td><td rowspan=1 colspan=1>.08</td><td rowspan=1 colspan=1>.29**</td><td rowspan=1 colspan=1>.06</td><td rowspan=1 colspan=1>.05</td><td rowspan=1 colspan=1>.22**</td><td rowspan=1 colspan=1>.64**</td><td rowspan=1 colspan=1>.52**</td></tr></table>

我们还检查了虚拟现实（VR）训练的潜在中介变量与演讲成绩之间的相关性。STAI-6、MRPCS和NASA-TLX的需求子量表与演讲成绩之间有显著相关。接下来，进行了单因素多变量方差分析（MANOVA），以检验实验条件（VR、镜子、视频）对后测指标（STAI-6、MRPCS、满意度、NASA-TLX、IMI）是否存在显著差异。在条件间观察到NASA-TLX交付分数的显著差异，$F(2, 177) = 7.75, p = 0.001, \eta^2 = 0.15$，以及NASA-TLX排练分数，$F(2, 78) = 4.29, \ L_{P} = 0.02, \eta^2 = 0$。在VR条件下的参与者 $\mathrm { ~ : ~ } n = 79, M = 3.68, SD = 0.94$，感知演讲交付的要求比在镜子条件下的参与者 $n = 68, M = 3.27, SD = 1.03$ 和视频条件下的参与者 $\mathbf { \bar { \rho } }_{ n } = 33, M = 2.94, SD = 0.88 \mathrm { \Omega }$ 更高。在VR条件下的参与者 $\mathbf { \chi }_{ M } = 3.52, SD = 0.97$ 认为排练比视频条件下的参与者 $M = 2.91, SD = 1.02$ 更困难。未观察到其他显著差异。最后，我们在参加实验的参与者中重复了从研究1中预测演讲成绩的回归分析 $\dot { \boldsymbol { n } } = 232$，且数据完整。年龄和性别在第一步中被输入，随后在第二步中输入自尊、演讲经验、PRPSA、STAI-T1、自我意识、FNES和VR经验。在第一步中，该模型并不显著，$F(2, 229) = 0.01, \ { p } = 0.98$；在第二步中，该模型同样不显著，$F(10, 221) = 0.73, \ { p } = 0.69$，并且没有显著的演讲成绩预测变量（见表8）。

<table><tr><td rowspan=1 colspan=10>TABLE 8Study 2 Hierarchical Regression Predicting Speech Scores of Lab Attendees</td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>β</td><td rowspan=1 colspan=1>SE</td><td rowspan=1 colspan=1>t</td><td rowspan=1 colspan=1>p</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Step 1</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>F</td><td rowspan=1 colspan=1>df</td><td rowspan=1 colspan=1>p</td><td rowspan=1 colspan=1>Adj. R²</td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>Age</td><td rowspan=1 colspan=1>-.01</td><td rowspan=1 colspan=1>.83</td><td rowspan=1 colspan=1>-.16</td><td rowspan=1 colspan=1>.88</td><td rowspan=1 colspan=1>.01</td><td rowspan=1 colspan=1>2,229</td><td rowspan=1 colspan=1>.98</td><td rowspan=1 colspan=1>.00</td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>Gender</td><td rowspan=1 colspan=1>.00</td><td rowspan=1 colspan=1>1.94</td><td rowspan=1 colspan=1>.06</td><td rowspan=1 colspan=1>.95</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Step 2</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>F</td><td rowspan=1 colspan=1>df</td><td rowspan=1 colspan=1>p</td><td rowspan=1 colspan=1>Adj. R²</td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>Age</td><td rowspan=1 colspan=1>.00</td><td rowspan=1 colspan=1>.84</td><td rowspan=1 colspan=1>-.06</td><td rowspan=1 colspan=1>.95</td><td rowspan=1 colspan=1>.72</td><td rowspan=1 colspan=1>10, 221</td><td rowspan=1 colspan=1>.69</td><td rowspan=1 colspan=1>.00</td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>Gender</td><td rowspan=1 colspan=1>-.04</td><td rowspan=1 colspan=1>2.12</td><td rowspan=1 colspan=1>-.61</td><td rowspan=1 colspan=1>.54</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>Formal exp.</td><td rowspan=1 colspan=1>.02</td><td rowspan=1 colspan=1>1.41</td><td rowspan=1 colspan=1>.32</td><td rowspan=1 colspan=1>.75</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>Informal exp.</td><td rowspan=1 colspan=1>-.04</td><td rowspan=1 colspan=1>.89</td><td rowspan=1 colspan=1>-.61</td><td rowspan=1 colspan=1>.54</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>PRPSA</td><td rowspan=1 colspan=1>-.13</td><td rowspan=1 colspan=1>.15</td><td rowspan=1 colspan=1>-1.01</td><td rowspan=1 colspan=1>.31</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>STAIT1</td><td rowspan=1 colspan=1>.20</td><td rowspan=1 colspan=1>.14</td><td rowspan=1 colspan=1>1.61</td><td rowspan=1 colspan=1>.11</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>SCS-R</td><td rowspan=1 colspan=1>-.07</td><td rowspan=1 colspan=1>2.75</td><td rowspan=1 colspan=1>-.90</td><td rowspan=1 colspan=1>.37</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>FNES</td><td rowspan=1 colspan=1>.06</td><td rowspan=1 colspan=1>.19</td><td rowspan=1 colspan=1>.74</td><td rowspan=1 colspan=1>.46</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>Self-esteem</td><td rowspan=1 colspan=1>-.02</td><td rowspan=1 colspan=1>.20</td><td rowspan=1 colspan=1>-.30</td><td rowspan=1 colspan=1>.76</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>VR Exp.</td><td rowspan=1 colspan=1>-.12</td><td rowspan=1 colspan=1>1.17</td><td rowspan=1 colspan=1>-1.70</td><td rowspan=1 colspan=1>.09</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr></table>

$N = 2 3 2$

# 讨论

在这篇论文中，我们呈现了两个研究的结果，实施了一种虚拟现实（VR）公共演讲模拟于基础沟通课程。研究1的结果支持VR练习与最终演讲评分之间存在适度关系，表明虚拟现实公共演讲体验可能是基础演讲课程的有益补充。然而，我们发现VR中的反馈表现和沉浸体验对演讲表现的影响无显著效应。因此，研究2试图揭示可能解释实验室练习效应的机制，并更严格地比较不同类型的技术辅助公共演讲练习，以考察虚拟观众对演讲成绩的影响。在研究2中，我们再次观察到实验室练习效应，即参加实验室的学生在演讲中的表现优于未参加实验室练习的学生。然而，与Davis等人（2020）的研究结果一致，与使用镜子自我观摩或视频录制等其他方法相比，VR在提高演讲成绩方面并没有特殊的实用性。我们确实发现，与其他练习模式相比，参与者感知到在VR中进行演讲和排练的要求更高，这可能支持基于计算机辅助社会活动（CASA）理论关于数字他者在模拟现实世界公共演讲中角色的论点。然而，对于焦虑、自我意识、对他人负面评价（FNE）或存在感等因素，并未发现类似的效应。

根据Vallade等人（2020）的研究，我们发现学生对这项研究感到兴奋，并渴望参与这一体验，部分原因是虚拟现实的创新性。因此，作为现有课程的一部分，虚拟平台可能是吸引学生进行实践的一种有效方式，而实践是提升演讲表现的关键因素。对公共演讲教师而言，实践的重要性并不让人感到意外（例如，Lucas，2015），并且与多项研究的发现相吻合（例如，Farris等，2013；Pearson等，2006；Pearson等，2008；Smith & Frymier，2006）。然而，正如Menzel和Carrell（1994）以及上述其他研究所暗示的，实践的数量和类型都很重要。虚拟现实实践所带来的新颖性与其日益增加的需求可能最终会随着时间的推移，比其他干预方法更有效地提高公共演讲得分；然而，这一假设在我们的结果中并未得到支持。不过，我们的结果存在几个局限性。首先，与Frisby等人（2020）类似，许多学生报告由于各种原因（例如，文档中字体过小、虚拟现实耳机中没有眼镜等）在虚拟教室中观看幻灯片或笔记时遇到困难，这可能妨碍了虚拟观众练习环节的有效性，或增加了我们观察到的需求得分。相关地，在进行参与者实验时，我们遇到了一些技术问题。例如，一些参与者没有声音被录入，或其表现没有得到评分。这些技术问题可能会减少课堂上创新的有效性。关于我们的软件，最后一点，尽管虚拟现实模拟器中的观众对演讲者表现出兴趣和热情，但我们没有对虚拟观众进行逐秒控制。未来的工作应使用更敏感的评估方法来评估使用此类软件的演讲者。其次，我们对反馈的关注度很低。很少有学生关注虚拟反馈（Book，1985；Bourhis & Allen，1998），我们建议未来对此项目的迭代考虑由经过培训的公共演讲教师提供量身定制的反馈。或者，可以让参与者有机会与能够解读反馈的第三方一起审视他们的自动反馈得分。在我们的案例中，我们依赖虚拟观众提供类似的反馈。然而，与Chollet等人（2015）相比，被动呈现的反馈和观众在课堂上使用的效果有限。第三，虽然视频和镜子条件是对比模拟和数字环境中看自己进行演讲的效果，但视频条件并没有反映出参与者与镜子条件下的相同视觉表现。例如，视频只允许参与者看到自己从胸部到上面的部分，而镜子则反映出其从头到脚的全身。未来的研究应确保视频和镜子能捕捉到相同数量的参与者身体，以便在两种条件之间更好地控制，并更好地分析为什么这种类型的练习与虚拟练习似乎都产生类似的效果。最后，正如我们在研究1的讨论中所指出的，演讲成绩可能受到学生动机或非实验室实践（例如，之前的演讲）的影响。这些混杂因素在学生群体的演讲实验评估中很常见（例如，Davis等，2020；Frisby等，2020），并在课堂上进行实验室研究时难以避免；然而，我们指出这些因素可能会限制我们发现的普遍适用性。尽管存在这些局限性，我们注意到学生普遍喜欢虚拟现实课程，认为它们有价值，并且可能作为实践工具具有实用性。这与Vallade等人（2020）在课堂上虚拟现实技术接受模型的发现一致，表明在公共演讲培训中引入这项技术可能具有很大效用。然而，我们尚未看到在基础沟通课程中广泛采用虚拟现实公共演讲模拟器，或许是由于使用更便宜且更易获取的硬件所得到的相当结果。缺乏虚拟现实采用的原因有很多，其中一些与技术相关（例如，硬件成本过高、延迟过大以及早期版本的虚拟现实模拟器像素化问题），还有一些则与教师或学生缺乏兴趣或经验有关。然而，技术的进步可能使虚拟现实系统在小额投资下变得日益可及。与此同时，教师培训和雇佣成本在增加，能够与学生花费数小时提供个性化反馈的能力可能有限。因此，虚拟现实系统可能提供一种真实的实践和个性化反馈的结合，这对基础沟通课程和增强教师的反馈可能是有利的。本研究的目标是说明将虚拟现实实践纳入大型入门公共沟通课程的实用性。总体而言，我们的研究发现将虚拟现实作为一种教学工具来提高公共演讲技能的效果有限。与我们的预期相反，我们并未发现单次虚拟现实实践能显著提高公共演讲成绩，反而发现面对镜子或自我录制的练习可能与沉浸式虚拟环境带来的好处相当。此外，我们基于以往文献所检验的潜在机制也未与后续的演讲成绩有明确关联。然而，由于本研究是在现有基础演讲课程中进行的准实验，限制了我们从这些结果中推广。因此，我们敦促该领域的研究者将我们的结果视为纳入虚拟现实到公共演讲课堂的起点，而非终点。

# References

Allen, M., & Bourhis, J. (1996). The relationship of communication apprehension to communication behavior: A meta-analysis. Communication Quarterly, 44, 214226. https://doi.org/10.1080/ 01463379609370011   
Allen, M., Hunter, J. E., & Donohue, W. A. (1989). Meta-analysis of self-report data on the effectiveness of public speaking anxiety treatment techniques. Communication Education, 38, 5476. https://doi. org/10.1080/03634528909378740   
Batrinca, L., Stratou, G., Shapiro, A., Morency, L. P., & Scherer, S. (2013, August). Cicero-towards a multimodal virtual audience platform for public speaking training. In International Workshop on Intelligent Virtual Agents, 116128. Springer, Berlin, Heidelberg. https://doi.org/10.1007/978-3-642- 40415-3_10   
Blom K. J. (2018). Virtual Orator [Computer Software]. publicspeaking.tech.   
Bodie, G. D. (2010). A racing heart, rattling knees, and ruminative thoughts: Defining, explaining, and treating public speaking anxiety. Communication Education, 59, 70-105. https://doi. org/10.1080/03634520903443849   
Book, C. L. (1985). Providing feedback: The research on effective oral and writen feedback strategies. Communication Studies, 36(12), 1423. https://doi.org/10.1080/10510978509363195   
Bourhis, J. & Allen, M.(1998). The role of videotaped feedback in the instruction of public speaking: A quantitative synthesis of published empirical research. Communication Research Reports, 15(3), 256261. https://doi.org/10.1080/08824099809362121   
Bowman, N. D., Wasserman, J. & Banks, J. (2018). Development of the video game demand scale. In N. D. Bowman (Ed.), Video games: A medium that demands our attention. Routledge.   
Chollet, M., Wörtwein, T. Morency, L. P. Shapiro, A., & Scherer, S. (2015, September). Exploring feedback strategies to improve public speaking: An interactive virtual audience framework. In Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing (pp. 11431154). ACM. https://doi.org/10.1145/2750858.2806060   
Cohen, S. S. (1994). Speaking freely. Foreign Affairs, 73, 194197. https://doi.org/10.2307/20046818   
Curtis, K., Jones, G. J. & Campbell, N. (2015, November). Effects of good speaking techniques on audience engagement. In Proceedings of the 2015 ACM on International Conference on Multimodal Interaction (pp. 3542). ACM. https://doi.org/10.1145/2818346.2820766   
Davis A. LinvilD.L.Hoges L. F.Da Costa A. F. &Lee A.2.Virtu reali ver aceae practice: A study into situational apprehension and performance. Communication Education, 69(1), 70-84. https://doi.org/10.1080/03634523.2019.1684535   
Deci E. L. Eghrari, H. Patrick, B. C., & Leone, D. R. (1994). Facilitating internalization: The seldetermination theory perspective. Journal of Personality, 62, 119142. https://doi.org/10.1111/ j.1467-6494.1994.tb00797.x   
Dermody, F., Sutherland, A. (Feb. 2019). Practising public speaking: User responses to using a mirror versus a multimodal positive computing system. In Proceedings of the 14th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications, Prague, Czech Republic. http://dx.doi.org/10.5220/0007694101950201   
English-Speaking Union. (2019). English-speaking Union—Resources. www.esu.org/resources/   
Farris, K. L., Houser, M. L., & Wotipka, C. D. (2013). Assessing student public speaking competence in the hybrid basic communication course. Basic Communication Course Annual, 25, 10. http:// ecommons.udayton.edu/bcca/vol25/iss1/10   
Frisy, B.N. Kauan R.Vallade, J. I. Frey, T. K. &Martin, J. 020 Usivirtual reality r rehearsals: Assessing student perceptions as foundational to instructor technology adoption decisions. Basic Communication Course Annual, 32, 59-78. https://ecommons.udayton.edu/bcca/vol32/ iss1/6   
Harris, S. R., Kemmerling, R. L., & North, M. M. (2002). Bri virtual reality therapy for public spekng anxiety. Cyberpsychology & Behavior, 5(6), 543550. https://doi.org/10.1089/109493102321018187   
Hart, S. G., & Staveland, L. E. (1988). Development of NASA-TLX (task load index): Results of empirical and theoretical research. Advances in Psychology, Vol. 52 (pp. 139183). North Holland. https://doi. org/10.1016/S0166-4115(08)62386-9   
Hartmann, T. Toz, E., & Brandon, M. (2010). Just a game? Unjustified virtual violence produces guilt in empathetic players. Media Psychology, 13, 339363. https://doi.org/10.1080/15213269.2010.524912   
Hartmann, T. Wirth, W., Schramm, H. Klimmt, C., Vorderer, P. Gysbers, A., Böcking, S., Ravaja, N., Laari, J., Saari, T. Gouveia, F. R., & Sacau, A. M. (2016). The spatial presence experience scale (SPES). Journal of Media Psychology, 28. https://doi.org/10.1027/1864-1105/a000137   
Haynes, W. L. (1990). Beyond writing: A case for a speech-based basic course in a vid-oral world. Basic Communication Course Annual, 2. http://ecommons.udayton.edu/bcca/vol2/iss1/10   
Kothgassner, O. D., Felnhofer, A., Hlavacs, H., Beutl, L., Palme, R., Kryspin-Exner, I., & Glenk, L. M. (2016). Salivary cortisol and cardiovascular reactivity to a public speakingtask in avirtual and real-life environment. Computers in Human Behavior, 62, 124135. https://doi.org/10.1016/j.chb.2016.03.081   
chology Bulletin, 9(3), 371375. https://doi.org/10.1177/0146167283093007   
LeFebvre, L. E, Lefebvre, L. & Allen, M. (2020). "Imagine al the people" Imagined interactions in vitual reality when public speaking. Imagination, Cognition and Personality: Consciousness in Theory, Research, and Clinical Practice. Advanced online publication. https://doi.org/10.1177/02762366 20938310   
Lucas, S. E. (2015). The art of public speaking (11th ed.). McGraw-Hill.   
McCroskey, J. C. (1970). Measures of communication-bound anxiety. Speech Monographs, 37, 269277. https://doi.org/10.1080/03637757009375677   
McCroskey, J. C. (1982). Oral communication apprehension: A reconceptualization. Annals of the International Communication Association, 6, 136170. https://doi.org/10.1080/23808985.1982.11678497   
Menzel, K. E., & Carrel, L. J. (1994). The relationship between preparation and performance in public speaking. Communication Education, 43, 1726. https://doi.org/10.1080/03634529409378958   
Morreale, S. P, Moore, M. Surges-Tatum, D., & Webster, L. (2007). The competent speaker speech evaluation form: Washington, DC: National Communication and Association.   
Morreale, S. P. Myers, S. A., Backlund, P. M. & Simonds, C. J. (2016). Study IX of the basic communication course at two- and four-year US Colleges and Universities: A re-examination of our discipline's "front porch." Communication Education, 65, 338355. https://doi.org/10.1080/03634523.2015. 1073339   
Mrer, E. JasFöark,M. Pt, A. HeOreon, T. (018. syertis of the Personal Report of Public Speaking Anxiety (PRPSA) in a sample of university students inwede.Inteatial JurnalCognitiveThery,11,3htts://oiorg00/ s41811-018-0022-0   
Nishikawa-Van Eester, M. (2009). Teaching public speaking in Japanese junior high school. In Teple University Japan Colloquium in Applied Linguistics (pp. 17).   
Pearson, J. . Carmon, A. F. Child, J. T. & Semlak, J. L. (2008). Why the range in grades? An attempt to explain the variance in students' public speaking grades. Communication Quarterly, 56, 392406. https://doi.org/10.1080/01463370802448188   
Pearon, J.C. &Child, J. T. (008). The influenceof biological sex, previus experience, and preparation time on classroom public speaking grades. Basic Communication Course Annual, 2008. http:// ecommons.udayton.edu/bcca/vol20/iss1/9   
Pearson, J. C., Child, J. T. & Kahl Jr., D. H. (2006). Preparation meeting opportunity: How do college students prepare for public speeches?. Communication Quarterly, 54, 351366. https://doi. org/10.1080/01463370600878321   
Pertaub, D. P. Slater, M. & Barker, C. (2001). An experiment on fear of public speaking in virtual realiy. Studies in Health Technology and Informatics, 372378. https://pubmed.ncbi.nlm.nih.gov/11317771/   
Pertaub, D. P., Slater, M. & Barker, C. (2002). An experiment on public speaking anxiety in response to three different types of virtual audience. Presence: Teleoperators & Virtual Environments, 11, 6878. https://doi.org/10.1162/105474602317343668   
Reeves, B., & Nass, C. I. (1996). The media equation: How people treat computers, television, and new media like real people and places. Cambridge University Press.   
Robinson, T. E. (1997). Communication apprehension and the basic public speaking course: A national survey of in-class treatment techniques. Communication Education, 46, 188197. https://doi. org/10.1080/03634529709379090   
Rosenberg, M. (1965). Rosenberg self-esteem scale (RSE). Acceptance and commitment therapy. Measures package, 61(52), 18.   
Rubin, R. B. Graham, E. E. & Mignerey J. T. (1990). A longitudinal study of college studentscommuication competence. Communication Education, 39, 114. https://doi.org/10.1080/03634529009378783   
Scheier, M. F., & Carver, C. S. (2013). Self-consciousness scale—(SCS-R). Measurement Instrument Database for the Social Science. www.midss.ie   
Schreiber, L. M., Paul, G. D., & Shibley, L. R. (2012). The development and test of the public speaking competence rubric. Communication Education, 61, 205233. https://doi.org/10.1080/03634523.2012 .670709   
Seibold, D. R., Kudsi, S, & Rude, M. (1993). Does communication training make a difference?: Evidence for the effectiveness of a presentation skills program. Journal of Applied Communication Research, 21(2), 111-131. https://doi.org/10.1080/00909889309365361   
Slater, M., Pertaub, D. P., Barker, C., & Clark, D. M. (2006). An experimental study on fear of public speaking using a virtual environment. Cyberpsychology & Behavior, 9(5), 627633. https://doi. org/10.1089/cpb.2006.9.627   
Smith, T. E. & Frymier, A. B. (2006). Get 'real: Does practicing speeches before an audience improve performance?. Communication Quarterly, 54, 111125. https://doi.org/10.1080/01463370500270538   
Spielberger, C. D., Gorsuch, R. L., Lushene, R. Vagg, P. R., & Jacobs, G. A. (1983). Manual for the StateTrait Anxiety Inventory (Form Y). Consulting Psychologists Press.   
Tluk, A. Henriques, J. B., &Brown, R. L. (2009). Support for the reliabiliy and validiy ofa si-item state anxiety scale derived from the State-Trait Anxiety Inventory. Journal of Nursing Measurement, 17(1), 19. https://doi.org/10.1891/1061-3749.17.1.19   
Vallde, J. I. Kaufmann, R. Frisby, B.N. & Martin, J. (2020) Technology acceptance mode: Invetigating students' intentions toward adoption of $3 6 0 ^ { \circ }$ videos for public speaking rehearsals. Communication Education. Advanced online publication. https://doi.org/10.1080/03634523.2020.1791351   
Valve. (2019). Steam VR [Computer software]. https://store.steampowered.com/steamvr   
Vanni, F. Conversano, C., Del Debbio, A., Landi, P. Carlini, M. Fanciullacci, C. Bergamasco M., Di Fiorino A., & Dell'Osso, L. (2013). A survey on virtual environment applications to fear of public speaking. European Review for Medical and Pharmacological Sciences, 17, 15611568. https://www. europeanreview.org/wp/wp-content/uploads/1561-1568.pdf   
Watson, D., & Friend, R. (1969). Measurement of social-evaluative anxiety. Journal of consulting and clinical psychology, 33(4), 448. https://psycnet.apa.org/doi/10.1037/h0027806   
Weber, R. & Popova, L. (2012). Testing equivalence in communication research: Theory and application. Communication Methods and Measures, 6(3), 190213. https://doi.org/10.1080/19312458.2012. 703834