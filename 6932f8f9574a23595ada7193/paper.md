# ScoreHOI: Physically Plausible Reconstruction of Human-Object Interaction via Score-Guided Diffusion

Ao Li1,2 Jinpeng Liu1,2 Yixuan Zhu2 Yansong Tang1,2\* 1Tsinghua Shenzhen International Graduate School 2Tsinghua University

# Abstract

Joint reconstruction of human-object interaction marks a significant milestone in comprehending the intricate interrelations between humans and their surrounding environment. Nevertheless, previous optimization methods often struggle to achieve physically plausible reconstruction results due to the lack of prior knowledge about human-object interactions. In this paper, we introduce ScoreHOI, an effective diffusion-based optimizer that introduces diffusion priors for the precise recovery of human-object interactions. By harnessing the controllability within score-guided sampling, the diffusion model can reconstruct a conditional distribution of human and object pose given the image observation and object feature. During inference, the ScoreHOI effectively improves the reconstruction results by guiding the denoising process with specific physical constraints. Furthermore, we propose a contact-driven iterative refinement approach to enhance the contact plausibility and improve the reconstruction accuracy. Extensive evaluations on standard benchmarks demonstrate ScoreHOI's superior performance over state-of-the-art methods, highlighting its ability to achieve a precise and robust improvement in joint human-object interaction reconstruction. Code is available at https://github.com/RammusLeo/ ScoreHOI.git

# 1. Introduction

The task of joint 3D human-object interaction reconstruction entails the recovery of both human body mesh and the pose of the interactive object from images or videos. In recent decades, human mesh recovery (HMR) [15, 25, 28, 29, 74] has garnered significant attention within the research community, owing to its extensive range of applications. Concurrently, a growing body of research has underscored the importance of reconstructing the interaction between humans and objects, rather than merely focusing on the reconstruction of the human. This approach holds substantial potential for various applications, such as data collection for robotics, VR/AR and game development.

![](images/1.jpg)  
Figure 1. Comparison of current methods and the proposed ScoreHOI. (a) Optimization-based methods iteratively refine predicted outcomes with the physical objectives. (b) Regressionbased methods update predictions via a dual-branch forward process. (c) Our ScoreHOI integrates a score-based denoising module that incorporates physical constraints during the sampling process.

Despite advancements, the direct reconstruction of human and object meshes from monocular images [68] remains a formidable challenge. This difficulty arises from the omission of numerous interaction patterns, such as grasping, lifting, or sitting, between humans and objects, which constitute valuable prior knowledge for the recovery task. To address this, existing methodologies have incorporated refinement modules that aim at transforming coarse estimations into more accurate outcomes. As illustrated in Figure 1, the prevailing approaches can be broadly categorized into optimization-based and regression-based methods. Optimization-based techniques [57, 59, 60] employ a joint optimizer like Adam [27] to iteratively refine results by incorporating physical objectives, including contact and collision constraints. However, an overemphasis on physical constraints while neglecting image-level features often results in significant reconstruction inaccuracies. Moreover, these methodologies are often inefficient and require considerable computational time. Conversely, regression-based approaches [37] devise a contact-aware cross-attention mechanism to reestablish the human-object relationship in a forward process that integrates image features. Nevertheless, the single-step forward refinement of parameters tends to lack robustness, particularly in scenarios like severe occlusion or depth ambiguity. Recently, diffusion models [20, 47, 49] have demonstrated their capability to recover data distributions from Gaussian noise. These models infer the implicit prior of the underlying data distribution $x$ by aligning the gradient of the log density $\nabla _ { x } \log p ( x )$ [49], which is also referred to as the score of the distribution. Leveraging Bayes' Theorem, the denoising process can be enhanced with an additional realistic guidance term, thereby steering the optimization process closer to the observed data. Owing to their rich prior knowledge and guided sampling proficiency, diffusion models have been employed to enhance the estimation quality in HMR tasks [14, 34, 50, 74]. More recently, methods like [58] endeavor to incorporate diffusion models into the humanobject reconstruction. However, these approaches primarily seek to leverage diffusion techniques for the generation of point clouds, while we focus on exploiting the potential of diffusion priors for refining the human-object interaction. To overcome the aforementioned limitations of prior approaches, we propose ScoreHOI, an effective framework that utilizes a score-based diffusion model to refine the coarse estimation results, as shown at the lower section of Figure 1. Our design contemplates two main challenges: (1) the integration of human-object interaction prior knowledge into the optimization process, and (2) the supervision of the sampling procedure with plausible physical constraints. To tackle these issues, we propose a contact-driven iterative refinement approach that leverages diffusion generative models as a robust optimizer endowed with extensive prior knowledge. In the inference phase, we first invert an initial regression estimation into a noisy latent representation via DDIM [47] inversion. Subsequently, we denoise this latent by DDIM sampling, augmented with interaction guidance such as contact and collision constraints. To enhance the controllability, we introduce the object geometry and image feature as the conditions. Furthermore, we iteratively refine the contact masks to improve the physical plausibility. We conduct extensive experiments on standard benchmarks, including BEHAVE [2] and InterCap [23] based on various initial regression results. Our ScoreHOI performs strong robustness and effectiveness, surpassing previous state-of-the-art methods and demonstrating significantly improved accuracy. Notably, we attain a $9 \%$ improvement in the contact F-Score on the BEHAVE benchmark, thereby substantiating the optimization capability of our approach. In addition, we conduct comprehensive ablation studies to underscore the effectiveness and efficiency of our pipeline and the refinements we have designed.

# 2. Related Work

Human-Object Interaction Reconstruction. Modeling 3D interactions between humans and objects is a significant challenge. While recent studies have demonstrated strong performance in modeling human motion using high dimensional data [1, 3, 4, 10, 32, 52, 63] and images [9, 11, 18, 26]. However, these methods are limited to handobject interactions and do not extend to full-body interactions, which are even more complex. Some approaches, such as PROX [16], can fit a 3D human model to meet scene constraints [17, 46, 70, 71], capture interactions from multiple views [24, 51, 66], or reconstruct 3D scenes based on human-scene interactions [66]. Recently, research has also expanded to include human-human interactions [12] and self-contacts [13, 36]. Despite these advancements, existing methods struggle to jointly reconstruct human-object contacts from single images. A few studies have attempted to reason about 3D contacts from images [5, 6, 21] and videos [31, 35, 43, 54, 67], but they do not achieve the 3D reconstruction of full body and objects from a single RGB image. Weng et al. [55] predict the 3D human and scene layout separately, using scene constraints to refine human reconstruction. They apply predefined contact weights on SMPL-X [39] vertices, which can lead to inaccuracies. PHOSA [69] fits SMPL and object meshes separately and relies on predefined contact pairs to reason about interactions, but these heuristics are not scalable and often lack accuracy. Our work injects diverse physical constraints through contact-driven iterative refinement. It leads to more reasonable positions of objects and human mesh.

Score-Based Diffusion Models. Diffusion models [20, 49] have emerged as powerful tools for representing complex probability distributions, demonstrating exceptional performance in text-to-image generation [20, 44]. In addition to traditional denoising techniques, [49] introduces the concept of a score to characterize the time-dependent gradient field of the perturbed data distribution. The application of score-based sampling enables the denoising process to be directed by diverse forms of guidance, thereby fostering the development of methods applicable to a wide range of tasks, including super-resolution [48, 75, 76] and image inpainting [7, 8]. Recently, methods like [50] have explored the potential of the score-based diffusion models for HMR tasks by refining the outcomes with observations. However, the score-guided optimization in the context of 3D humanobject reconstruction remains largely unexplored. Our work aims to bridge this gap by integrating diffusion priors into this domain, which can potentially enhance the accuracy of reconstruction and the physical plausibility of interaction.

![](images/2.jpg)  
Figure 2. The inference procedure of ScoreHOI. (a) Given the input image $I$ the human and object segmented silhouette $S _ { \mathrm { h } } , S _ { \mathrm { o } }$ and the object template $P _ { \mathrm { ~ o ~ } }$ , we initially extract the image feature $\mathcal { F }$ and estimate the SMPL and object parameters $\theta$ $\beta$ , $R _ { \mathrm { o } }$ and $t _ { \mathrm { o } }$ . (b) Employing a contact-driven iterative refinement strategy, we refine these parameters $_ { \textbf { \em x } }$ through the execution of a DDIM inversion and guided sampling lo Due i s, hysl ctant uc  pe $L _ { \mathrm { p t } }$ and contact $L _ { \mathrm { h o } } , L _ { \mathrm { o f } }$ are actively supervised. Following each optimization iteration, the contact masks $\{ \mathbf { M } _ { i } \} _ { i \in \{ \mathrm { h , o , f } \} }$ are updated to enhance the precision of the guidance.

# 3. Method

In this section, we present ScoreHOI, an effective optimizer designed to leverage priors and physical constraints for joint human-object interaction reconstruction. We will start by reviewing the background of human body models and score-based diffusion models. Then we will firstly introduce the full inference pipeline from the affordanceaware regressor to the contact-driven iterative refinement, as shown in Figure 2. Following this, we will demonstrate the architecture of the diffusion model and other details.

# 3.1. Preliminaries

Human Body Model. SMPL [33] is a sophisticated parametric model designed to represent the human body in three dimensions. Two sets of parameters characterize this model: pose parameters $\theta \in \mathbb { R } ^ { 2 4 \times 3 }$ , which capture the orientation and configuration of the body, and shape parameters $\beta \in \mathbb { R } ^ { 1 0 }$ , which define the physical characteristics of the body such as size and proportions. The model establishes a mapping function ${ \mathcal { M } } ( \theta , \beta )$ that translates these parameters into a detailed body mesh $\mathcal { M } \in \mathbb { R } ^ { N \times 3 }$ ,where $ { N _ { \mathrm { ~ \scriptsize ~ = ~ } } } 6 9 8 0$ indicates the total number of vertices that comprise the mesh. The SMPL-H [33, 39, 45] model is based on a parametric representation, which combines the SMPL [33] body model and MANO [45] hands model. This allows for the generation of realistic human figures that can be used in various applications, including manipulating objects with hands and interacting with the scene.

Score-Based Diffusion Models. Diffusion models, such as DDPM [20], comprise two processes: the forward diffusion and the inverse denoising. In forward diffusion, data $\scriptstyle { \mathbf { { \vec { x } } } } _ { 0 }$ is transformed into noised data $\mathbf { \nabla } _ { \mathbf { x } _ { T } }$ over $t ~ = ~ T$ timesteps using Gaussian kernels with variance schedule $\{ \zeta _ { t } \}$ , defined by $\ v { q } ( \mathbf { x } _ { t } | \mathbf { x } _ { 0 } ) = \mathcal { N } ( \sqrt { \alpha _ { t } } \mathbf { x } _ { 0 } , ( 1 - \alpha _ { t } ) \mathbf { I } )$ , where $\begin{array} { r } { \alpha _ { t } : = \prod _ { s = 1 } ^ { t } ( 1 - \zeta _ { s } ) } \end{array}$ .For the inverse denoising process, a denoising model $\epsilon _ { \phi }$ is trained to predict noise by minimizing: $\mathcal { L } ( \phi ) = \mathbb { E } _ { \pmb { x } _ { 0 } , t , \epsilon } | | \epsilon _ { \phi } ( \pmb { x } _ { t } , t ) - \epsilon | | ^ { 2 }$ , where $t$ is uniformly sampled from $\{ 1 , . . , T \}$ , and $\epsilon$ is the noise added to $\scriptstyle { \mathbf { { \mathit { x } } } } _ { 0 }$ . According to [49], the model's predicted noise at timestep $t$ is linked to the score of the model:

$$
\begin{array} { r } { \epsilon _ { \phi } ( \pmb { x } _ { t } , t ) = - \sqrt { 1 - \alpha _ { t } } \nabla _ { \pmb { x } _ { t } } \log p ( \pmb { x } _ { t } ) , } \end{array}
$$

where $\nabla _ { \pmb { x } _ { t } } \log p ( \pmb { x } _ { t } )$ refers to the score, which describes the time-dependent gradient field of the perturbed data distribution. For accelerated sampling, DDIM [47] can be used, which employs non-Markovian processes. Based on 1, the

# Algorithm 1 Contact-Driven Iterative Refinement

:Input: Initial parameters $\pmb { x } _ { 0 } ^ { 0 }$ ,diffusion model $\epsilon _ { \theta }$ , image feature $\mathcal { F }$ , time steps $t$ ,and condition $^ c$   
2: Output: The optimized parameters $\pmb { x } _ { 0 } ^ { N }$   
3: for $n = 0$ to $N - 1$ do   
4: $\mathcal { F } _ { \mathrm { h } } ^ { n } , \mathcal { F } _ { \mathrm { o } } ^ { n }  \bf { s a m p l e } ( \pmb { x } _ { 0 } ^ { n } , \mathcal { F } )$   
5: $\{ \mathbf { M } _ { i } \} _ { i \in \{ \mathrm { h , o , f } \} }  \mathbf { C o n t a c t } ( x _ { 0 } ^ { n } , \mathcal { F } _ { \mathrm { h } } ^ { n } , \mathcal { F } _ { \mathrm { o } } ^ { n } )$   
6: . $\mathbf { \boldsymbol { x } } _ { 0 } ^ { n + 1 } \gets \mathbf { \boldsymbol { D } } \mathbf { \boldsymbol { D } } \mathbf { \boldsymbol { I } } \mathbf { \boldsymbol { M } } \mathbf { \boldsymbol { L 0 0 p } } ( \mathbf { \boldsymbol { x } } _ { 0 } ^ { n } , t , c , \epsilon _ { \theta } , \{ \mathbf { M } _ { i } \} _ { i \in \{ \mathrm { h , o , f } \} } )$ 7: end for   
8: return $\pmb { x } _ { 0 } ^ { N }$ denoised result $\hat { x _ { 0 } } ( \pmb { x } _ { t } )$ from $\mathbf { \Delta } _ { \mathbf { \mathcal { X } } _ { t } }$ is calculated as:

$$
\begin{array} { l } { \displaystyle \hat { \pmb { x } _ { 0 } } ( \pmb { x } _ { t } ) = \frac { 1 } { \sqrt { \alpha _ { t } } } ( \pmb { x } _ { t } - \sqrt { 1 - \alpha _ { t } } \epsilon _ { \phi } ( \pmb { x } _ { t } , t ) ) } \\ { \displaystyle \simeq \frac { 1 } { \sqrt { \alpha _ { t } } } ( \pmb { x } _ { t } + ( 1 - \alpha _ { t } ) \nabla _ { \pmb { x } _ { t } } \log p ( \pmb { x } _ { t } ) ) . } \end{array}
$$

This framework also supports conditional distributions.

# 3.2. Affordance-Aware Regressor

For the joint human-object interaction reconstruction task, our primary goal is to precisely estimate the human bodyhand pose $\theta \in \mathbb { R } ^ { 5 2 \times 6 }$ , human shape parameter $\beta \in \mathbb { R } ^ { 1 0 }$ , along with the object rotation $R _ { \mathrm { o } } \in \mathbb { R } ^ { 6 }$ and the object translation $t _ { \mathrm { o } } ~ \in \ \mathbb { R } ^ { 3 }$ . We adopt the 6D rotation format following [73] for the representation of $\theta$ and $\scriptstyle { \mathbf { } } _ { R _ { \mathrm { o } } }$ to enhance the stability of predicted results. We use the cropped image $I _ { r g b } \in \mathbf { \bar { \mathbb { R } } } ^ { H \times \mathbf { \bar { W } } \times 3 }$ with its corresponding human and object segmentation parts $S _ { \mathrm { h } } ~ \in ~ \mathbb { R } ^ { H \times \bar { W } \times 3 }$ and $S _ { \mathrm { o } } ~ \in ~ \mathbb { R } ^ { H \times \bar { W } \times 3 }$ as the visual inputs. Following previous work [37, 59], a coarse object template $ { P _ { \mathrm { ~ o ~ } } } \in \ \mathbb { R } ^ { 6 4 \times 3 }$ is given to initialize the shape of the object. However, in general situations, the shape of the object is varied in numerous forms, while the object in our training data is limited. Previous work like [37] embeds the class identity to inject the object category information, yet this method is inaccessible when the object shape is out of the training set.

Although the objects have different shapes, we have a common assumption that the objects in the same category have a similar appearance, e.g. a table has a flat surface and usually has legs supported on the ground. Therefore, to enhance the generalization ability, we introduce the Affordance concept inspired by [40]. The affordance refers to the perceived or actual properties of an object that suggest how it can be used, which can be constructed with a pre-trained affordance-aware network. The pre-trained model generates abundant prior knowledge from large scale 3D object datasets that is valuable for the reconstruction. With the help of affordance awareness, we extract the image feature $\mathcal { F }$ , then we apply two separate heads to initially estimate the human body-hand SMPL-H parameters $\theta ^ { 0 }$ and $\beta ^ { 0 }$ , as well as the object rotation $R _ { \mathrm { o } } ^ { 0 }$ and translation $t _ { \mathrm { o } } ^ { 0 }$ .

# 3.3. Optimization with Physical Guidance

After obtaining the initial parameters, we define the optimization objective as the concatenation of human body pose, human body shape, object rotation and object translation, represented as $\pmb { x } = \{ \theta , \beta , R _ { 0 } , t _ { 0 } \} \in \mathbb { R } ^ { 3 3 1 }$ . We start from the initial etaion eult $\pmb { x } ^ { \mathrm { i n i t } }$ , using DDIM inversion process to obtain the noisy latent $\scriptstyle { \mathbf { 2 } } \left( { \mathbf { 2 } } \right)$ where $\tau$ is the noise level:

$$
\pmb { x } _ { t + 1 } = \sqrt { \alpha _ { t + 1 } } \hat { \pmb { x } _ { 0 } } ( \pmb { x } _ { t } ) + \sqrt { 1 - \alpha _ { t + 1 } } \epsilon _ { \phi } ( \pmb { x } _ { t } , t , \pmb { c } ) ,
$$

where $^ c$ is the combination of image feature condition $c _ { \mathrm { I } }$ and geometry feature condition $c _ { \mathrm { G } }$ defined in Section 3.5.

After we have obtained ${ \bf { x } } _ { \tau }$ , $\pmb { x } ^ { \mathrm { i n i t } }$ can be retrieved via the forward DDIM sampling process. Nevertheless, the intention is to enhance $\pmb { x } ^ { \mathrm { i n i t } }$ by incorporating physical constraints. Instead of using original score $\nabla _ { \pmb { x } _ { t } } \log p ( \pmb { x } _ { t } | \pmb { c } )$ , we apply the conditional score with physical objectives $\nabla _ { \pmb { x } _ { t } } \log p ( \pmb { x } _ { t } | \pmb { c } , \mathcal { P } )$ According to the Bayes rule, the score can be written as $\nabla _ { \pmb { x } _ { t } } \log p ( \pmb { x } _ { t } | \pmb { c } , \mathcal { P } ) = \nabla _ { \pmb { x } _ { t } } \log p ( \pmb { x } _ { t } | \pmb { c } ) +$ $\nabla _ { \pmb { x } _ { t } } \log p ( \mathcal { P } | \pmb { c } , \pmb { x } _ { t } )$ ,where $\nabla _ { \pmb { x } _ { t } } \log _ { \pmb { p } } ( \pmb { x } _ { t } | \pmb { c } )$ is the output of the diffusion model. However, directly computing $\nabla _ { \pmb { x } _ { t } } \log p ( \mathcal { P } | \pmb { c } , \pmb { x } _ { t } )$ from $\mathbf { \Delta } _ { \mathbf { \mathcal { X } } _ { t } }$ is difficult. Inspired by [7, 22, 50], we can take an assumption that:

$$
\nabla _ { \pmb { x } _ { t } } \log p ( \mathcal { P } | \pmb { c } , \pmb { x } _ { t } ) \simeq \nabla _ { \pmb { x } _ { t } } \log p ( \mathcal { P } | \pmb { c } , \hat { \pmb { x } _ { 0 } } ( \pmb { x } _ { t } ) )
$$

where $\hat { \pmb { x } _ { 0 } } ( \pmb { x } _ { t } )$ represents the denoised results from $\mathbf { \Delta } _ { \mathbf { \mathcal { X } } _ { t } }$ . Consequently, the predicted human mesh $\hat { V } _ { 0 } ^ { \mathrm { h } } ( V _ { t } ^ { \mathrm { h } } )$ and object mesh $\hat { V } _ { 0 } ^ { \mathrm { o } } ( V _ { t } ^ { \mathrm { o } } )$ can be derived from $\hat { \pmb { x } _ { 0 } } ( \pmb { x } _ { t } )$ to elucidate the interaction relationship, which constitutes the fundamental elements of computing physical constraints. Now we aim to define the physical objectives, consisting of the human-object contact, object-floor contact and 3D penetration following [22, 30, 60]:

$$
L _ { \mathcal { P } } = \lambda _ { \mathrm { h o } } L _ { \mathrm { h o } } + \lambda _ { \mathrm { o f } } L _ { \mathrm { o f } } + \lambda _ { \mathrm { p t } } L _ { \mathrm { p t } } ,
$$

where the individual constraints are given as:

•Human-Object Contact: $L _ { \mathrm { h o } } = | | ( \mathbf { M } _ { \mathrm { h } } + \mathbf { M } _ { \mathrm { o } } ) \odot | V _ { \mathrm { h } } -$ $V _ { \mathrm { o } } | \ | | _ { 2 }$ . The Euclidean distance between human mesh $V _ { \mathrm { h } }$ and object mesh $V _ { \mathrm { o } }$ at the predicted human contact regions $\mathbf { M } _ { \mathrm { h } }$ and object contact regions $\mathbf { M } _ { \mathrm { o } }$ should be ideally zero. Object-Floor Contact: $L _ { \mathrm { o f } } = | | \mathbf { M } _ { \mathrm { f } } \odot | V _ { \mathrm { o } } | \ | | _ { 1 }$ .The $\mathbf { M } _ { \mathrm { f } }$ represents the set of object vertices in contact with the ground surface. For vertices within this set, the height should be zero, indicating direct contact with the floor. Penetration Avoidance: $L _ { \mathrm { p t } } = - \mathbb { E } [ | \Phi _ { 0 } ^ { - } ( V _ { \mathrm { h } } ) | ]$ . We introduce a penalty for penetration scenarios utilizing the sign distance function (SDF) $\Phi _ { 0 } ^ { - }$ of objects. The value of $L _ { \mathrm { p t } }$ increases in the event of the overlaps happen. Finally, the modified noise prediction with physical constraints is written as:

$$
\epsilon _ { \phi } ^ { \prime } = \epsilon _ { \phi } ( \pmb { x } _ { t } , t , \pmb { c } ) + \rho \sqrt { 1 - \alpha _ { t } } \nabla _ { \pmb { x } _ { t } ^ { n } } L _ { \mathcal { P } }
$$

where $\rho$ is the weight to control the guidance scale.

# 3.4. Contact-Driven Iterative Refinement

During the denoising process procedure guided by physical guidance, we find that the precise prediction of contact regions is a critical factor. The prediction of these regions is derived from the grid-sampled features $\mathcal { F } _ { \mathrm { h } }$ and $\mathcal { F } _ { \mathrm { o } }$ by human and object pose parameters $_ { \textbf { \em x } }$ .However, the straightforward estimation of the contact mask via a single forward process is prone to deficiencies, especially under heavy occlusion. To address this, we have implemented a contactdriven iterative refinement strategy to augment the accuracy of contact estimation during the inference phase, as shown in Algorithm 1. Commencing with an initial parameter $\pmb { x } _ { 0 } ^ { n }$ at $n$ -th iteration, we firstly sample the $\mathcal { F } _ { \mathrm { h } }$ and $\mathcal { F } _ { \mathrm { o } }$ from image feature $\mathcal { F }$ . Subsequently, the human-to-object contact mask $\mathbf { M } _ { \mathrm { h } }$ , object-to-human contact mask $\mathbf { M } _ { \mathrm { h } }$ and object-tofloor contact mask $\mathbf { M } _ { \mathrm { f } }$ will be update by a contact predictor. Then as mentioned in Section 3.3, we obtain noisy $\pmb { x } _ { \tau } ^ { n }$ via DDIMn $\pmb { x } _ { 0 } ^ { n + 1 }$ through guided sampling, wherein the contact masks and the estimated human and object vertices are incorporated. Assuming that we optimize for $N$ steps, the final iteration yields $\pmb { x } _ { 0 } ^ { N }$ Following [37], we apply a dual-branch masked transformer [53] to ultimately enhance the quality of mesh recovery.

# 3.5. Diffusion Model Architecture

The main diffusion model is built with 3 cross-attention layers. However, without any guidance, the generation results are not controllable, not to mention in reconstruction tasks. To address this, we propose an IG-Adapter that can incorporate object geometry prior knowledge and visual observation as guidance. We introduce two conditions including the image feature condition $c _ { \mathrm { I } }$ derived from the average pooling of $\mathcal { F }$ and the geometry feature condition $c _ { \mathrm { o } }$ extracted from pre-trained affordance-aware network. Inspired by [65], we train an additional cross-attention block and its associated fusing linear head, as shown in Figure 3. By combining the attention value from geometry priors and observation information, the model is equipped with both interaction awareness and visual awareness. For the human shape parameters $\beta$ , we employ the same branch comprising 3 cross-attention layers. Moreover, we normalize the $\beta$ into $[ - 1 , 1 ]$ during processing. Regarding the timesteps, following [50], the input is conditioned on the timestep $t$ via scaling and shifting operations, defined as ${ \pmb x } _ { t } = t _ { s } { \pmb x } + t _ { b }$ , where the parameters $t _ { s }$ and $t _ { b }$ are derived from an MLP encoder. With the help of both guidance $c _ { \mathrm { I } }$ and $\mathbf { c _ { G } }$ , we can train the diffusion model with the objective:

$$
L _ { \mathrm { D M } } = \mathbb { E } _ { { \pmb { x } } _ { 0 } , { \epsilon } , { t } , { \pmb { c } } _ { \mathrm { I } } , { \pmb { c } } _ { \mathrm { G } } } | | \epsilon - { \epsilon } _ { \theta } ( { \pmb { x } } _ { t } , { t } , { \pmb { c } } _ { \mathrm { I } } , { \pmb { c } } _ { \mathrm { G } } ) | | ^ { 2 }
$$

# 3.6. Implementation

Pytorch [38] is used for implementation. As for the image feature extractor, we employ the ResNet50 [19] as a backbone. For the preliminary estimation of SMPL-H parameters, we adopt the Hand4Whole framework. Regarding the pre-trained affordance-aware network, we use PointNeXt [42] and we freeze the model during training to maintain stability in object feature extraction. During the inference phase, DDIM sampling is performed for step size $\Delta t = 2$ , and the contact-driven iterative refinement is iterated for $N = 1 0$ times. An intermediate noise level $\tau$ of 0.05 is selected. Further details regarding the hyperparameters are provided in Section 4.3.

![](images/3.jpg)  
Figure 3. The overview of IG-Adapter. We introduce an IGAdapter designed to integrate the image feature guidance $c _ { \mathrm { I } }$ and the geometry feature guidance $c _ { \mathrm { G } }$ into the diffusion model. The incorporation of observational and geometric awareness enhances the controllability of the model during the inference process.

# 4. Experiments

To verify the effectiveness and efficiency of our proposed ScoreHOI, we conduct comprehensive experiments and ablation studies on the standard benchmarks. We will introduce the experimental settings and offer a comprehensive analysis through detailed comparisons and ablation studies.

# 4.1. Experiment Setup

Datasets. BEHAVE [2] dataset is the largest dataset of human-object interactions in natural environments, with 3D human, object and contact annotation. The dataset includes: (1) 8 subjects interacting with 20 objects in 5 natural environments. (2) In total 321 video sequences were recorded with 4 Kinect RGB-D cameras. (3) Textured scan reconstructions for the 20 objects. InterCap [23] contains 10 subjects (5 males and 5 females) interacting with 10 objects of various sizes and affordances. It includes contact with the hands or feet. In total, InterCap has 223 RGBD videos, resulting in 67,357 multi-view frames, each containing 6 RGB-D images. IMHD dataset [72] contains 15 subjects (13 males, 2 females to participate in 10 different interaction scenarios. It also provides sequence-level textual guidance for each capture. Each split lasted from half a minute to one minute. It contains 32-view RGB videos with instance-level segmentation. IMHD utilizes ViTPose [64] and MediaPipe to annotate 2D and 3D human key points.

![](images/4.jpg)  
F    HO effectively addresses this ill-posed problem, achieving superior reconstruction fidelity.

We only utilize the IMHD training set during the diffusion training phase to augment the generation capability.

Training Details. The training phase has two parts. Initially, we train the image backbone, the contact predictor and the vertices refinement at the first stage following the loss functions in [37], including the supervision for the SMPL-H and object pose parameters, the contact mask and the 2D/3D vertices, etc. We train these baseline modules on BEHAVE [2] and InterCap [23] training set. Subsequently, the diffusion model is trained using image features extracted from a frozen image backbone, incorporating IMHD [72] to enhance generative capabilities. Weight updates are facilitated by the Adam optimizer [27], with a mini-batch size of 32 in the first stage and 256 in the second stage. In both stages, data augmentation techniques such as scaling, rotation, and color jittering are applied to enhance the diversity of the dataset. The training in the first stage is carried out for a total of 50 epochs, with an initial learning rate of $1 0 ^ { - 4 }$ , which is subsequently reduced by a factor of 10 after 30 epochs. In the second stage, the parameters converge more rapidly, thereby necessitating only 30 epochs of training at a learning rate of $1 0 ^ { - 4 }$ . The model is trained using 4

# NVIDIA RTX 4090 GPUs for around 1.5 days in total.

Evaluation Details. Following previous works [37, 59, 68], we utilize two kinds of metrics to elevate the model's performance: chamfer distance, precision, and recall. Chamfer distance $\mathbf { \hat { C D } _ { h u m a n } }$ , $\mathbf { C D _ { o b j e c t } } )$ Given the predicted 3D human and object meshes, we apply Procrustes alignment on combined 3D human and object meshes with the GT 3D human and object meshes. With the aligned 3D human and object meshes, we measure the Chamfer distance from GT separately on 3D human $\mathrm { ( C D _ { h u m a n } ) }$ and 3D object $\mathrm { ( C D _ { o b j e c t } ) }$ , in centimeters. Precision recall and F-Score for contact from reconstruction $\mathbf { ( C o n t a c t _ { p } ^ { r e c } }$ ,Contactrec, Contactre-s). Precision measures how many of the predicted positive cases are positive. A high Precision means that when the model predicts a positive outcome, it is likely to be correct. Recall indicates how many of the actual positive cases were correctly identified by the model. A high Recall means that the model successfully identifies most of the positive cases. However, achieving high precision concurrently with high recall presents a significant challenge. Therefore we introduce F-Score $= 2 \times \mathbf { p } \times \mathbf { r } / ( \mathbf { p } + \mathbf { r } )$ as a metric to strike a balance between the two. We adopt these metrics for the reconstructed 3D human and object meshes to evaluate 3D human and object reconstruction, especially in terms of contact. We obtain a contact map by classifying human vertices within 5cm of the object mesh following [37]. Then, we measure the precision, recall and F-Score between the human contact map and the GT.

Table 1. Quantitative comparison of 3D human and object reconstruction with state-of-the-art methods on BEHAVE [2] and InterCap [23]. Our ScoreHOI model demonstrates superior accuracy, particularly in reconstructing contact interactions.   

<table><tr><td>Datasets</td><td>Methods</td><td>CDhuman↓</td><td>CDobject</td><td>Contactec↑</td><td>Contactrec↑</td><td>Contactres↑</td></tr><tr><td rowspan="4">BEHAVE</td><td>PHOSA [68]</td><td>12.17</td><td>26.62</td><td>0.393</td><td>0.266</td><td>0.317</td></tr><tr><td>CHORE [ [59]</td><td>5.58</td><td>10.66</td><td>0.587</td><td>0.472</td><td>0.523</td></tr><tr><td>CONTHO [37]</td><td>4.99</td><td>8.42</td><td>0.628</td><td>0.496</td><td>0.554</td></tr><tr><td>Ours</td><td>4.85</td><td>7.86</td><td>0.634</td><td>0.586</td><td>0.609</td></tr><tr><td rowspan="4">InterCap</td><td>PHOSA [68]</td><td>11.20</td><td>20.57</td><td>0.228</td><td>0.159</td><td>0.187</td></tr><tr><td>CHORE [59]</td><td>7.01</td><td>12.81</td><td>0.339</td><td>0.253</td><td>0.290</td></tr><tr><td>CONTHO [37]</td><td>5.96</td><td>9.50</td><td>0.661</td><td>0.432</td><td>0.522</td></tr><tr><td>Ours</td><td>5.56</td><td>8.75</td><td>0.627</td><td>0.590</td><td>0.578</td></tr></table>

Table 2. Quantitative comparison of optimization efficiency. While achieving superior performance, our ScoreHOI maintains a higher inference efficiency compared with previous methods.   

<table><tr><td>Methods</td><td>CDhuman</td><td>CDobject↓</td><td>FPS↑</td></tr><tr><td>CHORE [59]</td><td>5.58</td><td>10.66</td><td>0.0035</td></tr><tr><td>VisTracker [61]</td><td>5.24</td><td>7.89</td><td>0.0359</td></tr><tr><td>Ours-Faster</td><td>4.87</td><td>7.95</td><td>2.0080</td></tr><tr><td>Ours</td><td>4.85</td><td>7.86</td><td>0.2895</td></tr></table>

# 4.2. Comparison with State-of-the-art Methods

Performance Comparison. We compare ours with previous state-of-the-art methods with two experimental protocols, BEHAVE [2] and InterCap [23]. Quantitative results are recorded in Table 1. Our method achieves the best performance in most metrics. To harmonize contact precision and recall, where the objective is to maximize both values, we introduce the contact F-Score as a metric to assess the quality of contact reconstruction. Due to the comprehensive physical constraints, we surpass the previous state-ofthe-art method by $9 \%$ on contact F-score. Additionally, the optimization results are visualized in Figure 4, illustrating that our ScoreHOI reconstructs contact relationships with greater rationality and physical plausibility. It is noteworthy that reconstruction inaccuracies often arise in side views given only a single monocular image. Our ScoreHOI effectively mitigates this ill-posed problem by harnessing the prior knowledge within generative models. Efficiency Comparison. To evaluate the inference efficiency of various optimization methods, we measure the Frames Per Second (FPS) on a single Nvidia RTX 4090 GPU. Our ScoreHOI is benchmarked against two established methods, CHORE [59] and VisTracker [61], both of which utilize the Adam Optimizer for reconstructing image and video inputs, respectively. The evaluation results, as shown in Table 2, indicate that our method's efficiency surpasses that of the comparator methods by one to two orders of magnitude while simultaneously delivering superior performance. Furthermore, we assess a more expedient framework with $N = 2$ as detailed in the 4-th row, Table 4. This configuration achieves a substantial seven-fold increase in efficiency with minimal compromise in performance.

Table 3. Ablation studies of modules, conditions and guidance. The CDIR refers to the contact-driven iterative refinement. All of the modules, conditions and guidance strategies we design contribute to the improvement of our model.   

<table><tr><td>Methods</td><td>CDhuman</td><td>Cobect Conacrec↑ Contcec↑ Contctrec ↑</td><td></td><td></td><td></td></tr><tr><td>* Module</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>w/o diffusion</td><td>5.03</td><td>8.48</td><td>0.612</td><td>0.523</td><td>0.588</td></tr><tr><td>w/o CDIR</td><td>4.93</td><td>7.98</td><td>0.628</td><td>0.545</td><td>0.577</td></tr><tr><td>* Condition</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>No condition</td><td>4.94</td><td>8.23</td><td>0.626</td><td>0.549</td><td>0.585</td></tr><tr><td>w/o cG</td><td>4.87</td><td>7.99</td><td>0.628</td><td>0.559</td><td>0.591</td></tr><tr><td>/ </td><td>4.88</td><td>8.03</td><td>0.631</td><td>0.566</td><td>0.597</td></tr><tr><td>* Guidance</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>No guidance</td><td>4.93</td><td>8.01</td><td>0.624</td><td>0.524</td><td>0.570</td></tr><tr><td>w/o Lho</td><td>4.87</td><td>7.95</td><td>0.632</td><td>0.525</td><td>0.574</td></tr><tr><td>w/o Lpt</td><td>4.87</td><td>7.93</td><td>0.619</td><td>0.567</td><td>0.592</td></tr><tr><td>w/o Lof</td><td>4.89</td><td>7.95</td><td>0.631</td><td>0.577</td><td>0.602</td></tr><tr><td>Full model</td><td>4.85</td><td>7.86</td><td>0.634</td><td>0.586</td><td>0.609</td></tr></table>

# 4.3. Ablation Study

We conduct all ablation studies on the BEHAVE [2] test split as a standard benchmark for fair comparison. Effectiveness of Optimizer Modules. We evaluate the influence of the diffusion sampling loop and the proposed contact-driven iterative refinement, as shown in the upper part of Table 3. Utilizing an affordance-aware regressor, our backbone network is capable of achieving satisfactory outcomes independently of the diffusion model. Nonetheless, there remains potential for enhancement, particularly in terms of contact recall. Additionally, we perform an ablation study excluding CDIR, wherein the contact map is not updated during the sampling loops. The results indicate that CDIR contributes to the improvement of both reconstruction accuracy and contact quality. Effectiveness of Conditions. As illustrated in the central

![](images/5.jpg)  
Figure 5. Qualitative results for ablation study. Upper row: the ablation study of $L _ { \mathrm { { h o } } }$ . The inclusion of contact guidance between the $L _ { \mathrm { h o } }$ . The absence of a penetration penalty results in a notable rise in the occurrence of unreasonable interactions.

Table 4. Ablation studies of optimization hyper-parameters. We evaluate the performance across various optimization hyperparameter configurations. The optimal results measured by chamfer-distance are selected to establish our baseline.   

<table><tr><td>N</td><td>τ</td><td>∆t</td><td>CDhuman</td><td>CDobject</td><td>Contactre ↑</td></tr><tr><td>10</td><td>50</td><td>25</td><td>5.80</td><td>10.70</td><td>0.539</td></tr><tr><td>10</td><td>50</td><td>10</td><td>5.22</td><td>8.72</td><td>0.584</td></tr><tr><td>10</td><td>50</td><td>5</td><td>4.99</td><td>8.16</td><td>0.569</td></tr><tr><td>2</td><td>50</td><td>2</td><td>4.87</td><td>7.95</td><td>0.604</td></tr><tr><td>5</td><td>50</td><td>2</td><td>4.86</td><td>7.87</td><td>0.607</td></tr><tr><td>20</td><td>50</td><td>2</td><td>4.87</td><td>7.89</td><td>0.610</td></tr><tr><td>10</td><td>25</td><td>2</td><td>4.87</td><td>7.95</td><td>0.606</td></tr><tr><td>10</td><td>100</td><td>2</td><td>4.88</td><td>8.07</td><td>0.615</td></tr><tr><td>10</td><td>50</td><td>2</td><td>4.85</td><td>7.86</td><td>0.609</td></tr></table>

Analysis of Optimization Hyper-Parameters. We undertake an ablation analysis to investigate the influence of optimization hyper-parameters, including the iteration times $N$ , the intermediate noise level $\tau$ , and the DDIM step size $\Delta t$ , as depicted in Table 4. Our findings indicate that an increase in $N$ results in a higher contact F-Score, attributable to the greater number of refinement steps enhancing the contact fidelity. A similar trend is observed with $\tau$ , where elevated values correspond to improved contact relationships. Regarding $\Delta t$ , more sampling steps is observed to produce substantially superior results. In summary, our results reveal a balance between reconstruction quality and interaction fidelity, and we finally choose $N = 1 0 , \tau = 5 0 , \Delta t =$ 2 as the optimal baseline parameter combination.

# 5. Conclusion and Future Work section of Table 3, the exclusion of either image guidance or geometry guidance from the diffusion model leads to a decrement in reconstruction performance. In comparison to the setting in the first row, which excludes the diffusion module, our contact-driven iterative refinement approach demonstrates the capability to enhance performance even in the absence of additional conditions.

Effectiveness of Physical Guidance. We investigate the impact of varying physical constraints during DDIM sampling, as illustrated at the bottom of Table 3. Experimental findings indicate that the incorporation of three distinct objectives enhances both reconstruction accuracy and contact performance. The omission of $L _ { \mathrm { { h o } } }$ results in a substantial decline in recall of the contact map, thereby diminishing the occurrence of contact interactions in the outputs. Contrarily, the absence of $L _ { \mathrm { p t } }$ , leads to a reduction in contact precision, attributable to an increase in penetrations and the redundant contact of unrelated parts. To substantiate our findings, qualitative results are also presented in Figure 5. In this paper, we have introduced ScoreHOI, an innovative and effective framework tailored for the physically plausible reconstruction of human-object interactions. It integrates diffusion-based prior knowledge for score-guided sampling refinement and incorporates physical constraints for realism. We also propose a contact-driven iterative refinement algorithm to improve the recovery of contact patterns. Extensive evaluations show superior reconstruction accuracy, enhanced physical plausibility, and faster inference than optimization-based methods. Nevertheless, we acknowledge our model has limitations in generalization due to the pre-defined canonical pose of known objects in the training dataset, which prevents the optimization of parameters for objects with undefined canonical pose. Our future research will focus on solving the issue of templatefree unseen objects. We anticipate that our work will contribute a novel perspective to the field of joint reconstruction of human-object interactions, fostering further research and development in this area.

# 6. Acknowledgement

This work was supported by Guangdong Natural Science Funds for Distinguished Young Scholar (No. 2025B1515020012) and Shenzhen Science and Technology Program (JCYJ20240813111903006).

# References

[1] Mykhaylo Andriluka, Leonid Pishchulin, Peter Gehler, and Bernt Schiele. 2D human pose estimation: New benchmark and state of the art analysis. In CVPR, 2014. 2   
[2] Bharat Lal Bhatnagar, Xianghui Xie, Ilya A Petrov, Cristian Sminchisescu, Christian Theobalt, and Gerard Pons-Moll. BEHAVE: Dataset and method for tracking human object interactions. In CVPR, 2022. 2, 5, 6, 7   
[3] Samarth Brahmbhatt, Ankur Handa, James Hays, and Dieter Fox. Contactgrasp: Functional multi-finger grasp synthesis from contact. In IROS, 2019. 2   
[4] Samarth Brahmbhatt, Chengcheng Tang, Christopher D Twigg, Charles C Kemp, and James Hays. Contactpose: A dataset of grasps with object contact and hand pose. In ECCV, 2020. 2   
[5] Zhe Cao, Hang Gao, Karttikeya Mangalam, Qi-Zhi Cai, Minh Vo, and Jitendra Malik. Long-term human motion prediction with scene context. In ECCV, 2020. 2   
[6] Yixin Chen, Siyuan Huang, Tao Yuan, Siyuan Qi, Yixin Zhu, and Song-Chun Zhu. Holistic $^ { + + }$ scene understanding: Single-view 3d holistic scene parsing and human pose estimation with human-object interaction and physical commonsense. In ICCV, 2019. 2   
[7] Hyungjin Chung, Jeongsol Kim, Michael T Mccann, Marc L Klasky, and Jong Chul Ye. Diffusion posterior sampling for general noisy inverse problems. ICLR, 2023. 3, 4   
[8] Hyungjin Chung, Byeongsu Sim, Dohoon Ryu, and Jong Chul Ye. Improving diffusion models for inverse problems using manifold constraints. NeurIPS, 2022. 3   
[9] Enric Corona, Albert Pumarola, Guillem Alenya, Francesc Moreno-Noguer, and Grégory Rogez. Ganhand: Predicting human grasp affordances in multi-object scenes. In CVPR, 2020. 2   
[10] Wenxun Dai, Ling-Hao Chen, Jingbo Wang, Jinpeng Liu, Bo Dai, and Yansong Tang. Motionlcm: Real-time controllable motion generation via latent consistency model. In ECCV, 2024. 2   
[11] Kiana Ehsani, Shubham Tulsiani, Saurabh Gupta, Ali u to predict physical forces by simulating effects. In CVPR, 2020.2   
[12] Mihai Fieraru, Mihai Zanfir, Elisabeta Oneata, Alin-Ionut Popa, Vlad Olaru, and Cristian Sminchisescu. Threedimensional reconstruction of human interactions. In CVPR, 2020. 2   
[13] Mihai Fieraru, Mihai Zanfir, Elisabeta Oneata, Alin-Ionut Popa, Vad Olaru, and Cristian Sminchisescu. Learning complex 3d human self-contact. In AAAI, 2021. 2   
[14] Lin Geng Foo, Jia Gong, Hossein Rahmani, and Jun Liu. Distribution-aligned diffusion for human mesh recovery. In ICCV, 2023. 2   
[15] Shubham Goel, Georgios Pavlakos, Jathushan Rajasegaran, Reconstructing and tracking humans with transformers. In ICCV, 2023. 1   
[16] Mohamed Hassan, Vasileios Choutas, Dimitrios Tzionas, and Michael J Black. Resolving 3d human pose ambiguities with 3d scene constraints. In ICCV, 2019. 2   
[17] Mohamed Hassan, Partha Ghosh, Joachim Tesch, Dimitrios Tzionas, and Michael J Black. Populating 3d scenes by learning human-scene interaction. In CVPR, 2021. 2   
[18] Yana Hasson, Gul Varol, Dimitrios Tzionas, Igor Kalevatykh, Michael J Black, Ivan Laptev, and Cordelia Schmid. Learning joint reconstruction of hands and manipulated objects. In CVPR, 2019. 2   
[19] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016.5   
[20] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. NeurIPS, 2020. 2, 3   
[21] Chun-Hao P Huang, Hongwei Yi, Markus Höschle, Matvey Safroshkin, Tsvetelina Alexiadis, Senya Polikovsky, Daniel Scharstein, and Michael J Black. Capturing and inferring dense full-body human-scene contact. In CVPR, 2022. 2   
[22] Siyuan Huang, Zan Wang, Puhao Li, Baoxiong Jia, Tengyu Liu, Yixin Zhu, Wei Liang, and Song-Chun Zhu. Diffusionbased generation, optimization, and planning in 3d scenes. In CVPR, 2023. 4   
[23] Yinghao Huang, Omid Taheri, Michael J Black, and Dimitrios Tzionas. InterCap: Joint markerless 3D tracking of humans and objects in interaction. In GCPR, 2022. 2, 5, 6, 7   
[24] Yuheng Jiang, Suyi Jiang, Guoxing Sun, Zhuo Su, Kaiwen Guo, Minye Wu, Jingyi Yu, and Lan Xu. Neuralhofusion: Neural volumetric rendering under human-object interactions. In CVPR, 2022. 2   
[25] Angjoo Kanazawa, Michael J Black, David W Jacobs, and Jitendra Malik. End-to-end recovery of human shape and pose. In CVPR, 2018. 1   
[26] Korrawe Karunratanakul, Jinlong Yang, Yan Zhang, Michael JBlack, Krikamol Muandet, and Sy Tang. Grasping field: Learning implicit representations for human grasps. In 3DV, 2020. 2   
[27] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2014. 2, 6   
[28] Nikos Kolotouros, Georgios Pavlakos, Michael J Black, and Kostas Daniilidis. Learning to reconstruct 3d human pose and shape via model-fitting in the loop. In ICCV, 2019.1   
[29] Nikos Kolotouros, Georgios Pavlakos, Dinesh Jayaraman, and Kostas Daniilidis. Probabilistic modeling for human mesh recovery. In ICCV, 2021.   
[30] Jiaman Li, Alexander Clegg, Roozbeh Mottaghi, Jiajun Wu, Xavier Puig, and C Karen Liu. Controllable human-object interaction synthesis. In ECCV, 2025. 4   
[31] Zongmian Li, Jiri Sedlar, Justin Carpentier, Ivan Laptev, Nicolas Mansard, and Josef Sivic. Estimating 3d motion and forces of person-object interactions from monocular video. In CVPR, 2019. 2   
[32] Jinpeng Liu, Wenxun Dai, Chunyu Wang, Yiji Cheng, Yansong Tang, and Xin Tong. Plan, posture and go: Towards open-vocabulary text-to-motion generation. In ECCV, 2024. 2   
[33] Matthew Loper, Naureen Mahmood, Javier Romero, Gerard   
1 Ul-l, alu il J D. il . A lu - person linear model. ACM TOG, 2015. 3 [34] Junzhe Lu, Jing Lin, Hongkun Dou, Ailing Zeng, Yue Deng, Yulun Zhang, and Haoqian Wang. Dposer: Diffusion model as robust 3d human pose prior, 2024. 2 [35] Aron Monszpart, Paul Guerrero, Duygu Ceylan, Ersin Yumer, and Niloy J Mitra. imapper: interaction-guided scene mapping from monocular videos. TOG, 2019. 2 [36] Lea Muller, Ahmed AA Osman, Siyu Tang, Chun-Hao P Huang, and Michael J Black. On self-contact and human pose. In CVPR, 2021. 2 [37] Hyeongjin Nam, Daniel Sungho Jung, Gyeongsik Moon, and Kyoung Mu Lee. Joint reconstruction of 3d human and object via contact-based refinement transformer. In CVPR,   
2024. 2, 4, 5, 6, 7, 1 [38] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. NeurIPS, 2019. 5 [39] Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, Ahmed AA Osman, Dimitrios Tzionas, and Michael J Black. Expressive body capture: 3d hands, face, and body from a single image. In CVPR, 2019. 2, 3 [40] Xiaogang Peng, Yiming Xie, Zizhao Wu, Varun Jampani, Deqing Sun, and Huaizu Jiang. Hoi-diff: Text-driven synthesis of 3d human-object interactions using diffusion models. arXiv preprint arXiv:2312.06553, 2023. 4 [41] Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J Guibas. Pointnet++: Deep hierarchical feature learning on point sets in a metric space. NeurIPS, 2017. 1 [42] Guocheng Qian, Yuchen Li, Houwen Peng, Jinjie Mai, Hasan Hammoud, Mohamed Elhoseiny, and Bernard Ghanem. Pointnext: Revisiting pointnet $^ { + + }$ with improved training and scaling strategies. In NeurIPS, 2022. 5, 1 [43] Davis Rempe, Leonidas J Guibas, Aaron Hertzmann, Bryan Russell, Ruben Villegas, and Jimei Yang. Contact and human dynamics from monocular video. In ECCV, 2020. 2 [44] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-resolution image synthesis with latent diffusion models. In CVPR, 2022. 2 [45] Javier Romero, Dimitris Tzionas, and Michael J Black. Embodied hands: Modeling and capturing hands and bodies together. TOG, 2017. 3 [46] Manolis Savva, Angel X Chang, Pat Hanrahan, Matthew Fisher, and Matthias NieBner. Pigraphs: learning interaction snapshots from observations. TOG, 2016. 2 [47] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. ICLR, 2021. 2, 3 [48] Jiaming Song, Arash Vahdat, Morteza Mardani, and Jan Kautz. Pseudoinverse-guided diffusion models for inverse problems. In ICLR, 2023. 3 [49] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. ICLR, 2021. 2, 3 [50] Anastasis Stathopoulos, Ligong Han, and Dimitris Metaxas. Score-guided diffusion for 3d human recovery. In CVPR,   
2024. 2, 3, 4, 5 [51] Guoxing Sun, Xin Chen, Yizhang Chen, Anqi Pang, Pei Lin, Yuheng Jiang, Lan Xu, Jingyi Yu, and Jingya Wang. Neural free-viewpoint performance rendering under complex human-object interactions. In ACM MM, 2021. 2   
[52] Omid Taheri, Nima Ghorbani, Michael J. Black, and Dimitrios Tzionas. GRAB: A dataset of whole-body human grasping of objects. In ECCV, 2020. 2   
[53] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In NeurIPS, 2017. 5   
[54] Yiqin Wang, Haoji Zhang, Yansong Tang, Yong Liu, Jiashi Feng, Jifeng Dai, and Xiaojie Jin. Hierarchical memory for long video qa. arXiv preprint arXiv:2407.00603, 2024. 2   
[55] Zhenzhen Weng and Serena Yeung. Holistic 3d human and scene mesh estimation from single view images. In CVPR, 2021.2   
[56] Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao. 3d shapenets: A deep representation for volumetric shapes. In CVPR, 2015. 1   
[57] Xianghui Xie, Bharat Lal Bhatnagar, Jan Eric Lenssen, and Gerard Pons-Moll. Template free reconstruction of humanobject interaction with procedural interaction generation. In CVPR, 2024. 2   
[58] Xianghui Xie, Bharat Lal Bhatnagar, Jan Eric Lenssen, and Gerard Pons-Moll. Template free reconstruction of humanobject interaction with procedural interaction generation. In CVPR, 2024. 2, 1   
[59] Xianghui Xie, Bharat Lal Bhatnagar, and Gerard Pons-Moll. CHORE: Contact, human and object reconstruction from a single RGB image. In ECCV, 2022. 2, 4, 6, 7   
[60] Xianghui Xie, Bharat Lal Bhatnagar, and Gerard Pons-Moll. Visibility aware human-object interaction tracking from single RGB camera. In CVPR, 2023. 2, 4   
[61] Xianghui Xie, Bharat Lal Bhatnagar, and Gerard Pons-Moll. Visibility aware human-object interaction tracking from single rgb camera. In CVPR, 2023. 7   
[62] Xianghui Xie, Jan Eric Lenssen, and Gerard Pons-Moll. Intertrack: Tracking human object interaction without object templates. 2024. 1   
[63] Yiming Xie, Varun Jampani, Lei Zhong, Deqing Sun, and Huaizu Jiang. Omnicontrol: Control any joint at any time for human motion generation. In ICLR, 2024. 2   
[64] Yufei Xu, Jing Zhang, Qiming Zhang, and Dacheng Tao. ViTPose: Simple vision transformer baselines for human pose estimation. In NeurIPS, 2022. 5   
[65] Hu Ye, Jun Zhang, Sibo Liu, Xiao Han, and Wei Yang. Ipadapter: Text compatible image prompt adapter for text-toimage diffusion models, 2023. 5   
[66] Hongwei Yi, Chun-Hao P Huang, Dimitrios Tzionas, Muhammed Kocabas, Mohamed Hassan, Siyu Tang, Justus Thies, and Michael J Black. Human-aware object placement for visual environment reconstruction. In CVPR, 2022. 2   
[67] Haoji Zhang, Yiqin Wang, Yansong Tang, Yong Liu, Jiashi Feng, and Xiaojie Jin. Flash-vstream: Efficient realtime understanding for long video streams. arXiv preprint arXiv:2506.23825, 2025. 2   
[68] Jason Y Zhang, Sam Pepose, Hanbyul Joo, Deva Ramanan, Jitendra Malik, and Angjoo Kanazawa. Perceiving 3D human-obiect spatial arrangements from a single image in the wild. In ECCV, 2020. 1, 6, 7   
[69] Jason Y. Zhang, Sam Pepose, Hanbyul Joo, Deva Ramanan, Jitendra Malik, and Angjoo Kanazawa. Perceiving 3d human-object spatial arrangements from a single image in the wild. In ECCV, 2020. 2   
[70] Siwei Zhang, Yan Zhang, Qianli Ma, Michael J Black, and Siyu Tang. Place: Proximity learning of articulation and contact in 3d environments. In 3DV, 2020. 2   
[71] Xiaohan Zhang, Bharat Lal Bhatnagar, Sebastian Starke, Vladimir Guzov, and Gerard Pons-Moll. Couch: Towards controllable human-chair interactions. In ECCV, 2022. 2   
[72] Chengfeng Zhao, Juze Zhang, Jiashen Du, Ziwei Shan, Junye Wang, Jingyi Yu, Jingya Wang, and Lan Xu. I'm hoi: Inertia-aware monocular capture of 3d human-object interactions. In CVPR, 2024. 5, 6   
[73] Yi Zhou, Connelly Barnes, Jingwan Lu, Jimei Yang, and Hao Li. On the continuity of rotation representations in neural networks. In CVPR, 2019. 4   
[74] Yixuan Zhu, Ao Li, Yansong Tang, Wenliang Zhao, Jie Zhou, and Jiwen Lu. Dpmesh: Exploiting diffusion prior for occluded human mesh recovery. In CVPR, 2024. 1, 2   
[75] Yixuan Zhu, Haolin Wang, Ao Li, Wenliang Zhao, Yansong Tang, Jingxuan Niu, Lei Chen, Jie Zhou, and Jiwen Lu. Instarevive: One-step image enhancement via dynamic score matching. In ICLR, 2025. 3   
[76] Yixuan Zhu, Wenliang Zhao, Ao Li, Yansong Tang, Jie Zhou, and Jiwen Lu. Flowie: Efficient image enhancement via rectified flow. In CVPR, 2024. 3

# ScoreHOI: Physically Plausible Reconstruction of Human-Object Interaction via Score-Guided Diffusion

Supplementary Material In this appendix, we describe the DDIM sampling loop in our methods in pseudo-code in Section A. We also provide additional detailed implementations and qualitative comparisons in Section B and Section D. Furthermore, we append rendered 3D object models and the source code along with this appendix.

# A. DDIM Refinement Loop

For a deeper understanding of the DDIM sampling loop, we illustrate a pseudo-code implementation in Algorithm A. The algorithm describe the DDIM Loop in detail.

# B. Detailed Implementations

We employ the PointNeXt [42] model, pre-trained on the ModelNet40 [56] dataset, as our affordance-aware regressor. ModelNet40 is a extensively utilized benchmark dataset for 3D shape classification and retrieval tasks, comprising 12,311 CAD models across 40 distinct object categories, including airplanes, chairs, tables, and cars. PointNeXt maintains the fundamental hierarchical architecture of PointNet $^ { - + }$ [41] while integrating contemporary deep learning techniques to augment performance and efficiency. Through the incorporation of point cloud awareness, the model is capable of comprehending object geometry across a variety of human-object interaction scenarios. For the contact predictor and mesh regressor, we leverage the contact estimation transformer and the contact-based refinement methodology proposed by [37]. The contact predictor receives human and object feature tokens, along with estimated human and object mesh vertices, as inputs to generate contact masks through two symmetrical 4-layer transformer blocks. During our contact-driven iterative refinement process, we iteratively update the human and object meshes to enhance contact interactions, thereby refining the contact prediction results with each iteration. After $N$ iterations of optimization, we obtain the $\pmb { x } _ { 0 } ^ { N }$ for final refinement. The mesh regressor, also constructed with two analogous 4-layer transformer branches, takes the updated human and object feature tokens and contact masks as input to further refine the mesh results.

# C. Ablation Studies

About Diffusion Priors. We demonstrate the generation results starting from different noise levels without physical guidance, as shown in the Figure A. The IG-Adapter successfully constructs plausible human-object interaction patterns, confirming that the diffusion model has acquired a valid prior distribution. Table A. Efficiency comparision with template-free methods.   

<table><tr><td></td><td>HDM</td><td>InterTrack</td><td>ScoreHOI</td><td>ScoreHOI-F</td></tr><tr><td>FPS↑</td><td>0.0047</td><td>0.0012</td><td>0.2895</td><td>2.0080</td></tr></table>

![](images/6.jpg)  
Input Image τ = T τ = 0.5T τ = 0.25 τ = 0.05 Input Image τ = T τ = 0.5 τ = 0.25 τ = 0.05T Figure A. Generation results starting from different noise levels.

Comparison with template-free methods. We compared ScoreHOI with template-free methods, including HDM [58] and InterTrack [62]. As shown in the Table A, ScoreHOI surpasses these methods in efficiency. Additionally, these methods output point clouds, which are less practical for applications like robotic data collection due to the additional time and uncertainty introduced when fitting SMPL parameters.

# D. More Qualitative Results

To further substantiate the performance of our ScoreHOI, we present additional qualitative results of human-object interaction reconstruction in Figure B. Our methodology exhibits superior performance across diverse interaction patterns, such as sitting, carrying, grasping, and lifting. By incorporating physical constraints, our ScoreHOI achieves a higher degree of accuracy and physical fidelity in the reconstruction of human and object meshes.

# E. Geometry Model Demos

The demo 3D geometry mesh results are available under the demo directory. Reviewers are able to assess the performance from any perspective utilizing software such as MeshLab or Blender.

# Algorithm A Score-Guided DDIM refinement loop

1: Input: latent parameters $\pmb { x } _ { 0 } ^ { n }$ at step $n$ , denoising model $\epsilon _ { \phi }$ , image features $c _ { \mathrm { I } }$ , geometry features $\mathbf { c _ { G } }$ , gradient step size $\rho$ noise level $\tau$ , DDIM step size $\Delta t$ , estimated caontact masks $\{ \mathbf { M } _ { i } \} _ { i \in \{ \mathrm { h , o , f } \} }$ Output: latent parameters $\pmb { x } _ { 0 } ^ { n + 1 }$ for next sampling step $n + 1$ 3: $\pmb { x } _ { \tau } = \mathrm { D D I M I n v e r t } ( \pmb { x } _ { 0 } ^ { n } , \pmb { c } _ { \mathrm { I } } , \pmb { c } _ { \mathrm { G } } )$ Run DDIM inversion until noise level $\tau$ 4: for $t = \tau$ to $\Delta t$ with step size $\Delta t$ do 5: $\tilde { \epsilon } \gets \epsilon _ { \phi } ( \mathbf { { x } } _ { t } ^ { n } , t , \mathbf { { c } } _ { \mathrm { { I } } } , { { c } } _ { \mathrm { { G } } } )$ Predict noise 6: Initialize computational graph for $\mathbf { \Delta } \mathbf { x } _ { t } ^ { n }$ 7: $\begin{array} { r l } & { \dot { x ^ { n } } _ { 0 } \gets \frac { 1 } { \sqrt { \alpha _ { t } } } \big ( \dot { x } _ { t } ^ { n } - \sqrt { 1 - \alpha _ { t } } \big ) \tilde { \epsilon } } \\ & { L _ { \mathcal { P } } \gets \mathrm { P h y s i c a l G u i d a n c e } ( \hat { x } _ { 0 } ^ { n } , \{ \mathbf { M } _ { i } \} _ { i \in \{ \mathrm { h , o , f } \} } \big ) } \\ & { \tilde { \epsilon } ^ { ' } \gets \tilde { \epsilon } + \rho \sqrt { 1 - \alpha _ { t } } \nabla _ { x _ { t } ^ { n } } L _ { \mathcal { P } } } \\ & { \dot { x ^ { n } } _ { 0 } ^ { ' } \gets \frac { 1 } { \sqrt { \alpha _ { t } } } ( x _ { t } ^ { n } - \sqrt { 1 - \alpha _ { t } } ) \tilde { \epsilon } ^ { ' } } \\ & { x _ { t - \Delta t } ^ { n } \gets \sqrt { \alpha _ { t - \Delta t } } \hat { x } _ { 0 } ^ { n ^ { ' } } + \sqrt { 1 - \alpha _ { t - \Delta t } } \tilde { \epsilon } ^ { ' } } \end{array}$ $\triangleright$ Predict one-step denoised result 8: $\triangleright$ Compute physical guidance loss 9: Compute modified noise after score-guidance 10: Predict one-step denoised result with modified noise 11: . DDIM sampling step 12:end for 13 xn+1 $\pmb { x } _ { 0 } ^ { n + 1 }  \hat { \pmb { x } } _ { 0 } ^ { n ^ { \prime } }$ Update $\pmb { x } _ { 0 } ^ { n }$ for next generation 14: return $\pmb { x } _ { 0 } ^ { n + 1 }$

![](images/7.jpg)  
Figure B. Extra Qualitative comparisons. We highlight the contact interaction within each picture.