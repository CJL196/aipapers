# 桌边的一个席位够吗？让教师和学生参与教育领域机器学习数据集的规范制定

梅坦，斯坦福大学，美国  
韩颂，斯坦福大学，美国  
达阔·王，东北大学，美国  
哈里哈兰·苏布拉莫尼亚，斯坦福大学，美国

尽管机器学习在教育领域的应用越来越普遍，但课堂上依然出现许多关于公平性、问责制和透明性的问题，以及对数据隐私和知情同意的担忧。这些问题的一个原因是缺乏对教育中复杂动态的理解，包括师生互动、协作学习和课堂环境。为了克服这些挑战，充分利用机器学习在教育中的潜力，软件从业者需要与教育工作者和学生紧密合作，深入理解数据的背景（机器学习应用的支撑），并共同定义机器学习数据规格。为了更深入地理解这种协作过程，我们与机器学习软件从业者、教育工作者和学生进行了十次共同设计会议。在这些会议中，教师和学生与机器学习工程师、用户体验设计师和法律从业者合作，定义特定机器学习应用的数据集特征。我们发现，利益相关者会根据他们的领域和程序知识对数据进行背景化，主动设计数据要求以降低潜在危害和数据可靠性问题，展现基于角色的协作策略和贡献模式。此外，我们发现，除了参与讨论之外，有意义的利益相关者参与机器学习还需要结构化的支持：定义持续迭代和共同评估的流程、共享的上下文数据质量标准，以及为技术和非技术利益相关者跨越专业界限提供的信息支架。

CCS 概念：$\bullet$ 计算机系统组织 嵌入式系统；冗余；机器人；$\bullet$ 网络 网络可靠性。

附加关键字和短语数据集，神经网络，注视检测，文本标注

# ACM 参考格式：

梅坦、汉索尔·李、大阔·王和哈里哈兰·苏布拉蒙亚姆。2023。坐在桌子上就足够了吗？让教师和学生参与教育领域机器学习的数据集规范。在。ACM，纽约，纽约州，美国，32页。https://doi.org/XXXXXXX.XXXXXXX

# 1 引言

教育是一个复杂而动态的系统。然而，机器学习（ML）在教育中的应用依赖于概括性的方式，狭隘地理解教育知识，以分析学习者的行为、互动和表现。因此，在学校管理、教学和学习中采用机器学习应用导致了公平性、问责制、透明度和对从业者及弱势学生群体影响的实用性问题。伤害包括推荐系统中的系统性不平等和高风险的自动决策、面部识别系统中的监视和公民权利问题、数据隐私问题以及学生同意倾向的差异。

这些问题根源于机器学习设计和开发面临的基本挑战，包括缺乏明确的政策级指导[79]、教师教育和参与机器学习开发的不足[10, 73, 78]、包容性和高质量数据系统的发展不足[24, 56]以及在数据收集、使用和传播中的缺乏伦理规制和透明度[61]。传统的机器学习开发过程低估了可信训练数据和数据集问责制的关键作用，并在很大程度上将数据视为既定事实[76]。

此外，目前的工程流程限制了与领域专家和最终用户（如教育工作者和学生）的参与，错失了现实世界数据的重要上下文特征。当领域专家被纳入时，他们仅在关键的数据相关决策之后才会在机器学习开发中达成一致。虽然研究人员已经为下游数据评估和文档创建了指南（例如，数据集说明书），但上游数据规范中的标准实践仍未定义。解决这些问题需要解决机器学习创新、工程优先事项与教师和学生需求之间的紧张关系。具体而言，为了在教育场景中创造符合伦理和以人为本的机器学习体验，我们需要教育工作者、学生和机器学习从业者之间的早期合作。

最近在机器学习实践中的方法论转变，重新重视训练数据的设计和质量（即数据中心的人工智能），为教师和学生早期参与机器学习数据管道的设计提供了机会。然而，单纯的参与是不够的。我们认为，要真正让教师和学生参与其中，必须提供必要的培训和资源，让他们理解并为设计过程做出贡献。这包括确保他们的输入和反馈被考虑，帮助他们解决知识差距，结合领域需求来具体化数据需求，以及就范围和可概括性进行权衡协商。此外，机器学习软件从业者应修订其工作实践，优先考虑领域知识和与领域专家的合作。

在这项工作中，我们探讨教师和学生是否以及如何与机器学习从业者合作，从零开始定义数据需求（机器学习模型的基础）。虽然之前的研究主要集中在与教师共同设计机器学习应用程序（例如，[32]），我们的工作则关注于数据集属性、标签和数据收集流程的协作规范（即数据集数据表中的项目 [25]）。我们提出以下研究问题：

•RQ1: 参与共同设计数据规范的多样化利益相关者带来了什么？ RQ2: 我们如何能够系统地支持和放大多样化利益相关者在机器学习数据规范过程中的声音？

为了研究这些研究问题，我们进行了系列共同设计会议，邀请了各领域的专家和利益相关者共同为教育领域的机器学习应用进行数据规范化设计。我们的研究共有四十名参与者，涵盖了机器学习工程师、教师、学生、用户体验设计师和法律专家等角色。在这些会议中，利益相关者定义了数据集特征，讨论了代表性和验证标准，开发了标签，并为多个常见应用场景（例如，学生辍学风险预测、自动化作文评分、学生参与度图像分类）计划了伦理数据收集策略。我们发现，教师和学生在上下游数据相关决策的背景化中发挥着至关重要的作用，并支持在数据收集和标注过程中识别潜在的偏见和可靠性威胁。此外，我们还识别出加深利益相关者合作以确保有效参与的挑战和需求。

总之，我们的工作为数据驱动的人工智能新兴实践、人本中心人工智能中的协作过程以及关于教育中机器学习应用的从业者需求的日益增长的文献做出了贡献。通过我们的共同设计会议，我们强调了参与决策的机会与局限性，并讨论了未来研究中设计协作过程以吸引教育领域利益相关者的方向。我们还讨论了我们的研究结果的影响，包括制定共享标准、信息支架以及支持工具，以支持多利益相关者对机器学习数据规范和评估的贡献。

# 2 相关工作

机器学习系统可能创造或加剧偏见、不公平以及下游伦理伤害的潜力已引起各学科的学术关注。本研究的重点在于调查研究和工业环境中构建这些机器学习系统的工程过程。以往的研究强调了组织采用工具和内部流程以支持更公平系统的负责任开发和维护的紧迫需求。这些行动呼吁强调了两个高级实践：专注于数据工作和在机器学习应用的设计和开发中涉及上下文。本文首先综合现有的关于机器学习数据实践的文献，然后将我们的工作置于当前数据文档和利益相关者合作的方法中。

# 2.1 机器学习数据管道与当前实践

与软件应用开发相比，机器学习应用需要复杂的数据发现和管理 [2]。机器学习生命周期始于数据管理，基于一组系统级要求，这产生了用于驱动模型学习、模型验证和模型部署阶段的训练数据集 [4, 28]。数据管理由多个步骤组成，包括数据获取、数据标注、数据预处理、数据增强和数据验证 [1]。在数据获取过程中，收集示例可能采用搜索和索引现有数据集的形式，从现有数据集中扭曲和派生合成示例，或通过数据生成技术创建数据集 [95]。在数据标注过程中，标记示例可能涉及利用现有标签，或手动或自动生成新标签 [95]。数据管道还包括存储和移动数据所涉及的设备和过程 [53]。用于开发机器学习系统的数据的创建通常需要昂贵的手工工作，但这项工作对所生成模型的可信性产生关键影响 [47]。

尽管数据管理的复杂性和重要性，当前行业实践依赖于以模型为中心的发展，其中工程资源主要用于迭代模型架构或训练过程以提升基准性能 [47]。先前的研究发现系统设计中存在“随意”的做法 [59, 76]，团队内部角色和职责模糊 [75]，以及依赖个别工程师识别问题和解决伦理问题 [69]。此外，传统工程流程限制了与领域专家和最终用户的参与，将技术开发工作与理解最终用户需求分开 [85]，并优先考虑技术能力而非从业者和现实世界环境的问题 [8, 38]。这些临时和以技术为中心的工程实践导致了无序的数据管理，在此过程中，关于数据定义的决策在一系列额外决策、机会、即兴发挥和假设下被遗忘 [52]。正在开发机器学习系统的从业者目前在数据管道的多个步骤中面临挑战，包括查找、理解、准备和验证数据 [65, 66]。对数据集开发工作的审计发现了重视效率而非细致的做法 [60]，导致绝大多数数据集未能达到质量标准 [54]。在传统机器学习开发中，数据中心的做法被低估，导致下游累积的负面影响 [72, 76]。

# 2.2 数据中心人工智能与数据文档

为了解决以模型为中心的人工智能实践的局限性，最近的研究开始关注以数据为中心的实践，提供支持工具以维护数据存储库并促进数据注释和验证 [47]。以数据为中心的人工智能研究主要通过创建大量框架来解决低质量数据的下游危害，以促进通过清晰的文档实践实现数据的问责和透明度 [3, 7, 15, 18, 25, 68, 71, 93]。数据集文档文献引入了标准化流程，要求数据集附带信息，以识别其动机、背景、组成、特征、收集过程、偏见、推荐用途等信息（例如，DataSheets） [25]。文档框架帮助工程师理解训练数据中的伦理问题 [12]，并提供支持数据质量标准问责的重要指导。

然而，优先考虑数据工作也需要在首位支持高质量数据集的收集和整理，并解决定义数据集需求的上游工作。理想的数据中心实践首先应根据应用需求进行规范和定义数据要求，但机器学习系统通常面临不完整或误解的要求。早期在数据管道中支持数据集需求规范的实践在数据中心机器学习文献中研究得较少。在教育环境中，机器学习开发初期适当的数据规范设计是减轻高风险领域伦理危害的关键。以往对教育中人工智能公平性的评估工作鼓励研究审视机器学习问题和数据收集程序的定义，并评估训练数据的质量。我们的研究调查了数据规范的前瞻性过程，预见了文档框架的评估组成部分。

# 2.3 领域背景与利益相关者协作

数据与地点和社区密不可分[89]。数据中编码的上下文以及数据生产的上下文对于理解数据集及其下游应用至关重要[92]。将数据置于其时间、地理和社会背景、学科规范及世界代表性中，是理解数据的关键组成部分[41]。先前研究呼吁纳入更多领域知识[91]，开发特定领域的性能指标[34, 81]，以及创建文档框架以记录特定上下文的预期使用案例[15]。

越来越多的研究关注通过协作和利益相关者参与来提高领域背景。人工智能和人机交互社区越来越呼吁在机器学习系统的设计、开发和维护中更多地参与利益相关者。然而，协作实践常常受到领域界限和实践社区交叉处的权力动态的影响。

首先，社交应用中的机器学习合作涉及跨学科沟通的复杂性。根植于专业孤岛的开发实践限制了学科之间的沟通。Subramonyam等人[86]研究了工程师和用户体验设计师之间的共同创造过程，发现工程师与领域从业者之间存在关注点分离。技术专家独立探索机器学习能力，同时在关于人类行为和上下文需求方面做出错误假设。Passi和Jackson[58]同样发现数据科学和商业分析专家之间在系统问责任务上的关注点分离。Mao等人[48]研究了数据科学家与生物医学科学家之间的合作实践，发现这些不同的角色在研究项目上常常难以建立共同基础。利益相关者合作的工作还强调了不同知识形式之间翻译的重要性[97]。Hou等人[35]在一次公民数据黑客松中研究了技术和非技术工人之间的合作角色，指出不同利益相关者讲不同的语言。合作迫使组织者理解数据科学和上下文，以便作为中介，跨学科翻译需求。领域利益相关者的参与需要透明和可解释的技术说明[21]，但用于教育利益相关者关于机器学习的材料很少[10]。由于持续的知识差距，领域专家在机器学习开发和决策中的参与面临障碍[85]。

其次，利益相关者与技术设计者之间的创造性合作需要跨实践社区协商价值观。利益相关者参与协作设计的努力源于参与设计的传统，该传统强调通过改变现有权力结构和在技术设计者与受影响用户之间创造一个混合空间来实现创新的民主化议程。公平和基于社区的参与设计强调对社区需求和实践敏感的方法。它们旨在促进创造力、学习和文化生产，以设计被社区指标视为成功的解决方案。

在教育领域，参与式设计方法在AI工具开发中很少被采用。尽管利益相关者的参与对创造有用且社会负责任的产品至关重要，教师在技术讨论中常常被边缘化，仅在机器学习系统实施过程中作为附属角色参与。Michos等人通过与教育从业者合作，了解实际挑战，并通过研讨会和实施设置反复评估解决方案，遵循基于设计的研究结构。Holstein等人让教师和学生参与“参与式快速约会”，以征求对教育中AI应用的设计反馈。教育领域的其他研究通过需求发现访谈和产品设计反馈来让最终用户参与。尽管这样的咨询是有价值的，但教师和学生往往作为最终用户只以有限的方式参与。在机器学习开发的较后阶段才参与，距离关键的数据相关决策已作出很久，想象公平设计解决方案的机会受到限制。

在机器学习管道中，数据规范是一个独特的高杠杆阶段，涉及利益相关者的参与。最终用户和领域专家在明确数据中被重视的内容方面可能发挥关键作用。当早期参与时，多方利益相关者的参与可能为收集和标注程序的设计、验证和评估措施、建模选择以及数据集和应用的下游使用和维护提供重要见解。通过在教育领域中涉及多样化的利益相关者，我们的工作进一步探讨了教师、学生、工程师、设计师和法律专业人士在共同设计数据规范中的扩展角色和贡献。我们将工作定位于机器学习数据规范设计中利益相关者协作这一尚未深入研究的交汇点，置于教育这一独特且高风险的背景中。

# 3 方法论

为了研究利益相关者之间的协作互动，我们与工程师、设计师、法律专业人士、领域专家和数据主体（即将被收集数据的个体）进行了结构化的共同设计研讨会。在每个研讨会中，我们向参与者展示了机器学习在教育领域的潜在应用，并请他们共同生成机器学习模型的数据规范。研讨会通过Zoom在线举行，每个利益相关者角色由一个人代表（共进行了10个研讨会）。每个研讨会的时长为120分钟。我们机构的伦理审查委员会批准了本研究。参与是自愿的，所有参与者因其参与而获得了50美元的补偿。

# 3.1 参与者

我们旨在每个会议中招募五个角色中的一个参与者。由于我们的研究基于教育领域，我们在领域专家角色中参与了教育工作者，在数据主体角色中参与了学生。除了学生角色，其他所有角色要求参与者至少具备一年相关的专业经验。我们通过直接电子邮件、大学部门和科技公司的邮件列表以及与人工智能、伦理和设计交叉领域相关的团体分享的社交媒体帖子招募参与者。如表1所示，除了一个会议外，所有会议都有来自五个角色中的四个角色的参与者。具有法律和伦理人工智能领域专业知识的参与者较难招募，因为这是一个新兴的实践角色。然而，在制定研究协议时，我们咨询了一位法律人工智能学者，以为小组提供充分的指导，帮助他们思考法律和伦理要求和限制。此外，在两个或更多预定参与者缺席的情况下，我们重新安排会议，并补偿在场者额外的$20作为时间补偿（总计3个会议）。对于第10个会议，我们决定继续进行，尽管只有三位参与者，因为法律专业人士较难招募和安排。总的来说，我们进行了40名参与者的研讨会。

Table 1. Each workshop session is listed with participants by role ( $\mathrm { E = }$ machine learning engineer, ${ \mathsf { T } } =$ teacher, ${ \mathsf { S } } =$ student, $\boldsymbol { \mathrm { D } } =$ designer, ${ \mathsf { L } } =$ legal/ethics professional) and the associated design scenario. Years of experience in their fields of expertise are indicated parenthetically for each professional stakeholder.   

<table><tr><td>会话</td><td>设计场景</td><td>参与者（经验年数）</td></tr><tr><td>1</td><td>学生参与度图像分类</td><td>E（25年），T（18年），S，D（2年）</td></tr><tr><td>2</td><td>学生参与度图像分类</td><td>E（3年），T（30年），S，D（2年）</td></tr><tr><td>3</td><td>学生参与度图像分类</td><td>E（15年），T（2年），S，L（7年）</td></tr><tr><td>4</td><td>基于简历的职业推荐</td><td>E（5年），T（9年），S，D（1年）</td></tr><tr><td>5</td><td>学生辍学风险预测</td><td>E（3年），T（3年），S，D（5年）</td></tr><tr><td>6</td><td>学生辍学风险预测</td><td>E（3年），T（3年），S，D（1年）</td></tr><tr><td>7</td><td>学生辍学风险预测</td><td>E（3年），T（8年），S，D（2年），L（5年）</td></tr><tr><td>8</td><td>自动化作文评分</td><td>E（2年），T（5年），S，D（1年）</td></tr><tr><td>9</td><td>自动化作文评分</td><td>E（7年），T（7年），S，D（2年）</td></tr><tr><td>10</td><td>自动化作文评分</td><td>E（1年），T（3年），L（2年）</td></tr></table>

# 3.2 研讨会协议

受到先前研究协作人工智能设计的启发，我们选择将我们的工作坊聚焦于人工智能在教育中的具体应用。此外，我们使用了关于以人为本的数据规范和数据文档的当前指南作为起点，来制定我们的工作坊协议。具体而言，第一位和第二位作者分析了《数据集数据表》中的主题和问题，以识别那些可以从多利益相关者输入中受益的问题，并且可以在实际数据收集之前主动定义。例如，关于每个数据实例属性、数据集代表性的含义以及收集程序的问题都可以事先描述。相比之下，关于样本大小和训练集与测试集之间数据分配的问题最好在机器学习流程的后期阶段进行定义。如图1所示，这些问题对应我们的工作坊协议的五个主要主题，包括（1）动机，（2）组成，（3）收集，（4）评估，以及（5）持续使用。此外，为了支持围绕每组问题的讨论，我们根据以人为本的数据指南开发了指导性提示和示例。

![](images/1.jpg)  
FOveviwour study protool, icuding desg bri and high-leve jective or each  thea co-design sections.

为了建立目标和共同语言，研讨会开始时展示了教育领域中的机器学习设计场景以及数据在预期应用中的作用的高层次解释。接下来，我们向参与者提供了一份数据规范文档，其中包含了每个数据管道阶段的考虑问题。虽然小组共同进行了口头头脑风暴，一名研究协调员主持了会议并在Zoom上共享屏幕记录了共识要点在数据规范文档中。我们的目标是鼓励不同利益相关方之间关于优先事项、权衡和伦理问题的讨论，以定义数据需求。在每次研讨会结束后，我们向参与者提出了一系列反思问题，以了解协作设计过程中面临的挑战以及改善协作所需的额外工具或支持。我们记录了每次研讨会的会议，并收集了生成的数据规范文档。以下是我们协议的主要步骤。

3.2.1 设计简报。我们为研讨会的数据规范活动准备了四个机器学习应用设计场景。这些场景的灵感来源于最近在教育领域流行的机器学习应用，我们的选择偏向于使用不同形式输入数据的场景。我们的目标是了解不同数据类型如何支持和挑战协作。这些场景包括使用图像数据的学生参与分类系统、使用表格学业记录数据的学生辍学预警系统，以及使用文本输入数据的自动作文评分系统。最初，我们打算将基于简历的职业推荐作为机器学习中文本数据的一种应用。然而，根据第4节的反馈，我们发现K-12教育工作者对这一应用案例不太熟悉。因此，在剩下的会议中，我们选择了基于人工智能的作文评分，这对K-12教师来说更为熟悉。在每个场景展示中，研讨会参与者被展示了模型的输入和输出示例，以及使用案例和应用界面的视觉模拟。我们通过一个包含样本特征和标签的数据管道插图，广泛描述了预期的训练数据，同时注意到留给参与者考虑的许多不确定性。然后，研讨会参与者被呈现了一个数据规范文档和共同设计任务。我们将数据规范文档解释为软件团队收集和评估用于构建所指定机器学习应用的训练数据的指南。我们还强调参与者应协作工作，寻求彼此的观点和专业知识，充分发挥各自独特的利益相关者角色来做出设计决策。我们的研究材料作为论文的补充资料。

3.2.2 动机。在协议的第一阶段，参与者被要求定义使用案例和ML应用程序的应用上下文的细节。在这一阶段的问题中，利益相关者被询问以识别将直接与系统互动、直接受到系统操作影响或可能对系统的创建、使用或管理有利益相关的人。我们提供了关于定义直接和间接利益相关者的指导，并促使参与者具体说明相关用户和环境的特征。最后，我们邀请参与者进行头脑风暴，详细阐述具体场景，以定位设计任务并建立共同基础，以支持后续步骤。

3.2.3 组成。在协议的组成阶段，参与者首先被要求考虑训练数据集应包含的属性、特征和示例实例。我们提示各个小组，数据集可以包含多种类型或媒介的示例（例如文件、照片、人员、国家等），并建议各组以生成性方式进行探讨，关注可能预测目标机器学习场景结果的特征（例如，“您认为哪些因素可能会导致学生有辍学的风险？”）。接下来，参与者的任务是设计与每个示例最相关的类别和标签。我们提醒各组，他们选择的标签方案将定义机器学习模型输出的结构，并提示参与者考虑他们在前一阶段选择的具体背景。重要的是，参与者被要求定义数据集在何种条件下能够代表场景用户，包括子群体的代表性和分布。在这一阶段结束时，利益相关者就示例、特征、标签方案和代表培训数据集中重要特征的相对数据量达成一致。

3.2.4 收集。在协议的收集阶段，参与者被要求根据前一步中定义的规格设计数据收集程序。我们提示可以通过收集相关社区的新原始数据或访问和重新利用现有数据源来实现这些方法。我们解释道，数据收集机制还可以包括受试者的直接报告（例如，调查响应）或从其他数据推断和推导（例如，词性标记）。我们还要求参与者考虑数据收集的时间框架和参与收集过程的人，以及如何请求和提供数据集中的个人同意。随后，参与者被要求设计标注数据集中示例的程序，具体说明参与者（例如，领域专家、众包工作者、学生）、补偿和时间表。最后，我们邀请参与者集思广益，提出应采取的预防措施，以避免数据收集过程引入的偏见，并修订收集程序以应对这些风险。在这一阶段结束时，利益相关者达成了一套数据收集和标注的规格，并为下一步做好数据形态的预期准备。

3.2.5 数据质量评估与数据清洗。在协议的评估阶段，参与者被要求评估所收集数据的质量。为了帮助理解数据评估，我们首先请参与者考虑如何衡量模型的质量，注意到下游系统中的可取行为和不可取行为。通过讨论模型质量作为共同基础，我们邀请参与者设计指标和验证过程，以测试数据质量。我们促使小组考虑所收集数据中的潜在错误、偏见和伦理问题，以及能够提升对高质量模型训练信心的高质量数据的特征。接下来，我们要求参与者设计高级数据清洗程序，包括移除低质量或错误的示例、处理敏感或机密数据、解决各个子群体代表性不足的方法，以及处理缺失数据。

3.2.6 持续使用。在最终的规范阶段，参与者被要求解决数据集使用中的隐私、安全、分发和版权问题，超出了所呈现应用的范围。我们邀请参与者讨论数据集是否应该被分发用于未来的应用，并考虑数据访问的机制和程序。我们鼓励小组考虑负责任的数据管理的特质，并集思广益地探讨指定和创建数据集的持续影响。

3.2.7 反馈。在每个研讨会结束时，邀请参与者反思他们的共同设计经验，并讨论创建数据规范的机会和挑战。我们请参与者分享他们合作共同设计经验的亮点和低点，回忆他们遇到或克服知识差距的时刻，并提出在吸引多元利益相关者参与机器学习应用设计过程中的改进建议。我们解释了用于数据规范设计任务的指导问题是一个活跃的研究领域，并征求了对该协议的顺序、清晰度和完整性的反馈。

# 3.3 数据分析

第一作者首先使用一个包含说话者分离的Python脚本转录了所有研讨会的会议记录，然后在第二遍中，手动验证了转录文本和说话者角色与视频录音的对应关系。接下来，我们在Atlas.ti [26]中进行归纳性的定性编码，采用扎根理论方法 [84]，从在生动分析开始。两位作者独立地对同样的两个转录文本进行开放编码，并协作制定了一个初始编码本，通过共识解决了分歧。最终的编码本包含53个代码。编码方案包括对程序数据需求（同意、标记、清理、验证等）、背景数据需求（代表性、减缓偏见、权衡等）和协作过程（翻译、分享领域专业知识、做假设、误解等）的引用。使用这个编码本，我们对其余的转录文本进行了编码。第一作者应用编码本分析了其余的转录文本 [17]。在整个编码过程中，作者写下反思备忘录，描述洞见和新兴主题，并在研讨会会议之间建立联系 [9]。编码完成后，研究团队进行了多次讨论会。在这些会议中，我们对代码进行了分组，并通过迭代性的理解过程讨论备忘录，以识别更高层次的主题并综合跨转录文本的发现。对主题的分析和讨论受到作者在进行研讨会过程中经验的启发，以及在每次会议中产生的文物和笔记的影响。我们的分析为跨利益相关者领域的以人为本的数据规范协作过程提供了见解。

# 3.4 位置性

我们承认我们的研究视角和方法受到我们自身经验和立场的影响。具体而言，我们是生活和工作在美国的研究人员，拥有与学校教师和学区人员在技术整合方面的教学经验，以及研究教育中人工智能公平性的经验，并与人工智能从业者合作进行与以人为本的设计相关的项目。此外，我们来自计算机科学、学习科学与技术、教育和人机交互等多个学科背景，我们在进行有关以人为本的人工智能设计实践的社会技术方法研究时，充分利用了这些背景。

# 4 发现

在每个研讨会中，我们为一组多样化的利益相关者提供了机器学习在教育领域的具体应用。我们请他们共同设计机器学习数据流水线每个阶段的规格。团队进行了深入的讨论，以明确数据集组成、收集和标记程序以及评估指标。通过参与生成式设计思维，参与者共享领域专业知识和个人（经验）视角，以预测挑战并应对数据主体和最终用户的伦理考虑。在所有会议中，知识共享和持续的共同评估促进了以人为本的机器学习数据流水线从头开始的概念化。我们总结了我们的研究发现，主要包括（1）将上游任务与下游使用相结合的背景化，（2）跨专业边界的协作策略，以及（3）角色、身份和支持需求的转变。

# 4.1 在下游应用中对上游机器学习任务的背景化

典型的机器学习数据管道是线性的，包含不同的数据和建模任务。我们基于当前数据文档模板的协议也遵循了线性组织。然而，参与者倾向于通过考虑各个组件与数据生命周期中其他阶段的互动来接近每个组件的规格。虽然机器学习数据管道中的当前阶段对工程任务是有意义的，但跨学科的关注点谈判超越了机器学习数据管道中的离散步骤。如表2所总结，各个会议的领域专家通过考虑下游应用背景，将上游机器学习数据任务进行上下文化，并推测收集和建模决策在下游使用中的后果。在与不同利益相关者协作设计管道每个阶段的数据需求时，我们发现协作实践能够打破在性能、效用或伦理问题出现时，向后看以改善模型的工程过程。在这里，我们呈现关于利益相关者如何主动预见挑战、考虑权衡、识别数据未知以及解决偏见和可靠性威胁的观察。

Table 2: Summary of stakeholders' downstream considerations in the education domain associated with upstream data specification tasks and challenges faced by teachers and students in our design workshops.

<table><tr><td>上游数据任务</td><td>领域背景</td><td>关注点</td><td>未满足的支持需求</td></tr><tr><td colspan="4">组成</td></tr><tr><td>ser s</td><td>训练数据应考虑不同教育环境（例如，公立和私立机构、地理位置、年级水平、学习科目和教学模式）之间的差异。需要在种族、性别、社会经济状况等人口统计维度以及个人学习需求（例如，语言能力、神经多样性、残疾）上代表子群体。</td><td>教师和学生对获取敏感信息（例如，学生对与教师关系的看法）的可行性和伦理性感到不确定。领域利益相关者对模型的公平性和实用性表示关注，因为数据无法捕捉到学生体验的重要因素（例如，行政数据未表明学生是否经历无家可归或校外创伤）。</td><td>非技术利益相关者缺乏对机器学习管道中数据使用的技术知识，包括训练数据、应用数据和用于验证的数据之间的关系（例如，指定训练数据的变量可能在应用数据中无法持续收集，犹豫收集人口统计变量，假设它们必须是模型输入）。</td></tr></table>

以及我们设计研讨会上教师和学生面临的挑战。(续)   

<table><tr><td>上游数据任务</td><td>领域背景</td><td>关注点</td><td>未满足的支持需求</td></tr><tr><td></td><td>行政变量的细微背景解释（例如，将一般缺席与涉及医疗假期的有原谅的缺席分开，检测学生从课程选择中自我感知的能力），学生校外因素（例如，家庭和社区支持、课外活动、社交网络）和自我报告的感知（例如，写作信心、课堂信任与安全感、无聊）都是影响力预测因素。</td><td>教师担心因用户试图理解模型输入和输出而误解因果关系，并采取随后错误的信息行动（例如，管理层将学生辍学归咎于教学质量，尽管测量不尽完善，学生学习插入复杂词汇而非全面提高写作）。</td><td>非技术利益相关者难以构思变量如何影响预测。这一知识差距由于不同类型数据的技术处理和影响可解释性的建模选择而进一步复杂化。</td></tr></table>

标签和属性应与教学目标对齐（例如，基于标准的作文评估量表，涵盖多个维度而非整体评分），并指示改善教学实践的行动（例如，识别参与度低的课堂活动，而不是看似无聊的学生，识别学生所需的具体支持，而不是辍学风险）。

教师们对行政和专业发展工作复杂性的担忧，表现在需要明确后续行动和问责制，以回应预测。

教师们警告不要使用会对学生产生假设并限制学生自主性的标签（例如，将学生归类为“辍学生”而造成的行政后果，或预测学生情绪而产生的行为管理影响）。标签会影响最终应用程序的设计以及用户如何接受培训以与其互动。

利益相关者缺乏共同基础，导致领域利益相关者需要倡导和解释教学目标、教学实践、学校系统的组织以及教育中的敏感问题。

标签方案应考虑教育系统中多个标准和固有的不一致性（例如，教师评分的自由裁量权、不同的学术标准、不同州的毕业要求）。

教师担心在严格评估环境中与质量标签相关的属性存在学术偏见（例如，重视标准美式英语而忽视学生所在社区熟悉的语言）

# 收藏

学校系统维护行政数据和历史记录，这些记录包含基本的学术和人口变量。教师也可能能够协助数据收集或直接提交数据。

领域利益相关者在未知数据所有权和未知数据管理方面面临困难（例如，依赖行政部门而不知道负责数据管理的角色或行政数据中可用变量，对隐私法的不确定性或教师可以合法分享的内容）。

教育系统包括与第三方合作伙伴以及与技术、测试和咨询公司互动，这些公司私下管理数据（例如，大学理事会、学习管理系统、国家职业教学委员会）。

利益相关者对第三方系统的数据收集、管理和隐私条款缺乏清晰认识。

<table><tr><td rowspan=1 colspan=17>预印本，CSCW’24，梅坦，韩索尔·李，达阔·王和哈里哈兰·苏布拉莫尼在我们的设计工作坊中面临的挑战。（续）上游领域背景 关注点 未满足的支持需求 数据任务</td></tr><tr><td></td><td rowspan=1 colspan=16>程序必须考虑法律规定     选择性同意政策可能导致      教师和学生缺乏一个</td></tr><tr><td></td><td rowspan=3 colspan=16>管理受保护学龄人群数据的法规   采样偏倚（例如，父母同意的    参与框架，以了解他们在权利和披露方面可以期待什么。</td></tr><tr><td></td><td rowspan=1 colspan=13>人群（例如，COPPA）。收集</td></tr><tr><td></td><td rowspan=2 colspan=14>可能需要多种形式的数据使用协议（例如，知情同意）。</td></tr><tr><td></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1>最高标准的数据同意</td></tr><tr><td></td><td rowspan=1 colspan=13>来自父母和法定监护人的同意</td><td rowspan=8 colspan=4>来自父母和法定监护人的同意                                          隐私和安全做法，他们无法评估数据协议的语言。</td></tr><tr><td></td><td rowspan=1 colspan=5></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td></td></tr><tr><td></td><td rowspan=3 colspan=4></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td rowspan=1 colspan=2>不可靠的o</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td rowspan=2 colspan=2></td><td rowspan=2 colspan=3>soet</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td rowspan=1 colspan=3></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td rowspan=1 colspan=12>写作任务，学生意识到被拍摄）。</td></tr><tr><td></td><td rowspan=1 colspan=12></td><td rowspan=4 colspan=5>标注应强调学生的权能和公平，通过纳入学生的视角（例如，允许学生自我认同参与）。标注者应具备领域专业知识（例如，经验丰富的教师，了解该年龄组的心理健康专业人士）。教师和学生对主观评估和教育领域中不可避免的偏见表达担忧（例如，教师偏见对学生行为的感知，不一致的评分标准）。</td></tr><tr><td></td><td rowspan=1 colspan=12>标注应强调学生</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td rowspan=1 colspan=11>(例如，允许学生自我认同</td></tr><tr><td></td><td></td><td rowspan=1 colspan=14>专家知识（例如，经验丰富的教师，了解该年龄组的心理健康专业人员）对教育领域中不可避免的偏见的透明度。</td></tr><tr><td></td><td></td><td rowspan=1 colspan=14>标签者的多样性和代表性应匹配数据对象的多样性和代表性。</td></tr><tr><td rowspan=1 colspan=17>评估数据可能受到缺失或收集限制的影响，包括包含学校的偏差样本（例如，仅来自城市特许学校的参与）和无法收集的数据字段（例如，学生健康详情）。4.1.1领域背景塑造数据集规范。在协议的组成阶段，参与者最初以广义的教育背景接触数据集特征。</td></tr></table>

然而，在所有的会议中，教师和学生在细化初步规范方面发挥了关键作用，以捕捉现实下游需求的细微差别。表2的第一部分总结了教师和学生的下游领域考虑因素如何影响他们在识别相关变量和开发标签方案方面的贡献。例如，学生的观点提供了有助于将学术和行政数据进行背景化和重新解释的见解。虽然教育中的模型通常基于对学业成绩的评估来预测学生的结果，但学生S6解释说，学业成功和幸福感的感觉取决于一系列有意义的变量组合：

S6（学生退学风险预测）：“我认为不仅仅是他们的成绩。如果有人在AP课程中不及格，而在非AP课程中表现优异，我觉得这些因素的组合传达了不同的故事。”（1）

教师同样识别了与领域相关的数据特征。虽然规范的数据实践将多样性和人口统计与有限的一组属性关联起来，但教师们强调了多样性在教育中所意味着的丰富内涵。例如，教师指出，环境背景，如教育机构类型、教师经验水平、城市性、教学质量和学科内容以及社区的社会经济状态，可能对预测结果产生影响。例如，在具体说明学生注意力数据时，教师T2解释道：

T2（学生参与度图像分类）：“多样性可以意味着许多不同的事情，不仅仅是身体特征。这就像环境的多样性，他们正在做的事情，因为关注数学可能与关注阅读或艺术看起来有所不同……或者他们是否在与其他人合作……因为这些都是可能影响学生参与度的因素。” (2)

此外，在定义亚组表现时，教师提倡使用已知显著区分学习经验和结果的特定学生上下文变量，包括学生年龄、语言学习者身份以及第一代或移民身份。教师通常提到的一个上下文变量是学习差异或残疾的存在，这些情况需要个性化教育计划（IEP）。教师T1描述道：

T1（学生参与图像分类）：“另一件事可能是有数据知道学生是否有个性化教育计划（IEP）。……如果一个学生被诊断为多动症，他的注意力可能不会像没有这种情况的学生那么集中。还有情感学习障碍……那些在家中经历特定创伤的学生，而这些实际上在动机和参与方面是非常相关的。”（3）

在各个会议中，编码信息的范围对多样性的背景与常见的工程对代表性标准的理解形成对比。通过分享丰富的轶事见解和例子，教师们介绍了促使小组重新思考数据集组成范围和普遍性的背景因素。因此，参与者考虑了在代表不同学习者和环境的上下文变量的大规模收集中，数据集的大小与应用场景范围之间的权衡。参与者对确保数据集中代表的子群体的公平分配所需的数据量以及对代表性不足的子群体的预测准确性表示担忧。接着，参与者考虑模型是否应该设计为仅适用于特定年龄组、学习者状态或学校类型。在这些讨论中，工程师们将下游建模选项和机器学习过程置于背景中，以支持数据组成和目标应用决策。例如，工程师E6解释了在技术利益相关者之间对公立和私立学校数据的语义差异存在分歧时，比较多个模型的做法：

E6（学生辍学风险预测）：“在机器学习中，拥有多个模型是很常见的，这被称为集成，你只需将它们放在一起。然后你选择最佳结果。但你对相同数据有不同的理解，这是非常有用的，特别是当我们想进行比较时。”（4）

在大多数会议中，工程师们分享了他们的专业知识，强调了机器学习的优势、测试多种设计选择的下游机会，以及技术方法在准确性和可解释性上的权衡。这些技术贡献将数据集构成的设计置于下游处理和建模应用中，为领域从业者分享的现实因素添加了方法论背景。

4.1.2 上下文使识别数据收集中的偏见和可靠性威胁成为可能。根据教师提供的上下文知识，所有团队在数据收集和标记规范的设计中识别出数据质量威胁。表2的第二部分总结了参与者的领域上下文如何影响他们在识别数据来源、定义收集程序和定义标记程序时的关注和考虑。例如，在设计数据收集程序时，利益相关者依赖学生作为数据主体的观点，以预见虚假、畸形和缺失数据的问题。学生分享了他们在调查疲劳、不足的激励机制和制造虚假信号方面的个人经历。在帮助小组最大化收集学生简历的响应率时，学生S4解释了他们对各种收集策略的反应：

S4（基于简历的职业推荐）：“作为一名学生，我可能不会为了没有报酬而发送我的简历，但如果给我补偿，我可能会尝试去做。这就是如果你要求我提供简历并给予报酬和调查，我觉得回答调查问题可能会让我更投入，而不是简单地发送 PDF。”（5）

学生S2警告说，学生的可观察信号可能与他们的需求或经历不一致。他们解释道：“学生总是有办法掩饰。即使在Zoom上，看起来我在看屏幕，其实我可能在玩手机。”在几次会议中，利益相关者们努力应对不合作的数据主体可能带来的影响，并调整了收集程序，以防止不良后果。他们假设的解决方案包括开展信息宣传活动，以提高数据主体的认同感，设计非侵入式的收集方法，以避免打断真实的学生行为，以及强制填写调查工具中的数据字段，以避免后续处理缺失数据。

此外，数据质量威胁促使利益相关者设计数据清理程序，以检测和删除格式不正确或虚假的数据，并标准化数据字段。在对收集到的地区写作样本中成绩标签解释的变异性方面，工程师E10（自动化作文评分）解释道：“一些学校在评分上很严格，而另一些学校则不然，所以我们也许需要统一这些……也许我们需要进行数据工程，使所有这些标准化。”在另一个会议上，一位学生的评分经历鼓励小组考虑依据州标准派生的标签方案。学生S8解释道：“在我看来，教师在评分时并不总是保持一致。他们对什么是A和B有不同的看法。”在评估阶段，数据代表性和不同子组的适当分布成为数据质量的一个反复出现的主题。参与者设计流程以追求这一标准，回到数据收集程序的设计，并通过额外的收集过程、外推或从其他上下文借用数据来增强来自少数群体的数据。

第三，团队集思广益，寻找在数据标记程序规范中考虑数据收集错误的方法。参与者承诺雇用多个标记员，计算一致性得分，审计二手数据集中的标签，并指定标记员的资格和多样性要求，以作为获得可靠标签的预防措施。虽然标记程序在研讨会协议的收集阶段进行了讨论，但参与者通常讨论数据质量标准和数据评估概念，以支撑他们的设计决策。考虑到标记员的真实性，并借鉴他们作为特殊教育教师的经验，设计师D2建议让数据样本参与自我识别标签：

D2（学生参与图像分类）：“我认为让学生自我认同实际上是非常重要的。解读面部表情的人与产生该表情的人会有不同的解读。但是，比如说进行学生自我反思和教师感知之间的比较，并衡量两者之间的差距。”（6）

在一些小组决定重新利用现有数据集而不是收集新数据的会议中，与会者对潜在的偏见标签表示怀疑，并对错误标记示例的下游影响表示关注。

4.1.3 通过映射到上下文验证规范。在新获得的上下文知识的基础上，所有团队参考上下文作为评估不断变化的规范和收集程序的方式。表2的第三部分总结了领域上下文如何影响参与者在识别数据清理和验证要求时的考虑。少数团队指出数据过程透明性的重要性，以减轻在下游用例中应用的偏见。例如，在自动化作文评分的场景中，其中一个团队考虑重新使用来自标准化测试服务的二手数据，同时观察到能够经济负担得起该服务的学生的工作样本过于代表性。指定无法减轻的偏见的沟通，教师T8描述道：

T8（自动化作文评分）：“我认为还需要指出那些你无法减少或解决的偏见，所以如果你使用的是AP构建的一套标准，那么对语言惯例的强调是偏向于标准化学术英语的。好的，如果我们无法消除这种偏见，我们至少可以在我们的过程中指出它。”（7）

此外，领域专家鼓励小组在协议的评估阶段优先考虑整体应用的评估，而不是依赖技术语言和传统工程指标来衡量模型性能。在所有会议中，小组承认了标准化定量指标的传统，但认为它们无法捕捉机器学习应用的现实世界效果。在关于测试程序验证模型准确性的讨论中，教师T9（自动评分论文）提倡在教育领域最相关的特定绩效指标：“质量应该通过学生的学习成果来衡量……比如他们如何回应来自工具的反馈。我知道这真的很困难。”设计评估规范的挑战促使利益相关者重新审视数据管道早期阶段的决策。这通常涉及回到数据组成阶段的设计决策，并选择不同的标签，以更好地支持最终用户的目标。尽管认识到现有指标的不完整性，参与者在创建更好地满足上下文需求的新指标时仍面临困难。

为了总结这一部分，参与者在数据管道中自由移动，將数据需求和机器学习过程置于领域意识的背景中。他们预见了最终用户的体验，并主动缓解了对数据质量的威胁。数据、建模和应用工作之间的关注点分离代表了一种以工程为中心的框架。我们发现，多个利益相关者群体在决策时采取整体视角，将数据规范与用例提取和应用开发各阶段的权衡相结合。

# 4.2 跨专业边界的合作策略

虽然基于角色的知识边界通常限制了机器学习工程师与领域专家之间的合作机会，但我们观察到多方利益相关者群体参与了跨界协作的实践。参与者采用特定于专业的策略来克服知识差距，建立跨学科的理解。通过翻译和倡导的实践，群体放大了多样化的观点，建立了共同基础，并在模糊性中找到方向。

4.2.1 翻译。非技术利益相关者通常会因为对机器学习能力和流程的知识缺口而感到参与技术决策的障碍。认识到在教育领域对机器学习的不熟悉，教师T9解释道：

T9（自动化作文评分）：“如果你走进一间教室，我认为美国大多数高中老师……如果你提到机器学习、自然语言处理和算法，他们可能根本不知道你在说什么。这并不是因为他们愚蠢，而是因为这是一个非常小众的话题，在课堂上你并不常听到。需要有某种中间立场……某种对不生活在零和一的世界里的普通人的翻译。”（8）

在共同协商数据需求时，所有会议中的工程师通过翻译促进了合作。具体来说，技术专家不仅仅是将从业者的优先事项转化为机器学习术语的资料规范。参与最成功的共同设计会议的工程师积极分享技术知识，以建立共同基础，并为领域专家的参与提供实践理解。将上下文数据需求转化为技术规范的一种方式是评估教师请求的可行性。在数据构成阶段，当教师T5提倡用当地课堂表现指标来增强标准化考试成绩时，工程师E5从其技术表现的角度考虑这个特征：

T5（学生辍学风险预测）：“添加那个层会很困难吗？这只是看他们是否以某个字母通过了一门课，在这种情况下是C或更高。” E5（学生辍学风险预测）：“我不认为这是一个难以添加的特征，这听起来像是一个二元特征。要么是是，要么不是，对吧？你添加一列，值就是是或不是。是的，我觉得这是可行的。”（9）

各个会议的工程师运用他们的技术知识，尽可能支持教师提出的功能请求。在编码教师提出的相关数据字段时进行了翻译，同时在数据收集和评估阶段规划技术流程，以满足用例关注。工程师通过阐明机器学习过程，参与翻译，以支持更广泛的从业者关注和价值观。例如，考虑到围绕隐私侵犯和机器学习中人口统计维度的偏见的宣传，非技术利益相关者对收集种族、年龄和性别变量表现出敏感性。为了消除对收集和使用人口统计数据的困惑和不安，工程师E2解释道：

E2（学生参与图像分类）：“您可以决定使用[人口变量]来理解您的数据，然后您已经知道数据可能存在偏见。因此，当您构建模型时，要考虑到这一点，并对模型进行优化以应对这种偏见。”（10）

通过将领域优先事项转化为评估规范，工程师跨越知识边界，加深了对人口数据在机器学习过程中的使用的集体理解。作为一种实践，翻译使工程师能够运用他们的技术专长来扩大小实践者的声音，使非技术利益相关者能够参与构建以人为本的数据需求。在共享场景的背景下，工程师解释了数据和建模选择中的权衡，建立了支持领域专家参与的技术基础。在考虑数据构成阶段多样学校环境的表现时，工程师E6描述了他们在规定模型范围时的考量：

E6（学生辍学风险预测）：“如果你只为这所学校训练这个模型，那么你将查看该学校的所有以前的数据……缺点是可能没有足够的数据供模型学习，或者可能得出错误的结论。为该地区所有学校训练模型的好处是你拥有更多的数据点。但其缺点是，例如你所在的学校很贫困，而你所在地区的其他学校都很富裕，因此辍学模式可能会不同。” T6（学生辍学风险预测）：“它们似乎都有缺点，但也许按学区划分会更好，因为如果它适用于所有人，准确性就会更高，但数据量却会更多，因此更准确更好。”（11）

通过依赖设计情境，工程师将技术决策的影响以领域相关的术语进行情境化，使教师能够参与权衡的评估。虽然在研讨会上以前使用过“准确性”和“泛化”等技术术语，但教师并未采纳。通过翻译建模选择的情境成本和收益，工程师使得教师能够使用技术语言并参与决策。

在许多会议中，技术相关方更加注意通过延长对话来教育非技术相关方关于技术细节，积极帮助他们在设计过程中理解技术语言。在一些会议中，工程师们运用隐喻，将机器学习比作熟悉的类比过程，在解释中调整技术知识，以充当不同领域之间的桥梁。翻译主要由技术专家进行。由于教育领域的社会性质，技术专家可能更容易对教育背景做出假设，而无需来自领域专家的翻译，而将技术融入教育是最近的一种颠覆性变化，对许多领域从业者来说是陌生的。

4.2.2 倡导。在教育领域的高风险性质上，开发优先考虑从业者经验的机器学习应用是必要的。在合作的背景下，参与倡导的领域专家进行了深入的讨论，使用情感驱动的语言，敦促跨领域的利益相关者面对教育系统的复杂性和数据决策的隐含影响。正如学生S4所描述的，“你必须尝试成为一个倡导者，如果你要部署这样的系统，你将不得不面对那些倡导其他利益的人。”事实上，教师和学生在各个环节中的协作参与都被视为一种倡导。他们倡导公平和实用性，动机源自他们的领域背景和生活经历，同时协商跨领域的要求。

通过揭示数据标签、特征编码和建模选择的关键下游影响，教师和学生表达了教育领域核心的价值观和敏感性。学生

S5通过解释隐私侵犯和数据滥用会使学生面临未来教育机会受到负面影响的风险，倡导保护数据主体。

S5（学生辍学风险预测）：“我会担心老师或管理人员或一个委员会在监督结果。如果我被显示为可能辍学的学生，那将会有多尴尬。这意味着你知道自己的表现不佳，有些事情出了问题。”（12）

老师T6同样对由于标签所使用的严厉语言（例如“辍学”和“未辍学”）对学生造成的下游伤害表示担忧。在学生辍学预测场景中，他们警告说：“那么这些学生将被贴上辍学的标签，这样就给管理者提供了一个理由，把这样的学生赶出学校。”老师T6提倡使用以学生为中心的标签，并将应用场景重新框架为预测学生是否“按时毕业”。教育系统的复杂结构导致了基于角色的利益、优先事项和模型结果解读的差异。虽然学校和地区管理员重视辍学指标，但教师更倾向于采用一种反向框架，强调学生朝着积极目标的进展，意识到被系统标记的学生在现实世界中可能会受到怎样的对待。通过解释他们基于经验的对心态和实践在下游应用背景中的理解，数位教师在几次会议中倡导数据规范，以避免延续系统不平等。

在许多情况下，团队最终采用了教师推荐的标签，这表明他们愿意认同支持学生自主性和避免惩罚性行政后果的从业者价值观。然而，教师偶尔会遭遇来自技术利益相关者的强烈反对。这种教师和机器学习工程师之间的反复交流模式在图2中得到了说明。在这些情况下，教师坚持自己的主张，直到团队理解他们关注背后的意图和重要性。在一次关于参与分类场景的会议中，教师和工程师就使用情感标签对学生进行分类的伦理问题进行了长时间的激烈讨论。教师T3解释了在课堂实践中假设学生情感状态的种族化基础：

T3（学生参与图像分类）：“我个人觉得这是一件我可以根据自己和学生的关系来决定的事情。如果有学生感到沮丧或困惑，使用这些标签，我会担心刻板印象。这在教育中是一个非常大的问题，黑人学生和白学生的行为在许多白人教师眼中被解读为不同，尽管这可能只是他们特定的文化背景。”（13）

在反对使用对学生情绪状态做出假设的标签时，教师T3提到了教育领域的两个其他敏感主题：种族偏见对学生行为的历史背景，以及机器学习对教师在课堂上人类判断角色的侵犯。这一交流强调了教育中这些关键紧张关系的重要性，以及种族和文化考量在这一领域的突出性。在另一个会议中，关于收集教学质量评估数据以预测学生辍学风险的讨论同样激烈。教师T5认为，管理者使用教师评估数据将影响教师工会和人员配置政策，进一步复杂化了学区在保护教师方面的现有斗争。通过将与技术上客观变量相关的社会和政治构建进行情境化，教师倡导使各团体能够集体将数据决策置于复杂生态系统中，并以尊重和敏感的态度接近所蕴含的世界观。

在多个会议中，倡导通过分享个人生活经验来进行。教师T9在自动化论文评分场景中设计数据集成分时，反对依靠量化的基于规则的语法特征来评估学生写作。

T9（自动化作文评分）：“当我在芝加哥西区教英语时，我的学生中有百分之九十九是非洲裔美国人。我理解他们所说的内容，但这并不像传统的学术美国英语那样书写。你不想因为学生所生活的文化和他们所说的语言而惩罚他们。”（14）

教师T9反思了他们在尊重每个学生背景和为学生准备未来严格评估环境之间的个人挣扎，并承认他们仍然对这种平衡感到不确定。共同设计会议的问题解决性质邀请了涉及课堂中面临的困难的敏感实践者故事。尽管教师和学生所需的相对脆弱性与其他角色相比更为明显，但他们迎接了这一任务，并热切倡导该领域中的复杂现实。

4.2.3 模糊性。在时间有限的共创会议中，参与者在大局讨论和具体设计细节之间寻求平衡。参与高层次讨论要求利益相关者培养对模糊性的舒适感，接受数据的不确定性和未完成的设计决策。尽管参与者对设计任务中的模糊性表示不安，但工程师E5指出，这一过程与抱有虚假确定感的设计形成了鲜明对比：

E5（学生辍学风险预测）：“当我们谈论设计一个系统时，每个人都想假装自己知道的比实际上更多。当我们谈论做决定时，每个人都觉得自己已经知道答案，就像他们应该知道答案一样。在这种情况下……我觉得我不知道答案是可以的……我依赖于其他角色。”（15）

多元利益相关者的存在促进了在选择主动的大局数据规划时对模糊性的集体接受。其他会议中的工程师们也表达了对设计决策开放性本质的深切赞赏，因为在典型的机器学习实践中，高层次对话相对不频繁。

# 4.3 角色、身份和支持需求的转变

我们的研究表明了基于角色的协作动态以及持久的知识差距和边界，这些因素在多利益相关者的环境中复杂化了贡献。尽管参与者在共同设计过程中的参与富有成效，但我们观察到各组在做出假设、建立在误解基础上以及被共享的未知问题困扰。利益相关者在基于角色的身份和贡献方面面临困难。我们识别出了在协作数据规范中吸引多样性利益相关者的挑战和支持需求，并在表2的最后一栏中进行了总结。

4.3.1 严格的责任边界。虽然共同设计会议促进了工程师与领域专家之间的许多跨界实践，但某些基于角色的边界依然存在，妨碍了合作。几个工程师对数据决策的责任和义务保持了有限的视角。特别是在伦理决策的评估、对人口子群体的公平性，以及同意实践方面，工程师往往迅速将责任委托给专业实体。关于协议构成阶段子群体的代表性，工程师E1解释道：

E1（学生参与图像分类）：“这通常是你不应该随便问任何人的问题。我会将这个问题留给伦理审查小组的专业人士。”（16）

![](images/2.jpg)  
FigVisualization of role-based contributions in workshopdiscussions across stages of data specification. Each horizontal line represents one sentence of speech. Selected quotes are marked by number.

在通过基于角色的专业化使行业高效运作的情况下，工程职责可能被狭义地定义。伦理标准通常由专业团队处理，这些团队与工程过程分开。除了倾向于关注分离，工程师们表示习惯于一种与数据集设计选择无关的标准行业实践。在自动化作文评分的场景中，工程师E10解释了他们在协议的数据收集阶段的不安，同时在考虑几种标签方案。

E10（自动化论文评分）：“我们通常没有那么多选择。你没有选择，我们真的只能利用我们所拥有的。我不设计人们如何提供他们的数据。”（17）

虽然工程师们参与了知识共享和翻译实践，但效果各不相同。尽管工程团队努力打破技术壁垒，一些教师仍然感到对技术的无知感到畏惧。其他人则在意识到他们有经验教授的学生年龄组与机器学习应用的目标学生年龄组之间存在不一致时，更加难以贡献。教师T4解释道：

T4（简历基础职业推荐）：“我没想到我从教育的角度能够提供这么多，因为我的背景是与很多年纪更小的学生在一起。”（18）

尽管教师在年龄段或学科方面的经验有所不同，但教师们仍然贡献着领域专业知识。通过低估自己在教育系统中作为教育工作者的背景理解，一些教师将自己的利益相关者角色视为直接的最终用户，而不是共同设计者。在几次会议中，教师们因为自我设限和对参与资格的误解而变得更加沉默。

4.3.2 持续的知识差距。各组在识别数据所有者方面面临知识差距。尽管从学业记录、课堂观察和学生作品中收集了教育数据，但教师对数据所有权的规定仍不确定。老师T8在提到收集学生论文数据时解释道：

T8（自动化作文评分）：“他们可能住在教师的区域或学校的谷歌云盘，或者他们正在使用的任何东西……所以我不太确定谁拥有这些的版权。”（19）

数据所有权因教育科技系统的存储而进一步复杂化，这些系统与学校管理之间的隐晦数据隐私条款进行了谈判。即使是被认为直接由学校管理维护的数据，教师们也无法识别所有权和访问流程。关于获取学生学业记录，多位教师表示需要学校管理人员在场。教育系统中的情况导致各学区之间的角色和责任存在差异，使得将利益相关者的声音纳入讨论变得复杂。对于领域专家而言，这一知识差距可能指出学校管理中的一个未知利益相关者和数据所有者，他们应参与数据规格的设计。工程师同样会对数据的可用性做出假设。关于各种学生学业和财务记录，工程师E6假设：

E6（学生辍学风险预测）：“很多这些数据可以通过大学申请直接收集，对吧？可以说大学肯定有这些数据，我是说他们会记录所有事情。这些数据可能已经在他们的系统中标记了。”（20）

对于工程师来说，这些假设可能反映了他们的训练，因为数据集是给定的而不是构建的。尽管对于数据使用协议、数据的形状和组成，以及联系正确的数据所有者存在未知数，工程师们仍然对数据的存在保持信心。

尽管涉及了倡导数据隐私问题合法性的利益相关者，但在数据安全和访问方面仍然存在知识差距。工程师E1利用安全假设来为随意的同意做法辩护：

E1: “对于教育应用，几乎没有任何有害影响或数据泄露的可能性，你可以让孩子们勾选一个框，表明我的父母同意。”（21）

技术和非技术参与者对数据安全表现出放松的态度，认为没有恶意数据泄露的动机。教师T2解释道：“我不明白为什么任何人会想要黑进学校使用的东西。”

4.3.3 转变的利益相关者身份。虽然教师、工程师和法律专业人员拥有明确的参与角色和既定的贡献预期，但学生和用户体验专业人员的协作身份则不太明晰。参与者之间的不同参与模式在图2中得到了体现，显示出教师与工程师之间的互动一致性，与学生和用户体验专业人员的贡献差异形成对比。学生S4解释道：“始终保持学生的视角……是困难的，因为学生不会参与每个阶段。”在几次会议中，学生们表达了在一群专业人士中作为最年轻一员的 discomfort，并且缺乏明确的贡献结构。因此，他们常常把自己从最终用户的主要角色中抽离出来，以一般协作者的身份参与集体任务。学生们热衷于参与技术共同设计，提供数据收集和建模的创意，与学生视角无关。例如，在小组讨论纳入学生退学预测场景协议的数据集组成阶段的潜在特征时，学生 S5 解释了他们关于非常规调查方法的想法：

S5（学生辍学风险预测）：“让学生彼此调查，几乎也是有趣的。这听起来有点怪，但在你们每节课中指定一个人，然后问‘这个人看起来还好还是像要辍学’我觉得这可能是有趣的。”

E5（学生辍学风险预测）：“我能看到潜在的欺凌材料。”（22）

为了为设计任务作出贡献，学生失去了对数据主体的同理心，这要求工程师指出潜在的下游危害。在学生辍学预测场景中，几位学生还主张收集有关学生的心理健康和其他敏感信息。在所有场次中，学生们常常把数据主体称为“他们”，并与自己区分开来。

我们发现，在所有会议中，利益相关者依靠之前的角色和经验，通常表现出多种能力，并在协作共同设计过程中在这些身份之间转换。一些法律专业人士还具备技术经验，因此他们能够贡献机器学习最佳实践并参与翻译实践。一些设计师和工程师在教育行业的多个职位上有过经验，因此他们能够贡献基于领域专业知识的想法，以便为数据提供背景。每个利益相关者要么记得自己曾是学生的经历，要么通过其社交关系与学生密切关联，因此他们能够代表学生利益发言。与此同时，学生们在作为数据主体和最终用户的角色中总是难以贡献意见。他们通常选择以数据规范的共同设计者的身份参与。

UX专业人士在他们的参与角色上同样缺乏明确性。在研讨会的总结中，工程师E7反思道：“这个问题与UX视角关系不大，因此参与者在讨论中的代表性不平等。”通过组织让多方利益相关者参与的共同设计研讨会，研究的设置在某种程度上履行了设计师的传统角色，混淆了小组对他们预期贡献的理解。在各个会议中，几位设计师还维持了基于角色的关注分离，限制了他们对技术主题的贡献。由于与技术贡献无关，并且缺乏教师和学生的个人领域经验，设计师通常会淡出背景。

# 5 讨论

我们的研究结果展示了多方利益相关者合作在数据集规范设计中的重要作用。通过开展以共同设计高风险教育领域的机器学习数据集为基础的研讨会，我们强调了从业者在情境化领域和程序知识、建立共同基础以及减轻下游伤害方面的努力。参与者在数据管道的每个阶段都参与了一个生成性的过程，以协商数据要求和质量，强调了以人为本的系统的主动设计。我们强调了参与领域专家的价值，并讨论了在这一研究中探索的协作过程的可扩展实施面临的挑战。我们将我们的贡献描述为对数据规范工作的影响，以及对未来在教育中负责任使用数据的多方利益相关者协作过程整合需求的支持。

# 5.1 拿到入场券就够了吗？

批判性学术研究探索了为可扩展生产开发机器学习系统与让最终用户参与这些系统设计之间的紧张关系。通过建立一个结构化的共同设计环境，在这个环境中，各种利益相关者被给予发言权，我们的许多参与者参与了有机的协商，以克服知识边界，通过协作策略建立共同基础。我们发现参与者在数据需求规范方面做出了重要贡献，同时在共同设计过程中也面临挑战。在本节中，我们通过两个参与框架和教育领域的应用背景讨论了利益相关者参与我们工作坊会议的优势和局限性。

Delgado等人描述了一个参与维度的分析框架，旨在帮助从业者评估参与过程在多大程度上赋权于不同利益相关者，以便在机器学习应用的设计中有效地参与。咨询、参与、合作和赋权是参与的不同层级，在五个决策点上进行评估，这些决策点涵盖了动机、利益、出席情况、形式和权力分配等参与过程。Sloane等人警告“参与洗牌”，在这种情况下，参与的叙述掩盖了权力动态和合作的掠夺性本质。通过批判性地将参与设计实践框架视为工作、咨询和正义的形式，从业者可以评估协作过程的真实性。在这里，我们反思在我们的共同设计会议中参与的性质。

5.1.1 共同设计的可行性。我们的研究结果有效地展示了协作在数据规范中的关键作用，通过识别并确认了机器学习应用开发中的一个关键参与点，贡献了以往文献。在Delgado等人的框架中的多个决策点上，我们的工作坊的参与结构改进了当前的实践，这些实践限制教师参与的程度较低，例如参与设计反馈，以改善人工智能系统的用户体验。相比之下，数据规范的共同设计是一种参与结构，使利益相关者能够为机器学习应用的范围和目的做出贡献。数据是机器学习模型的基础，规范数据要求是一种系统化的方法，可以影响系统行为并让人工智能对利益相关者负责。通过让利益相关者参与机器学习管道这一高杠杆、高影响力的阶段，数据属性的设计和数据质量的评估可以系统性地放大利益相关者声音的影响。

教师们分享了影响数据集设计和模型性能的领域专业知识。跨领域专家通常对自己的知识差距表示惊讶，并对与教育领域相关的上下文变量的假设产生了动摇。在回顾他们的协作经验时，各个小组的工程师讨论了传统机器学习开发流程的狭隘技术焦点，承认常常出现错误的努力和忽视实践者优先事项。在大多数会议中，工程师们表达了对项目早期阶段协作价值的认可，并渴望将这一过程融入实践。教师们同样表示热衷于参与数据工作。各方利益相关者在会议中一致认为，早期利益相关者参与数据规范设计可以揭示领域相关的优先事项和潜在的下游危害。

小组还意识到“大局”对话的重要性，通过结合对数据选择如何影响最终用户及其环境的背景理解，以预见未来的危害。小组在设计决策上没有达成一致，而是参与了一个创意和筛选的过程，这往往导致识别出多个进一步探索的可能性。与强调摩擦和分歧重要性的协作方法一致，不同的观点鼓励参与者对模糊性产生欣赏。在这个参与性过程中，构建一个共同协商的框架，其中各种利益相关者的专业知识被同等重视，促进了成果规格中设计的多样性。在这个过程中，参与者承认未知，并依赖于在座人士的集体知识。

5.1.2 不平等的负担。为了进行有效的共同设计，参与者通过实践其角色独特的协作策略跨越专业边界。我们观察到领域专家努力通过分享脆弱的个人经历和在复杂的历史与社会文化背景中倡导实践者的需求来建立共同基础。领域外的利益相关者经常自信地对教育系统做出假设。教师和学生不得不承担为其课堂经验辩护和应对以技术为中心的推回的情感负担。相比之下，作为边界跨越者的技术专家承受着沉重的沟通负担。这一发现扩展了对机器学习团队合作的现有理解，在这样的团队中，技术成员缺乏领域背景，各方假设存在多样但平等的贡献[51, 57, 64]。由于教育领域的从业者感受到在设计高度技术应用时存在显著的障碍，工程师必须支持翻译在协作实践中的核心角色。在最积极的协作会议中，工程师表现出愿意教授基础概念和流程，耐心解释技术权衡。通过将领域特定要求翻译为数据和建模要求，工程师能够满足非技术领域专家倡导的需求。然而，尽管这些协作策略产生了积极的结果，但在不同的方式上对技术和非技术参与者都带来了巨大的能力要求。如果没有结构化的支持，多方利益相关者的协作是一项高难度的工作。在我们的会议中，当任何利益相关者缺乏满足这些协作要求的技能、知识或精力时，团队经常退回到以工程师为主导的线性决策。

在Sloane等人的参与形式框架中，本研究的共同设计研讨会最接近于“参与作为咨询”，其中不同的利益相关者参与各种短期项目的不同阶段。咨询形式的参与通常采取一刀切的方式，创建一个单一的流程，并期望所有利益相关者提供相同的贡献。然而，不同的利益相关者贡献不同，需要不同的支持。协作过程可以通过将参与设计为特定于上下文和利益相关者，更好地吸引利益相关者的观点，并重新审视流程，以确保向适当的利益相关者提供和收集适当的信息。

5.1.3 未填补的席位。我们的共同设计工作坊在利益相关者选择的维度上代表了较低的参与程度，因为纳入的社区成员是由研究团队选择的。根据Delgado等人的框架，真正赋权利益相关者的参与过程涉及与由社区本身指定的社区成员进行互动。尽管这一标准是有价值且必要的，但在教育环境中实现这一标准是困难的。

教育领域涉及复杂的动态系统，这些系统受到机构、从业者、社区和政策属性的影响。虽然教师积极参与共同设计数据规范，但跨会议的参与者在面对未在我们研讨会中代表的多样化领域相关利益相关者的未知视角时感到困惑。除了学生和教师，参与者提到父母、地区管理员、学校顾问、教学教练、支持人员和地区人员、社区组织以及政策制定者作为所呈现设计场景中的重要利益相关者。参与者始终表现出对学校和学校系统的组织结构存在知识差距，难以识别数据所有者并将职位头衔与基于角色的责任匹配。尽管参与者经常将“管理”引用为一个有能动性的实体和关键利益相关者，但具体需要呼唤的从业者角色仍未明晰。此外，教师分享了在行政和支持人员缺席时被迫承担那些职责的经历。教育系统的复杂性因不断的组织变革、个别机构之间的情境差异，以及由于人员流动和资源紧张而产生的重叠角色而加剧。在教育领域，识别出所有适当利益相关者以参与合作的非琐碎任务是多方合作的必要前提条件。

# 5.2 支持协作数据规范

以往评估工程过程的工作指出，缺乏明确的实践以吸引领域专家和多样化利益相关者，以及对结果系统的公平性和实用性的影响 [87]。对此，我们制定了我们的研讨会协议，作为多利益相关者共同设计数据规范的初步方法。我们的研究结果表明，为了实现协作数据规范系统性支持和放大多样化利益相关者声音的潜力，需要结构性支持。我们还通过识别促进参与的过程需求，进一步丰富了参与设计文献，这些需求通过建立共同基础和持续的协作实践来实现。

5.2.1 信息支架。在共同设计工作坊之前，参与者仅被告知研究动机。设计情境和关于数据在机器学习开发中使用的背景信息在会议期间进行介绍。因此，我们的工作坊中的参与形式为由研究人员发起的引导小组讨论。虽然这种研究设计使我们能够观察从业者如何应对知识空白，但初步基础工作的引入可能会促进更高程度的参与。经过精心设计的信息支架可以建立共同基础，克服技术知识差距，并加速参与者之间的主动贡献。

虽然已知缺乏适合教育领域专家关于基础机器学习知识的材料[10]，但用于教育机器学习从业者了解领域背景的材料同样稀缺。尽管在协作机器学习工作中普遍假设非技术专家需要技术信息的支撑，但同样的假设和要求很少被归属于技术专家。关于设计场景的社会和政治背景的预读材料可能为理解领域需求、实践和动机奠定基础。此外，参与者反馈在对自己贡献质量感到不确定以及对角色期望感到不确定。 在进行共同设计之前建立共同基础和定义利益相关者角色，可能更好地为参与者准备更丰富的协作讨论。

信息支架可能会更有效地定义协作背景。参与者在决策过程中面临困难，因为对设计情境的限制缺乏清晰度。尽管开放式情境邀请进行优先级和需求的高级谈判，团队反思将意识形态限制在现实条件下的潜在价值，将财务、劳动力和时间资源考虑在任务的初始制定中。最后，初步工作的纳入可能会增强生成设计过程，使参与者在共同讨论和决策之前有时间独立构思。

5.2.2 共享标准。在不同的会议中，各组在设计数据质量评估规范方面遇到了最大的困难。参与者发现这个任务具有挑战性，因为缺乏跨学科的数据和系统评估的共享语言和标准。非技术利益相关者对标准的机器学习指标（如准确性、预测和召回率）并不熟悉，并且对这些指标在特定设计场景中的应用意义缺乏背景。相应地，技术利益相关者无法将从业者对基于学生学习成果的评估要求转化为可操作的数据规范。尽管意识到现有指标的不完整性，参与者在创造更好地满足情境需求的新指标方面也面临困难。我们呼应以往研究的观点，认为机器学习的公平性需要开发特定领域的质量指标[81]。

5.2.3 持续迭代。应用Delgado等人的框架，参与我们的研讨会是一次性合作，旨在更好地将机器学习应用与利益相关者的需求对齐。尽管这种动机代表了高程度的协作参与，但由于缺乏问责机制，设计未能赋予利益相关者权力。如果没有对利益相关者贡献实施质量的问责，参与研讨会就可能变得形式化，无法实现不同利益相关者的建议。根据Sloan等人的框架，最有意义的利益相关者参与形式（即“作为正义的参与”）需要与多样化利益相关者建立长期合作伙伴关系，通过互利、互惠、公平以及频繁沟通的紧密关系来建立信任。为了建立跨领域合作的流程，以往的工作强调了设计迭代与不断评估的重要性。

确实，参与每个研讨会的与会者都强调了这种协作需求，呼吁在数据规范执行的每个步骤中都要有利益相关者的参与。虽然领域从业者欣赏这种积极的数据规划活动，但他们对实施忠实度和可能在缺席情况下导致有害假设重新进入开发过程表示担忧。涉及多利益相关者的持续协作需要构建一个框架，以定义和支撑参与者在机器学习管道下游阶段的迭代数据规范中的角色。一些团体建议共同创建一套治理性的效用和伦理标准，以便在新的数据决策和权衡出现时用于间隔质量评估。对持续参与的支持可能还涉及开发软件平台，以便让利益相关者参与到数据清洗和模型评估的下游过程。机器学习开发的行业应用可能会受益于新角色的创建，聘用教师和跨界人士担任永久或半永久职位。新兴的教育数据科学领域可能会培养在技术和教育交叉领域具备专业知识的个人，他们能够在不同领域之间进行转换。未来的工作应探索这些以及其他必要的流程，以支持最终用户和领域专家在数据和机器学习开发中的迭代和长期参与，涵盖数据生命周期的每个阶段及其以外的方面。

# 5.3 限制因素

我们呈现的数据规范研讨会程序作为一个概念验证，承认我们的会议受到若干限制。一个2小时的研讨会代表了一种过于简化的数据规范过程，时间限制影响了参与的性质。围绕丰富利益相关者参与的叙述，重点在于通过参与领域背景和受影响社区来防止伤害（例如，[11]）。这种优先级的框架，加上时间限制和利益相关者角色之间潜在的结构性不平等，限制了教师在围绕教育领域公认挑战的倡导中的贡献。当知识差距足够大时，协作时间主要用于建立基础的领域理解，从而使利益相关者潜在的贡献未被充分探索。尽管文献承认参与式设计的局限性 [29, 74]，我们选择进行设计研讨会，因为它们允许我们想象可以适应真实背景的研究方法。本次展示无法评估协作数据规范程序的效率、可行性或经济性。然而，我们识别出它们在解决以模型为中心的发展下游问题方面的潜力，并邀请未来的工作探索将这一实践整合到行业环境中。

此外，我们的采样方法可能引入了选择偏差，偏向于那些感受到较少参与障碍并表现出寻求合作意愿的利益相关者。我们的参与者也未能完整代表利益相关者社区。由于便利性和有关参与研究的伦理法规，学生角色由本科生代表，而不是更准确受到主要K-12设计场景影响的年轻学生。我们从各种研究和行业背景中招募了机器学习工程师，以及专注于不同年龄段和学科领域的教师，但我们没有考虑这种异质性在参与结果中的作用。

最后，四种设计场景在会议中产生了异质性，并由于所涉及数据集的性质（例如，表格、文本和图像数据）引入了不同的挑战和设计讨论。有些场景情感更为强烈，而其他场景在技术上则对利益相关者的挑战更大。例如，涉及学生图像的场景中监视的潜在含义引发了更丰富的关于种族偏见、代表性和公平性的话题讨论，而涉及文本数据的场景则相对较少。虽然表格数据更容易概念化，但利益相关者对图像和文本处理的熟悉程度较低，这些会议在很大程度上依赖技术专家进行处理说明。

# 6 结论

围绕教育领域机器学习应用开发的新兴公平性、问责性、透明性和实用性问题根植于传统机器学习工程过程的局限性。为教育场景开发道德和以人为本的机器学习体验，需要优先考虑与教师和学生的早期合作所形成的高质量数据。在一系列共同设计会议中，通过让多元利益相关者参与，我们观察到了对数据集规范的有意义贡献。参与者分享了领域和技术专长，以便对数据需求进行背景化，倡导利益相关者的价值观，预见下游影响，克服知识界限，并建立共同基础。然而，尽管我们的合作过程提供了许多优势，但仅仅拥有一个席位是不够的。在机器学习数据集规范中赋权利益相关者的观点需要系统性的支持，包括持续让教师和学生参与迭代和共同评估的问责流程，共享上下文数据质量标准，以及为技术和非技术利益相关者提供的信息支架，以便跨越专业知识的界限。

# 致谢

我们感谢评审和我们的研究参与者为他们的时间和有益反馈所做的贡献。本研究得到了斯坦福大学麦考伊家庭社会伦理中心的资助。王大阔作为访问研究员在斯坦福人本人工智能研究所受到了IBM Research的支持。