# 通过可靠且信息丰富的增强技术提升图对比学习在推荐系统中的表现

卢鸿宇 微信，腾讯 中国广州 luhy94@gmail.com 郑博文 中国人民大学 中国北京 bwzheng0324@ruc.edu.cn 张俊杰 中国人民大学 中国北京 junjie.zhang@ruc.edu.cn 陈宇 微信，腾讯 中国北京 nealcui@tencent.com 陈铭 微信，腾讯 中国广州 mingchen@tencent.com 赵欣伟 中国人民大学 中国北京 batmanfly@gmail.com 温基荣 中国人民大学 中国北京 jrwen@ruc.edu.cn

# 摘要

图神经网络（GNN）由于其能够建模高阶用户-物品关系，已成为协同过滤（CF）中的一种强大方法。近年来，为了缓解数据稀疏性并增强表征学习，许多研究致力于将对比学习（CL）与GNN结合。尽管取得了令人鼓舞的改进，但现有方法中基于结构和表征扰动的对比视图生成可能会干扰对比视图中的协同信息，导致正对齐的有效性有限。

为了解决这个问题，我们提出了CoGCL，一个新颖的框架，旨在通过离散编码构建具有更强协作信息的对比视图，从而增强图对比学习。其核心思想是将用户和物品映射到丰富协作信息的离散编码中，以便生成可靠且信息丰富的对比视图。为此，我们首先以端到端的方式引入了多级向量量化器，将用户和物品表示量化为离散编码。基于这些离散编码，我们分别考虑邻域结构和语义相关性，从而增强对比视图的协作信息。在邻域结构方面，我们通过将离散编码视为虚拟邻居提出了虚拟邻居增强，这将观察到的用户-物品交互扩展为涉及离散编码的多个边。在语义相关性方面，我们基于共享离散编码和交互目标识别相似的用户/物品，以生成语义相关的视图。通过这些策略，我们构建了具有更强协作信息的对比视图，并发展了一种三视图图对比学习方法。在四个公共数据集上的大量实验证明了我们所提方法的有效性。此外，详细分析突显了我们在增强推荐图对比学习方面的贡献。我们的代码可在 https://github.com/RUCAIBox/CoGCL 获取。

# CCS 概念

信息系统 推荐系统。

# 关键词

推荐，协同过滤，图对比学习

# ACM 引用格式:

Bowen Zheng, Junjie Zhang, Hongyu Lu, Yu Chen, Ming Chen, Wayne Xin Z oWe 0. 使用可靠且信息丰富的增强技术进行推荐. 载于（请确保输入您权限确认邮件中的正确会议标题（会议缩写‘XX’））ACM, 纽约, NY, 美国, 13 页. https://doi.org/XXXXXXX.XXXXXXX

# 1 引言

在推荐系统的文献中，基于图神经网络（GNN）的协同过滤（CF）由于能够建模高阶用户-项目关系而在推荐系统中显示出显著的成功。这种方法通常涉及将用户-项目互动数据组织为一个二分图，并学习包含来自图结构的协作知识的节点表示。然而，考虑到用户行为的稀疏性，基于GNN的方法往往面临图边缘有限和监督信号不足的挑战。这一挑战妨碍了高质量用户和项目表示的开发，而高质量的表示对提高推荐效果至关重要。为了应对这一挑战，近年来的研究提出将对比学习（CL）与基于GNN的协同过滤结合，以融入自监督信号。

根据对比视图的构建方式，现有的基于图对比学习的方法可以分为两类：结构增强和表示增强。结构增强通过扰动图结构来创建增强图，这些增强图随后被图神经网络用于生成对比节点表示。作为一种代表性方法，SGL采用随机节点/边丢弃来构建增强图作为对比视图。表示增强涉及从交互图中编码节点的额外表示以进行对比学习。特别地，SimGCL通过向节点嵌入添加随机噪声来扰动节点嵌入，以生成对比视图。尽管这些方法有效，但现有的方法仍然受到意外自监督信号的影响。基于扰动的对比视图生成可能会破坏对比视图中的协作信息。更具体地说，在用户行为稀少的推荐场景中，结构扰动可能会丢失稀疏用户的关键交互。而添加到节点嵌入中的随机噪声可能干扰节点表示中的隐含协作语义。此外，第二章第二节的实证分析确认，基于扰动的正对之间的对齐效果并不如预期，模型性能在很大程度上依赖于对比学习所促进的不同实例之间的表示均匀性。

![](images/1.jpg)  

Figure 1: Comparison of current graph CL-based methods (e.g., SGL [51], SimGCL [60]) that disrupt collaborative information within contrastive views and the proposed approach that enhances collaborative information.

考虑到这些问题，我们的目标是构建更高质量的对比视图以增强协作信息。具体而言，我们努力在对比视图生成中保持可靠性和信息丰富性。关于可靠性，我们预计通过图增强引入的结构信息是有根据的，而不是任意的，即基于观察到的用户-项目交互。我们的想法是将每个用户或项目表示为与协作信息相关的离散ID元组（在本文中称为代码）。给定用户和项目代码，如图1所示，我们可以自然地将一个${ } ^ { * } \cup { } - \dot { \beth } { } ^ { s }$交互边扩展为多个“u-codes (i)”和“codes (u) $- \overset { \cdot } { \beth } ^ { \mathfrak { n } }$边。关于信息丰富性，这种基于代码的增强可以改善邻域结构，有效缓解交互图的稀疏性，将代码视为虚拟邻居。此外，不同用户/项目之间共享离散代码表明它们在协作语义上的相关性，例如图1中的$u$和$u ^ { + }$。为了发展我们的研究方法，我们专注于（a）如何优雅地学习与丰富协作信息相关的离散代码，以及（b）如何将学习到的离散代码整合到图对比学习框架中以改善推荐。

在本文中，我们提出了CoGCL，这是一种可靠且信息丰富的图对比学习方法，旨在通过引入离散编码构建暗示更强协作信息的对比视图。为了将用户和物品映射到充满协作信息的离散编码中，我们以端到端的方式学习多级向量量化器，将通过图神经网络编码的用户和物品表示量化为离散编码。随后，学到的离散编码被用来从两个方面增强对比视图的协作信息：邻域结构和语义相关性。在邻域结构方面，我们通过基于现有交互将离散编码视为虚拟邻居进行虚拟邻居增强。这一过程旨在增强节点的邻居信息并缓解对比视图中的交互稀疏性。在语义相关性方面，我们将共享离散编码或交互目标的用户/物品识别为语义相似的进行正样本采样。通过通过对比学习将语义相关的用户/物品对齐，我们可以进一步增强协作语义的整合。通过上述策略，我们可以生成具有更强协作信息的多种对比视图。最后，我们提出了一种三视图图对比学习方法，以实现增强节点和相似用户/物品之间的对齐。本文的贡献可以总结如下： • 我们提出了一种可靠且信息丰富的图对比学习方法，称为CoGCL，通过离散编码构建暗示更强协作信息的对比视图。 • 我们提出了一种优雅的端到端方法来学习用户和物品的离散编码。这些离散编码被用来从邻域结构和语义相关性两个方面增强对比视图的协作信息。 • 在四个公共数据集上进行的广泛实验表明，我们的方法在一致性上优于基线模型。进一步的深入分析阐明了我们设计的组件在增强推荐图对比学习中的关键作用。

# 2 初步与实证分析

在本节中，我们首先概述了图神经网络在推荐系统中的常见范式。随后，我们进行了简要的实证分析，以进一步探讨图神经网络在对比学习中的工作原理。

# 2.1 图神经网络推荐系统

给定用户集合 $\mathcal { U }$ 和物品集合 $\boldsymbol { \mathcal { T }$，令 $\mathbf { R } \in \{ 0 , 1 \} ^ { | \mathcal { U } | \times | \mathcal { I } | }$ 表示用户-物品交互矩阵，其中 ${ \bf R } _ { u , i } = 1$ 表示用户 $u$ 和物品 $i$ 之间存在观察到的交互， 否则 $\mathbf { R } _ { u , i } = 0$。基于交互数据 $R$，基于GNN的协同过滤方法构建一个二分图 $\mathcal { G } = ( \mathcal { V } , \mathcal { E } )$，其中节点集合 $\mathbf { \nabla } _ { \mathbf { \gamma } } \mathbf { \mathbf { \Phi } } _ { \mathbf { \mathcal { V } } } = \{ { \mathcal { U } } \cup T \}$ 包含所有用户和物品，$\mathcal { E } = \{ ( u , i ) | u \in \mathcal { U } , i \in \mathcal { T } , \mathbf { R } _ { u , i } = 1 \}$ 表示交互边的集合。通常，基于GNN的协同过滤方法 [15, 48] 采用邻居聚合方案在 $\mathcal { G }$ 上获取信息丰富的节点表示，其形式化描述如下：

$$
\begin{array} { r } { \boldsymbol { \mathbf { Z } } ^ { l } = \boldsymbol { \mathbf { \check { G } } } \boldsymbol { \mathbf { N } } \boldsymbol { \mathbf { N } } ( \boldsymbol { \mathbf { Z } } ^ { l - 1 } , \boldsymbol { \mathbf { \check { \phi } } } ) , \quad \boldsymbol { \mathbf { Z } } \mathrm { ~ = ~ \boldsymbol { \ R e a d o u t } ( \boldsymbol { \mathbf { \check { Z } } } ^ 0 , \boldsymbol { \mathbf { Z } } ^ 1 , \ldots , \boldsymbol { \mathbf { Z } } ^ { L } ] ) , } } \end{array}
$$

![](images/2.jpg)  

Figure 2: Performance comparison of different graph CLbased methods with their variants.

其中 $L$ 表示 GNN 层数，$Z ^ { l } ~ \in ~ \mathbb { R } ^ { | \mathcal { V } | \times d }$ 表示第 $l$ 层 GNN 中的节点表示，捕捉第 $l$ 阈邻域信息。这里，$\mathbf { Z } ^ { 0 }$ 是可训练的 ID 嵌入矩阵。读出函数 Readout $( \cdot )$ 用于汇总所有表示以进行预测。然后，预测得分定义为用户和项目表示之间的相似性（例如，内积，$\hat { y } _ { u i } = z _ { u } ^ { T } z _ { i } )$。对于推荐优化目标，大多数研究使用成对的贝叶斯个性化排序 (BPR) [36] 损失进行模型训练，记作 $\mathcal { L } _ { b p r }$。此外，图形 CL 基础的方法 [4, 29, 51, 60] 提出通过在两个对比视图之间进行对比学习，进一步提高推荐性能。具体而言，给定一个节点的两个视图表示 $\mathbf { z } _ { v } ^ { \prime }$ 和 $\mathbf { z } _ { \boldsymbol { v } } ^ { \prime \prime }$（例如，通过两个增强图 [51] 获得），基于 InfoNCE [42] 损失的 CL 优化目标为：

$$
\mathcal { L } _ { c l } = - \log \frac { e ^ { s ( \mathbf { z } _ { v } ^ { \prime } , \mathbf { z } _ { v } ^ { \prime \prime } ) / \tau } } { e ^ { s ( \mathbf { z } _ { v } ^ { \prime } , \mathbf { z } _ { v } ^ { \prime \prime } ) / \tau } + \sum _ { \tilde { v } \in \mathcal { V } _ { \mathrm { n e g } } } e ^ { s ( \mathbf { z } _ { v } ^ { \prime } , \mathbf { z } _ { \tilde { v } } ^ { \prime \prime } ) / \tau } } ,
$$

其中 $s ( \cdot )$ 表示余弦相似度函数，$\tau$ 是温度系数，$v$ 是用户/项目，$\mathcal { V } _ { \mathrm { n e g } }$ 表示负样本集，例如批内负样本。最后，基于图的对比学习的协同过滤联合学习方案如下所示：

$$
\mathcal { L } = \mathcal { L } _ { b p r } + \mu \mathcal { L } _ { c l } ,
$$

其中 $\mu$ 是用于平衡两个目标的超参数。

# 2.2 干扰视图之间的对齐效果不佳

为了进一步强调我们的动机，我们进行了一项实证分析，以探讨现有方法在破坏协作信息方面的局限性。遵循之前的研究[12, 46]，当负样本数量较大时，InfoNCE损失的渐近性可以通过以下方程表示：

$$ - \frac { 1 } { \tau } \underset { ( \mathbf { z } , \mathbf { z } ^ { + } ) \sim p _ { \mathrm { p o s } } } { \mathbb { E } } \left[ s ( \mathbf { z } , \mathbf { z } ^ { + } ) \right] + \underset { \mathbf { z } \sim p _ { \mathrm { d a t a } } } { \mathbb { E } } \left[ \log _ { \mathbf { z } ^ { - } \sim p _ { \mathrm { d a t a } } } \left[ e ^ { s ( \mathbf { z } , \mathbf { z } ^ { - } ) / \tau } \right] \right] , $$ 其中 $ { p _ { \mathrm { p o s } } }$ 表示正样本对的分布，$ { p _ { \mathrm { d a t a } } }$ 表示整体数据分布。从直观上看，第一个项保持正样本对之间的相似性，而第二个项则拉开负样本对之间的距离。这些在单位超球面上被正式定义为表示的一致性和均匀性 [46]。在这里，我们试图通过单独禁用这两个项的影响来研究它们的贡献。具体而言，我们对三个具有代表性的图神经网络基于对比学习的协同过滤模型进行实验：SGL [51]、SimGCL [60] 和 LightGCL [4]。对于每个模型，我们引入两种变体：(a) w/o U 停止了公式（2）中负样本对的相似性计算的梯度（使用 PyTorch 的 det ach 函数），这导致公式（4）中的均匀性崩溃。(b) w/o A 停止了公式（2）中正样本对之间的梯度，导致公式（4）中的一致性崩溃。从图 2 的结果中，我们可以观察到以下两个现象：

![](images/3.jpg)  

Figure 3: The overall framework of our CoGCL, which enhances graph CL by constructing contrastive views that imply stronger collaborative information via discrete codes.

禁用统一性并仅将正对拉近并未显著提升相较于LightGCN的性能。此外，去除统一性（SGL w/o U）导致性能下降。禁用对齐导致的负面影响非常小，甚至可能会稍微提高性能。通常，上述方法中正例之间的对齐可能无效或潜在有害。我们认为，扰动方法如随机边/节点丢弃（即SGL）、随机噪声（即SimGCL）和通过SVD不完整重构邻接矩阵（即LightGCL）可能会干扰对比视图中的协作信息[27, 29, 55]，而基于这些对比视图的对齐可能会误导图卷积学习中的模型学习。

# 3 方法论

在这一部分，我们提出了CoGCL，一个新颖的框架，通过构建包含更强协同信息的对比视图来增强图对比学习。我们所提方法的整体框架如图3所示。

# 3.1 方法概述

如第1节和第2节所述，我们的基本想法是通过引入与丰富协作信息相关的离散编码来增强对比视图生成并改进图形对比学习。为此，我们在以下几个方面进行了努力： • 端到端离散编码学习（第3.2节）：为了优雅地学习与丰富协作信息相关的离散编码，以表示用户和物品，我们提出了一种端到端的多层次向量量化器，该量化器将由GNN编码的用户和物品表示量化为离散编码。 • 可靠且信息丰富的对比视图生成（第3.3节）：基于学习到的离散编码，我们通过分别提出虚拟邻居增强和语义相关性采样，使用它们生成可靠且信息丰富的对比视图。 • 三视图图形对比学习（第3.4节）：基于生成的对比视图，我们最终引入三视图图形对比学习，以实现在多个对比视图之间的对齐，从而将这些视图中包含的更强的协作信息整合到模型学习中。

# 3.2 端到端离散编码学习

如前所述，我们旨在学习丰富的协同信息的离散编码，以增强对比视图生成。这包括 (a) 通过 GNN 编码用户和项目表示（第 3.2.1 节），以及 (b) 学习端到端的多层向量量化器，将编码表示映射到离散代码（第 3.2.2 节）。3.2.1 通过 GNN 进行表示编码。根据之前的研究 [29, 51, 60]，我们在框架中采用 LightGCN [15] 作为 GNN 编码器，以便于在交互图中传播邻居信息，因其简单而有效。值得注意的是，与先前的实现不同，我们在每一层的输入表示上加入了 dropout（而不是在图结构上进行边缘 dropout），以减轻过拟合。该过程可以表示为：

$$
\mathbf { Z } ^ { l } = \mathrm { G N N } ( \rho ( \mathbf { Z } ^ { l - 1 } ) , G ) ,
$$

其中 $\rho ( \cdot )$ 表示 dropout 操作。关于读出函数，我们遵循 SimGCL 的方法，跳过 $\mathbf { Z } ^ { 0 }$，这在基于图表示学习的协同过滤中显示出轻微的性能提升。随后，用户和物品的表示分别用 $z _ { u }$ 和 $z _ { i }$ 表示，这将用于推荐任务和多级编码的联合学习。 3.2.2 端到端多级编码学习。给定用户和物品的表示，学习离散编码的常见方法包括层次聚类、语义哈希和矢量量化。我们的 CoGCL 采用端到端的多级矢量量化（vQ）方法，如残差量化（RQ）和乘积量化（PQ）。接下来，我们以用户的离散编码学习为例，量化过程可以表示为：

$$
c _ { u } ^ { h } = \underset { k } { \arg \operatorname* { m a x } } P ( k | \mathbf { z } _ { u } ^ { h } ) , \quad P ( k | \mathbf { z } _ { u } ^ { h } ) = \frac { e ^ { s ( \mathbf { z } _ { u } ^ { h } , \mathbf { e } _ { k } ^ { h } ) / \tau } } { \sum _ { j = 1 } ^ { K } e ^ { s ( \mathbf { z } _ { u } ^ { h } , \mathbf { e } _ { j } ^ { h } ) / \tau } } ,
$$

其中 $c _ { u } ^ { h }$ 是用户的第 $h$ 个编码，$\mathbf { z } _ { u } ^ { h }$ 表示第 $h$ 层的用户表示。RQ 计算每一层的残差表示，表示为 ${ \bf z } _ { u } ^ { h + 1 } = { \bf z } _ { u } ^ { h } - { \bf e } _ { c _ { h } } ^ { h }$，并且 $\mathbf { z } _ { u } ^ { 1 } = \mathbf { z } _ { u }$。Psplits 将 $\mathbf { z } _ { u }$ 拆分为 $H$ 个子向量 $\mathbf { z } _ { u } = \left[ \mathbf { z } _ { u } ^ { 1 } ; \ldots ; \mathbf { z } _ { u } ^ { H } \right]$，每个维度为 $d / H$。在这里，我们不采用先前 VQ 工作中常用的欧几里得距离 [14, 34, 44, 64]，而是采用余弦相似度，以便与 CL 中的相似性度量同步（公式 (2)）。我们的优化目标是通过交叉熵 (CE) 损失最大化将表示分配到其对应中心的似然性。正式来说，用户离散编码学习的训练损失为：

$$
\mathcal { L } _ { c o d e } ^ { U } = - \frac { 1 } { H } \sum _ { h = 1 } ^ { H } \log P ( c _ { u } ^ { h } | \mathbf { z } _ { u } ^ { h } ) ,
$$

其中 LU $\mathcal { L } _ { c o d e } ^ { U }$ 表示用户端的离散编码损失，而物品的损失定义类似，记作 $\mathcal { L } _ { c o d e } ^ { I }$。总的编码损失 $\mathcal { L } _ { c o d e } = \mathcal { L } _ { c o d e } ^ { U } + \mathcal { L } _ { c o d e } ^ { \bar { I } }$。

# 3.3 可靠且信息丰富的对比视图生成

与以前涉及信息干扰的方法相比，我们强化协作信息的动机需要我们开发一种可靠且富有信息的对比视图生成方法，通过学习到的离散编码。下面我们介绍虚拟邻居增强（第3.3.1节）和语义相关性采样（第3.3.2节），分别用于增强对比视图的邻居结构和语义相关性。 3.3.1 通过离散编码的虚拟邻居增强。为了生成具有增强邻居结构的可靠对比视图，我们在图中使用离散编码进行虚拟邻居增强。例如，考虑用户 $u$ ，我们以概率 $\mathcal { P }$ 从用户的邻居 $N _ { u }$ 中选择节点来创建增强数据，记作 $\mathcal { N } _ { u } ^ { \mathrm { a u g } }$。然后我们在图结构上设计两个操作来增强节点邻居，即“替换”和“添加”。前者用其对应的编码替换邻居项，不保留原始边，而后者则直接将编码作为虚拟邻居添加。所有增强操作严格依赖于观察到的交互，以确保可靠性。形式上，$u$ 的增强边可以表示为：

$$
\begin{array} { r l } & { { \mathcal E } _ { u } ^ { c } = \left\{ ( u , c _ { i } ^ { h } ) | i \in N _ { u } ^ { \mathrm { a u g } } , h \in \{ 1 , . . . , H \} \right\} , } \\ & { { \mathcal E } _ { u } ^ { r } = \left\{ ( u , i ) | i \in ( N _ { u } \setminus N _ { u } ^ { \mathrm { a u g } } ) \right\} \cup { \mathcal E } _ { u } ^ { c } , } \\ & { { \mathcal E } _ { u } ^ { a } = \{ ( u , i ) | i \in N _ { u } \} \cup { \mathcal E } _ { u } ^ { c } , } \end{array}
$$

其中，$\mathcal { E } _ { u } ^ { c }$ 表示用户 $u$ 与离散编码之间的边，$\mathcal { E } _ { u } ^ { r }$ 是用户与“替换”增强的所有交互边，$\mathcal { E } _ { u } ^ { a }$ 是与“添加”增强的边。在这种情况下，离散编码可以被视为用户的虚拟邻居。上述操作包括将原始邻居替换为多个虚拟邻居或添加额外的虚拟邻居，可以带来更丰富的邻居信息，有效缓解图的稀疏性。物品的图增强可以对称地进行。为了获得一对用于对比学习（CL）的增强节点，我们执行两轮虚拟邻居增强。增强后的图如下所示：

$$
\mathcal { G } ^ { 1 } = ( \widetilde { \mathcal { V } } , \mathcal { E } ^ { o _ { 1 } } ) , \quad \mathcal { G } ^ { 2 } = ( \widetilde { \mathcal { V } } , \mathcal { E } ^ { o _ { 2 } } ) , \quad o _ { 1 } , o _ { 2 } \in \{ r , a \}
$$

节点集 $\widetilde { \mathcal { V } } = \{ \mathcal { U } \cup C ^ { U } \cup \mathcal { I } \cup C ^ { I } \}$ 包含所有用户、物品及其对应的离散编码。两个随机操作 $o _ { 1 }$ 和 $o _ { 2 }$ 从“替换” $( i . e . , r )$ 和“添加” (i.e., a) 中选择。${ \varepsilon } ^ { o _ { 1 } }$ 和 $\varepsilon ^ { o _ { 2 } }$ 表示通过上述虚拟邻居增强得到的边集，适用于所有用户和物品。这两个图中的增强节点具有丰富（广泛的虚拟邻居）和同质（大量的共同邻居）邻居结构信息。两个增强节点之间的对齐有助于将更多的邻居结构信息引入模型。按照 SGL [51] 的方法，我们在训练期间每个周期更新一次离散编码和增强图。

3.3.2 基于离散编码的语义相关性采样。在我们的框架中，我们不仅将同一节点的不同增强视图视为正样本，还将具有相似语义的不同用户/项目视为互为正样本，这导致了更具信息性的对比视图。这强调了相似实例之间的对齐，而不是盲目地使不同实例之间的距离增加[53, 60]。值得注意的是，与 NCL [29] 基于 EM 算法学习聚类中心作为锚点不同，我们通过离散编码以更细粒度的方式测量语义相关性。具体而言，我们通过以下两种方式评估用户的语义相关性：（a）共享代码：我们学习的离散编码与用户表示的协作语义相关联。两个用户之间共享代码表明细粒度的语义相关性。因此，我们将共享至少 H-1 代码的用户识别为正样本。（b）共享目标：当两个用户共享一个共同的交互目标，即他们在数据集中拥有相同的预测标签时，我们也认为他们是相关的。这种监督正采样方法在包括句子嵌入[12]和序列推荐[33]等多种场景中显示了其有效性。考虑到由上述两组实例组合而成的正样本集，我们为每个用户配对一个采样的相关实例进行对比学习。此外，项目的语义相关正样本也可以以对称的方式获得。通过在上述采样实例中执行对比学习，我们旨在增强相似用户/项目之间的聚类，并改进语义学习。

# 3.4 三视图图对比学习

在上述对比视图生成方法之后，我们可以通过虚拟邻居增强和语义相关性采样为每个节点获得三个具有更强协作信息的对比视图：两个增强节点具有更丰富的邻域结构以及一个语义相关的用户/项目。在这一部分，我们首先介绍如何编码多视图节点表示，然后提出我们的三视图图对比学习方法，以有效整合结构和语义信息。3.4.1 多视图表示编码。对于这两个增强图，我们引入用户和项目离散代码的额外可学习嵌入作为补充输入，记作 $\mathbf { Z } ^ { c } \in \mathbb { R } ^ { ( | C ^ { U } | + | C ^ { I } | ) \times d }$。增强图的输入嵌入矩阵是通过将 ID 嵌入与代码嵌入连接而成，记作 $\dot { \bf Z } ^ { 0 } = [ { \bf Z } ^ { 0 } ; { \bf Z } ^ { c } ]$。然后，我们基于第 3.2.1 节中的相同 GNN 编码器获得不同视图的表示：

$$
\begin{array} { r } { \mathbf { Z } _ { 1 } ^ { l } = \mathrm { G N N } ( \rho ( \mathbf { Z } _ { 1 } ^ { l - 1 } ) , \mathcal { G } ^ { 1 } ) , \quad \mathbf { Z } _ { 2 } ^ { l } = \mathrm { G N N } ( \rho ( \mathbf { Z } _ { 2 } ^ { l - 1 } ) , \mathcal { G } ^ { 2 } ) , } \end{array}
$$

初始表示被设置为 ${ \bf Z } _ { 1 } ^ { 0 } = { \bf Z } _ { 2 } ^ { 0 } = \widetilde { { \bf Z } } ^ { 0 }$。在应用读出函数后，我们分别将这两个视图的表示记为 $\mathbf { Z ^ { \prime } }$ 和 $\mathbf { Z } ^ { \prime \prime }$。至于与语义相关的用户/项目，我们直接采用根据第 3.2.1 节初始交互图获得的节点表示，因为没有进行结构增强。此外，我们引入的表示 dropout 也可以视为一种小的数据增强。在两个前向传播中应用的不同 dropout 掩码导致了不同的特征 [12, 33, 56, 66]。3.4.2 邻居增强视图之间的对齐。如第 3.3.1 节所述，经过两轮虚拟邻居增强产生的两个增强节点具有丰富的邻居结构。因此，我们的目标是通过对齐这些邻居增强视图来融入更多结构信息并提升模型效能。正式地，用户端的对齐目标如下：

$$
\mathcal { L } _ { a u g } ^ { U } = - \left( \log \frac { e ^ { s ( \mathbf { z } _ { u } ^ { \prime } , \mathbf { z } _ { u } ^ { \prime \prime } ) / \tau } } { \sum _ { \tilde { u } \in \mathcal { B } } e ^ { s ( \mathbf { z } _ { u } ^ { \prime } , \mathbf { z } _ { \tilde { u } } ^ { \prime \prime } ) / \tau } } + \log \frac { e ^ { s ( \mathbf { z } _ { u } ^ { \prime \prime } , \mathbf { z } _ { u } ^ { \prime } ) / \tau } } { \sum _ { \tilde { u } \in \mathcal { B } } e ^ { s ( \mathbf { z } _ { u } ^ { \prime \prime } , \mathbf { z } _ { \tilde { u } } ^ { \prime } ) / \tau } } \right) ,
$$

其中 $u$ 和 $\tilde{u}$ 是批数据 $\mathcal{B}$ 中的用户。$\mathbf{z}_{u}^{\prime}$ 和 $\mathbf{z}_{u}^{\prime\prime}$ 表示经过虚拟邻居增强后的两种不同用户表征。损失由两个部分组成，代表两个视图之间的双向对齐。同样，我们为物品方面计算 CL 损失 $\mathcal{L}_{aug}^{I}$。结合得到 $\mathcal{L}_{aug} = \mathcal{L}_{aug}^{U} + \mathcal{L}_{aug}^{I}$。3.4.3 语义相关用户/物品之间的对齐。遵循第 3.3.2 节中的语义相关性采样方法，我们为每个用户 $u$ 随机选择一个具有相似协同语义的正例，记作 $u^{+}$。然后，我们对这些相关用户进行对齐，以将更多协同语义信息融入模型中。对齐损失可以写为：

$$
\mathcal { L } _ { s i m } ^ { U } = - \left( \log \frac { e ^ { s ( \mathbf { z } _ { u } ^ { \prime } , \mathbf { z } _ { u ^ { + } } ) / \tau } } { \sum _ { \tilde { u } \in \widetilde { \mathcal { B } } } e ^ { s ( \mathbf { z } _ { u } ^ { \prime } , \mathbf { z } _ { \tilde { u } } ) / \tau } } + \log \frac { e ^ { s ( \mathbf { z } _ { u } ^ { \prime \prime } , \mathbf { z } _ { u ^ { + } } ) / \tau } } { \sum _ { \tilde { u } \in \widetilde { \mathcal { B } } } e ^ { s ( \mathbf { z } _ { u } ^ { \prime \prime } , \mathbf { z } _ { \tilde { u } } ) / \tau } } \right) ,
$$

其中 $( u , u ^ { + } )$ 是一个正向用户对，$\widetilde { \mathcal B }$ 是一批次中的采样数据。方程的两个组成部分分别对应于两个增强视图之间的对齐和相似用户之间的关系。此外，结合项目侧的对称对齐损失，相似用户/项目之间的总对齐损失为 $\mathcal { L } _ { s i m } = \mathcal { L } _ { s i m } ^ { U } + \mathcal { L } _ { s i m } ^ { I }$。在最终的整体优化中，通过结合推荐损失（即 BPR 损失）、离散编码学习目标（公式 (7)）和所有对比学习损失（公式 (13) 和公式 (14)），我们的 CoGCL 通过最小化以下整体损失来进行联合优化：

$$
\mathcal { L } = \mathcal { L } _ { b p r } + \lambda \mathcal { L } _ { c o d e } + \mu \mathcal { L } _ { a u g } + \eta \mathcal { L } _ { s i m } ,
$$

其中 $\lambda$、$\mu$ 和 $\eta$ 是用于不同目标之间权衡的超参数。

# 3.5 讨论

在本节中，我们对现有的基于图的对比学习推荐方法进行了简要比较，以突出CoGCL的创新性和贡献。根据如何构造对比视图，现有方法可以分为两类：结构增强和表示增强。

Table 1: Statistics of the preprocessed datasets.   

<table><tr><td>Datasets</td><td>#Users</td><td>#Items</td><td>#Interactions</td><td>Sparsity</td></tr><tr><td>Instrument</td><td>48,453</td><td>21,413</td><td>427,674</td><td>99.959%</td></tr><tr><td>Office</td><td>181,878</td><td>67,409</td><td>1,477,820</td><td>99.988%</td></tr><tr><td>Gowalla</td><td>29,858</td><td>40,988</td><td>1,027,464</td><td>99.916%</td></tr><tr><td>iFashion</td><td>300,000</td><td>81,614</td><td>1,607,813</td><td>99.993%</td></tr></table>

结构增强方法通常通过对图结构进行扰动，如随机节点/边丢弃，生成对比视图。最近的几项工作尝试使用具有良好理论基础的结构扰动方法，例如基于奇异值分解的邻接矩阵重构和基于掩码自编码的图推理发现。然而，在稀疏图上的扰动无法构建更具信息性的对比视图。相比之下，我们的方法既可靠又富有信息性，利用离散编码作为虚拟邻居，可靠地增强节点邻域结构并缓解数据稀疏性。邻接有丰富邻居的两个增强节点之间的对齐，有利于进一步整合协同信息。表示增强方法涉及将额外的节点表示建模为对比视图，如学习超图表示和添加随机噪声。然而，由于低秩超图矩阵和噪声扰动的限制，生成的对比视图也遭遇了语义干扰问题。此外，这些方法通常不加区分地区分不同实例的表示。相比之下，我们将共享代码或交互目标的用户/项目视为语义相关的对象。通过对齐具有相似协同语义的用户/项目，我们可以进一步释放协同学习的潜力，增强模型的语义学习。

# 4 实验

# 4.1 实验设置

4.1.1 数据集。我们在四个公共数据集上评估我们提出的方法：来自最新的 Amazon2023 基准的 Instrument 和 Office 子集 [17]，Gowalla [10]，Alibaba-iFashion [8]。对于 Instrument 和 Office 数据集，我们过滤掉低活跃用户和交互少于五次的项目。对于 Gowalla 数据集，我们使用 10-core 过滤来确保数据质量，遵循之前的工作 [15, 48]。至于稀疏的 iFashion 数据集，我们采用 [51] 处理过的数据，随机抽样 $3 0 0 \mathrm { k }$ 用户及其交互。我们处理的数据集在领域、规模和稀疏性方面各不相同。它们的统计信息汇总在表 1 中。对于每个数据集，我们将观察到的交互按 8:1:1 的比例划分为训练集、验证集和测试集。4.1.2 基线模型。我们采用以下竞争基线与我们的 CoGCL 进行比较，包括传统的协同过滤模型：（1）BPR [36]，（2）GCMC [41]，（3）NGCF [48]，（4）DGCF [49]，（5）LightGCN [15]，（6）SimpleX [31]，以及各种代表性的基于 CL 的模型：（7）SLRec [56]，（8）SGL [51]，（9）NCL [29]，（10）HCCF [53]，（11）GFormer [27]，（12）SimGCL [60]，（13）LightGCL [4]。有关上述基线模型的更详细介绍见附录 B.1。4.1.3 评估设置。为评估上述模型的性能，我们采用推荐中的两项广泛使用的指标：Recall@N 和标准化折扣累积增益 $\mathrm { \Omega } ( { \mathrm { N D C G } } ) @ N$。在本文中，我们将 $N$ 设置为 5、10 和 20。为了进行严格的比较，我们对整个项目集进行全面排名评估 [62, 63]，而不是基于样本的评估。

4.1.4 实施细节。对于所有比较模型，我们使用 Adam 作为优化算法，并将嵌入维度统一设置为 64。批量大小为 4096，基于 GNN 的方法中 GNN 层数设置为 3。为了确保公平比较，我们利用网格搜索根据基准方法原始论文中报告的超参数设置来获取最佳性能。对于我们的方法，我们采用 RQ 作为默认的离散编码学习方法。代码层级数量 $H = 4$，温度 $\tau = 0 . 2$。由于 Instrument 和 Gowalla 数据集规模较小，编码表大小 $K$ 设置为 256，而 Office 和 iFashion 数据集由于规模较大，编码表大小设置为 512。超参数 $\lambda$ 在 {5, 1, 0.5} 中调整，而 $\mu$ 和 $\eta$ 在 {5, 1, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005, 0.001} 中调整。在虚拟邻居增强中“替换”和“添加”的概率设置为 $\{ 0 . 0 1 , 0 . 0 5 , 0 . 1 , 0 . 1 5 , 0 . 2 , 0 . 2 5, 0.3, 0.4, 0.5, 0.6}$。有关超参数调整实验的更多信息，请参阅附录 B.2。

# 4.2 整体性能

表2展示了CoGCL与其他基线模型的性能比较总体结果。从结果中，我们发现以下观察：基于对比学习的方法（如SGL、NCL、SimGCL、LightGCL）表现出明显优于传统矩阵分解方法（如BPR、SimpleX）和基于图神经网络的方法（如NGCF、LightGCN）。这种性能提升可归因于对比学习所带来的自监督信号，这有助于缓解数据稀疏性并增强表征学习。在基于对比学习的方法中，结构增强和表示增强在不同场景下展现出不同的优势。具体而言，作为典型表示增强方法的SimGCL在Instrument和Gowalla数据集上表现优于其他基线模型，这得益于通过引入随机噪声提高的一致性。相反，Office和iFashion数据集上的最具竞争力的模型分别是GFormer和LightGCL，均为结构增强方法。而SGL的表现较差，表明随机边/节点丢弃可能干扰关键的结构信息，从而带来负面影响。最后，我们提出的CoGCL在所有情况下持续保持最佳性能，相较于基线方法实现了显著提升。与这些基线模型不同，CoGCL通过构建暗示更强协作信息的对比视图，释放了对比学习的潜力。基于丰富协作信息的离散编码，我们引入虚拟邻居增强和语义相关性采样，分别增强对比视图的邻里结构和语义相关性。此外，在获得的对比视图之间进行三视图图对比学习，为模型带来了补充的协作见解。因此，CoGCL在Office和iFashion数据集上展现出卓越的鲁棒性和有效性。

<table><tr><td>Dataset</td><td>Metric</td><td>BPR</td><td>GCMC</td><td>NGCF</td><td>DGCF</td><td>LightGCN SimpleX</td><td></td><td>SLRec</td><td>SGL</td><td>NCL</td><td>HCCF GFormer</td><td></td><td>SimGCL</td><td>LightGCL</td><td>CoGCL</td><td>Improv.</td></tr><tr><td rowspan="5">Instrument</td><td>Recall@5</td><td>0.0293</td><td>0.0334</td><td>0.0391</td><td>0.0401</td><td>0.0435</td><td>0.0386</td><td>0.0381</td><td>0.0449</td><td>0.0449</td><td>0.0456</td><td>0.0471</td><td>0.0470</td><td>0.0468</td><td>0.0515</td><td>9.34%</td></tr><tr><td>NDCG@5</td><td>0.0194</td><td>0.0218</td><td>0.0258</td><td>0.0269</td><td>0.0288</td><td>0.0244</td><td>0.0256</td><td>0.0302</td><td>0.0302</td><td>0.0303</td><td>0.0314</td><td>0.0316</td><td>0.0310</td><td>0.0345</td><td>9.18%</td></tr><tr><td>Recall@10</td><td>0.0469</td><td>0.0532</td><td>0.0617</td><td>0.0628</td><td>0.0660</td><td>0.0631</td><td>0.0574</td><td>0.0692</td><td>0.0685</td><td>0.0703</td><td>0.0715</td><td>0.0717</td><td>0.0715</td><td>0.0788</td><td>9.90%</td></tr><tr><td>NDCG@10</td><td>0.0250</td><td>0.0282</td><td>0.0331</td><td>0.0342</td><td>0.0361</td><td>0.0324</td><td>0.0319</td><td>0.0380</td><td>0.0377</td><td>0.0383</td><td>0.0393</td><td>0.0395</td><td>0.0391</td><td>0.0435</td><td>10.13%</td></tr><tr><td>Recall@20</td><td>0.0705</td><td>0.0824</td><td>0.0929</td><td>0.0930</td><td>0.0979</td><td>0.0984</td><td>0.0820</td><td>0.1026</td><td>0.1011</td><td>0.1028</td><td>0.1041</td><td>0.1057</td><td>0.1042</td><td>0.1152</td><td>8.99%</td></tr><tr><td rowspan="7"></td><td>NDCG@20</td><td>0.0310</td><td>0.0357</td><td>0.0411</td><td>0.0419</td><td>0.0442</td><td>0.0413</td><td>0.0381</td><td>0.0466</td><td>0.0459</td><td>0.0466</td><td>0.0478</td><td>0.0482</td><td>0.0474</td><td>0.0526</td><td>9.13%</td></tr><tr><td>Recall@5</td><td>0.0204</td><td>0.0168</td><td>0.0178</td><td>0.0258</td><td>0.0277</td><td>0.0291</td><td>0.0294</td><td>0.0349</td><td>0.0293</td><td>0.0340</td><td>0.0353</td><td>0.0349</td><td>0.0338</td><td>0.0411</td><td>16.43%</td></tr><tr><td>NDCG@5</td><td>0.0144</td><td>0.0109</td><td>0.0116</td><td>0.0177</td><td>0.0186</td><td>0.0199</td><td>0.0209</td><td>0.0242</td><td>0.0201</td><td>0.0230</td><td>0.0245</td><td>0.0240</td><td>0.0232</td><td>0.0287</td><td>17.14%</td></tr><tr><td>Recall@10</td><td>0.0285</td><td>0.0270</td><td>0.0279</td><td>0.0380</td><td>0.0417</td><td>0.0422</td><td>0.0402</td><td>0.0493</td><td>0.0434</td><td>0.0489</td><td>0.0492</td><td>0.0494</td><td>0.0490</td><td>0.0582</td><td>17.81%</td></tr><tr><td>NDCG@10</td><td>0.0170</td><td>0.0141</td><td>0.0149</td><td>0.0217</td><td>0.0231</td><td>0.0241</td><td>0.0244</td><td>0.0289</td><td>0.0243</td><td>0.0282</td><td>0.0292</td><td>0.0289</td><td>0.0280</td><td>0.0343</td><td>17.47%</td></tr><tr><td>Recall@20</td><td>0.0390</td><td>0.0410</td><td>0.0438</td><td>0.0544</td><td>0.0605</td><td>0.0602</td><td>0.0534</td><td>0.0681</td><td>0.0629</td><td>0.0677</td><td>0.0672</td><td>0.0689</td><td>0.0698</td><td>0.0785</td><td>12.46%</td></tr><tr><td>NDCG@20</td><td>0.0197</td><td>0.0178</td><td>0.0189</td><td>0.0258</td><td>0.0279</td><td>0.0287</td><td>0.0277</td><td>0.0336</td><td>0.0292</td><td>0.0331</td><td>0.0338</td><td>0.0337</td><td>0.0332</td><td>0.0393</td><td></td><td>14.18%</td></tr><tr><td rowspan="6">Gowalla</td><td>Recall@5</td><td>0.0781</td><td>0.0714</td><td>0.0783</td><td>0.0895</td><td>0.0946</td><td>0.0782</td><td>0.0689</td><td>0.1047</td><td>0.1040</td><td>0.0836</td><td>0.1042</td><td>0.1047</td><td>0.0947</td><td>0.1092</td><td>4.30%</td></tr><tr><td>NDCG@5</td><td>0.0707</td><td>0.0633</td><td>0.0695</td><td>0.0801</td><td>0.0854</td><td>0.0712</td><td>0.0613</td><td>0.0955</td><td>0.0933</td><td>0.0749</td><td>0.0935</td><td>0.0959</td><td>0.0860</td><td>0.0995</td><td>3.75%</td></tr><tr><td>Recall@10</td><td>0.1162</td><td>0.1089</td><td>0.1150</td><td>0.1326</td><td>0.1383</td><td>0.1187</td><td>0.1045</td><td>0.1520</td><td>0.1508</td><td>0.1221</td><td>0.1515</td><td>0.1525</td><td>0.1377</td><td>0.1592</td><td>4.39%</td></tr><tr><td>NDCG@10</td><td>0.0821</td><td>0.0749</td><td>0.0808</td><td>0.0932</td><td>0.0985</td><td>0.0834</td><td>0.0722</td><td>0.1092</td><td>0.1078</td><td>0.0866</td><td>0.1085</td><td>0.1100</td><td>0.0988</td><td>0.1145</td><td>4.09%</td></tr><tr><td>Recall@20</td><td>0.1695</td><td>0.1626</td><td>0.1666</td><td>0.1914</td><td>0.2002</td><td>0.1756</td><td>0.1552</td><td>0.2160</td><td>0.2130</td><td>0.1794</td><td>0.2166</td><td>0.2181</td><td>0.1978</td><td>0.2253</td><td>3.30%</td></tr><tr><td>NDCG@20</td><td>0.0973</td><td>0.0903</td><td>0.0956</td><td>0.1100</td><td>0.1161</td><td>0.0996</td><td>0.0868</td><td>0.1274</td><td>0.1254</td><td>0.1029</td><td>0.1271</td><td>0.1286</td><td>0.1159</td><td>0.1333</td><td>3.65%</td></tr><tr><td rowspan="6">iFashion</td><td>Recall@5</td><td>0.0195</td><td>0.0240</td><td>0.0234</td><td>0.0297</td><td>0.0309</td><td>0.0345</td><td>0.0237</td><td>0.0377</td><td>0.0330</td><td>0.0419</td><td>0.0354</td><td>0.0401</td><td>0.0423</td><td>0.0463</td><td>9.46%</td></tr><tr><td>NDCG@5</td><td>0.0128</td><td>0.0156</td><td>0.0151</td><td>0.0197</td><td>0.0205</td><td>0.0231</td><td>0.0157</td><td>0.0252</td><td>0.0219</td><td>0.0280</td><td>0.0235</td><td>0.0267</td><td>0.0284</td><td>0.0310</td><td>9.15%</td></tr><tr><td>Recall@10</td><td>0.0307</td><td>0.0393</td><td>0.0384</td><td>0.0459</td><td>0.0481</td><td>0.0525</td><td>0.0361</td><td>0.0574</td><td>0.0501</td><td>0.0636</td><td>0.0540</td><td>0.0608</td><td>0.0641</td><td>0.0696</td><td>8.58%</td></tr><tr><td>NDCG@10</td><td>0.0164</td><td>0.0206</td><td>0.0199</td><td>0.0249</td><td>0.0260</td><td>0.0289</td><td>0.0198</td><td>0.0315</td><td>0.0274</td><td>0.0350</td><td>0.0294</td><td>0.0334</td><td>0.0354</td><td>0.0386</td><td>9.04%</td></tr><tr><td>Recall@20</td><td>0.0470</td><td>0.0623</td><td>0.0608</td><td>0.0685</td><td>0.0716</td><td>0.0770</td><td>0.0535</td><td>0.0846</td><td>0.0742</td><td>0.0929</td><td>0.0790</td><td>0.0897</td><td>0.0932</td><td>0.1010</td><td>8.37%</td></tr><tr><td>NDCG@20</td><td>0.0206</td><td>0.0264</td><td>0.0256</td><td>0.0307</td><td>0.0320</td><td>0.0351</td><td>0.0242</td><td>0.0384</td><td>0.0335</td><td>0.0425</td><td>0.0358</td><td>0.0407</td><td>0.0428</td><td>0.0465</td><td>8.64%</td></tr></table>

![](images/4.jpg)  

Figure 4: Ablation study of data augmentation methods.

# 4.3 消融研究

在这一部分，我们首先探讨了所提方法中各种对比视图生成方法的贡献，然后对 CL 的对齐性和一致性进行深入的消融分析。4.3.1 数据增强的消融研究。为了探讨 CoGCL 中数据增强方法的贡献，我们评估了以下变体的性能：（1）w/o Replace 移除了虚拟邻居增强中的“替换”操作；（2）w/o Add 移除了虚拟邻居增强中的“添加”操作；（3）w/o Shared-C 移除了语义相关采样中相似用户/项目的共享代码；（4）w/o Shared-T 移除了语义相关采样中相似用户/项目的共享交互目标。结果如图 4 所示。我们可以观察到，任一数据增强方法的排除都会导致性能下降，这表明在 CoGCL 中使用的所有数据增强方法对于性能提升都是有益的。

Table 3: Performance analysis of alignment and uniformity in CoGCL.   

<table><tr><td rowspan="2">Methods</td><td colspan="2">Instrument</td><td colspan="2">Office</td></tr><tr><td>Recall@10</td><td>NDCG@10</td><td>Recall@10</td><td>NDCG@10</td></tr><tr><td>LightGCN</td><td>0.0660</td><td>0.0361</td><td>0.0417</td><td>0.0231</td></tr><tr><td>CoGCL</td><td>0.0788</td><td>0.0435</td><td>0.0582</td><td>0.0343</td></tr><tr><td>w/o A</td><td>0.0726</td><td>0.0401</td><td>0.0490</td><td>0.0280</td></tr><tr><td>w/o U</td><td>0.0703</td><td>0.0384</td><td>0.0465</td><td>0.0267</td></tr><tr><td>w/o AA</td><td>0.0741</td><td>0.0411</td><td>0.0536</td><td>0.0315</td></tr><tr><td>w/o AU</td><td>0.0762</td><td>0.0421</td><td>0.0542</td><td>0.0306</td></tr><tr><td>w/o SA</td><td>0.0767</td><td>0.0422</td><td>0.0554</td><td>0.0329</td></tr><tr><td>w/o SU</td><td>0.0779</td><td>0.0429</td><td>0.0574</td><td>0.0336</td></tr></table>

4.3.2 三视图图对比学习的消融研究。除了上述技术外，我们进一步探讨 CL 的对齐性和均匀性如何影响我们的方法。我们通过在实证分析中应用相同的梯度停止操作（第 2.2 节），分别禁用 CL 损失中的这两个项（即第 3.4 节中的 $\mathcal { L } _ { a u g }$ 和 $\mathcal { L } _ { s i m }$）。具体而言，我们构造了以下变体以进行详细探索：（1）$\underline { { \mathbf { W } / \mathbf { o } ~ \mathbf { A } } }$ 和（2）w/o U 与第 2.2 节一致，分别表示在 CL 中禁用对齐和均匀性，包括 $\mathcal { L } _ { a u g }$ 和 $\mathcal { L } _ { s i m }$ 的两个部分。（3）w/o AA 和（4）w/o AU 仅涉及禁用 $\mathcal { L } _ { a u g }$ 的上述两个项，而保持 $\mathcal { L } _ { s i m }$ 不变。（5）w/o SA 和（6）w/o SU 是对 $\mathcal { L } _ { s i m }$ 的类似变体，并不改变 $\mathcal { L } _ { s i m }$。

如表3所示，缺乏对齐（即 ${ \underline { { \mathbf { W } / \mathbf { 0 } } } } \mathbf { A } $）或统一性（即 $\underline { { \mathbf { w } / \mathbf { o } \mathbf { U } } } $）会导致 $\mathcal { L } _ { a u g }$ 和 $\mathcal { L } _ { s i m }$ 的性能显著下降。该观察结果验证了这两个元素的联合效应对所提方法的有效性至关重要，而不仅仅依赖于统一性。此外，单独禁用 $\mathcal { L } _ { a u g }$ 中的统一性（即 w/o AU）和 $\mathcal { L } _ { s i m }$ 中的统一性（即 w/o SU）未造成如所推测的显著不利影响。这可能归因于 $\mathrm { C o G C L }$ 中两个 CL 损失之间的共享统一性效应，它们可能相互增强。相反，在 $\mathcal { L } _ { a u g }$ 中单独禁用对齐（即 $\underline { { \mathbf { w } / \mathbf { o } \mathbf { A A } } } $）和在 $\mathcal { L } _ { s i m }$ 中（即 w/o SA）则会导致性能显著下降。这进一步表明我们提议的两种正样本之间的对齐带来了超越统一性的增强协作信息。

![](images/5.jpg)  

Figure 5: Performance comparison of different discrete code learning methods.

# 4.4 进一步分析

4.4.1 不同离散编码学习方法的性能比较。为了验证所提出的端到端离散编码学习方法的先进性，我们将其与以下三种变体进行比较：（1）非可学习编码使用 Faiss 库 [23] 基于训练好的 LightGCN 嵌入生成离散编码。生成的编码是不可学习的，并且在模型训练期间保持不变。（2）欧几里得编码采用欧几里得距离来衡量用户/物品表示与代码本向量之间的相似度，如公式 (6) 所示，这与原有的 RQ 方法 [9] 一致。（3）PQ 编码则采用 PQ 作为离散编码学习的多级量化器，而不是 RQ。我们在 Instrument 和 Office 数据集上进行实验，结果如图 5 所示。可以看出，与端到端学习的离散编码相比，非可学习编码的鲁棒性较差，这可能源于在优化模型时无法持续改进离散编码中的协作信息。与欧几里得编码和 PQ 编码相比，我们提出的方法表现更优。与欧几里得编码不同，我们的方法利用余弦相似度与 CL 中的相似性度量进行同步。与 PQ 编码相比，我们所采用的 RQ 在每一层建立了编码之间的条件概率关系，而不是将它们视为独立的，这有利于不同粒度的语义建模。4.4.2 数据稀疏性下的性能比较。为了验证我们的方法在缓解数据稀疏性方面的优势，我们评估了在不同稀疏级别的用户组上进行的 CoGCL。具体而言，遵循之前的研究 [4, 29]，我们根据用户的互动次数将用户分为五组，同时保持每组中的用户数量相同。随后，我们评估这五组用户的性能，结果如图 6 所示。我们可以看到，CoGCL 在所有稀疏级别下始终优于基线模型。此外，我们的模型在高度稀疏的用户组中表现出更好的性能和显著的提升。这一现象表明，CoGCL 能够在互动稀疏的场景中实现高质量的推荐，这得益于强协同信息下的对比视图之间 CL 带来的额外洞察。

![](images/6.jpg)  

Figure 6: Performance comparison on user groups with different sparsity levels.

# 5 相关工作

基于图神经网络的协同过滤。图神经网络（GNN）因其在建模用户-物品关系方面的有效性，已在协同过滤（CF）中变得突出。核心方法是将用户-物品交互数据组织成一个二部图，并从图结构中学习节点表示。早期的研究使用随机游走策略提取图信息。随着GNN的发展，研究逐渐转向设计有效的消息传递机制，以在图上传播用户/物品嵌入。随后，LightGCN 和 LR-GCCF 提出了消除变换和非线性激活，以简化GNN并提高性能。此外，最近的研究还致力于通过各种先进技术增强GNN，如解耦表示学习、超图学习和对比学习。

推荐系统中的对比学习。最近，对比学习（CL）在诸如序列推荐[33, 54, 65]和知识图谱增强推荐[67, 68]等各种推荐场景中展示了显著的潜力。在基于图神经网络（GNN）的协同过滤（CF）背景下，现有研究可以根据对比视图的构建方式大致分为两种主要方法。第一种方法是对图结构进行数据增强[4, 27, 35, 51]。例如，SGL [51] 在交互图中随机删除节点/边以构造增强图。第二种方法是为对比学习建模额外的用户和物品视图表示[26, 29, 40, 53, 58, 60]。特别地，SimGCL [60] 通过向节点嵌入添加随机噪声生成对比视图。尽管这些方法取得了一定的成功，但在对比视图中协同信息可能会受到干扰，因此对比学习的潜力尚未得到充分发挥。本文提出通过离散编码构建具有更强协同信息的对比视图，从而释放对比学习的潜力。

推荐中的用户/项目 ID 离散化。ID 离散化涉及使用一组离散代码作为标识符来表示用户/项目，而不是简单的单一 ID，这通过语义哈希 [5, 19, 37]、向量量化 [14, 44] 等方法实现。这些方法允许相似的用户/项目共享某些代码，从而为后续推荐模型提供有价值的先验知识。最初，重点是通过共享代码嵌入开发内存和时间高效的推荐算法 [1, 24, 25, 28, 38]。最近，离散代码在提高各种场景下的推荐质量方面越来越受欢迎。它们特别有助于缓解数据稀疏性，并提供先验语义，在可转移推荐 [16]、生成式序列推荐 [30, 34, 39, 47] 和基于大语言模型的推荐 [18, 64] 中都证明是有利的。与这些研究不同，我们的工作旨在利用离散代码进行虚拟邻域增强和语义相似性采样，以提升协同过滤中的图卷积学习。

# 6 结论

在本文中，我们提出了一种新颖的框架，通过构建可靠且信息丰富的对比视图来增强图对比学习，旨在暗示更强的协同信息。核心思想是学习与用户和物品相关的离散编码，这些编码包含丰富的协同信息，以生成对比视图。具体而言，我们提出了一种端到端的多级向量量化器，将用户和物品映射到离散编码中。这些编码被用于增强对比视图的邻域结构和语义相关性。首先，我们通过用离散编码替换节点邻居或依靠观察到的交互将其作为虚拟邻居来生成具有丰富邻域结构的双重增强节点。其次，我们将具有共享离散编码的用户/物品视为语义相关，并基于这种语义相关性选择相似的正例。最后，我们引入了一种三视图图对比学习方法，以对齐两个增强节点和抽样的相似用户/物品。在四个公共数据集上的大量实验验证了我们提出的CoGCL的有效性。作为未来的工作，我们尝试提高框架的可扩展性，以将其扩展到其他推荐场景，如点击率预测和序列推荐。